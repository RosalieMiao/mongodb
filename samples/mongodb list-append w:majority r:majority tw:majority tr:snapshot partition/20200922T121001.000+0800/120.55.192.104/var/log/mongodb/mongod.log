2020-09-22T12:10:13.443+0800 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-09-22T12:10:13.454+0800 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] MongoDB starting : pid=3597 port=27019 dbpath=/var/lib/mongodb 64-bit host=Jepsen-Node-02
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] db version v4.2.6
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0g  2 Nov 2017
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] modules: none
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] build environment:
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten]     distmod: debian92
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten]     distarch: x86_64
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-09-22T12:10:13.455+0800 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-09-22T12:10:13.455+0800 I  STORAGE  [initandlisten] 
2020-09-22T12:10:13.455+0800 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-09-22T12:10:13.455+0800 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-09-22T12:10:13.455+0800 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=487M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-09-22T12:10:14.118+0800 I  STORAGE  [initandlisten] WiredTiger message [1600747814:118649][3597:0x7f1f6ea76b00], txn-recover: Set global recovery timestamp: (0, 0)
2020-09-22T12:10:14.130+0800 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-09-22T12:10:14.141+0800 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-09-22T12:10:14.147+0800 I  CONTROL  [initandlisten] 
2020-09-22T12:10:14.147+0800 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-09-22T12:10:14.147+0800 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-09-22T12:10:14.147+0800 I  CONTROL  [initandlisten] 
2020-09-22T12:10:14.148+0800 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-09-22T12:10:14.148+0800 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-09-22T12:10:14.148+0800 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-09-22T12:10:14.148+0800 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-09-22T12:10:14.149+0800 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 3ca4c4c6-7418-42ba-b7d1-25bee22b0a36 and options: { capped: true, size: 10485760 }
2020-09-22T12:10:14.170+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-09-22T12:10:14.170+0800 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-09-22T12:10:14.170+0800 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-09-22T12:10:14.174+0800 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: f8d9f36e-b771-4387-9d34-43caa7d4463a and options: {}
2020-09-22T12:10:14.175+0800 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-09-22T12:10:14.175+0800 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-09-22T12:10:14.187+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-09-22T12:10:14.187+0800 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 25f79fe6-54ce-478e-b70d-87df63dcf340 and options: {}
2020-09-22T12:10:14.201+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-09-22T12:10:14.202+0800 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-09-22T12:10:14.202+0800 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 975ab54b-a390-4aaf-b110-3abd423f66da and options: {}
2020-09-22T12:10:14.216+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-09-22T12:10:14.216+0800 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-09-22T12:10:14.216+0800 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-09-22T12:10:14.216+0800 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-09-22T12:10:14.216+0800 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 140e017d-564d-4751-a591-cf4bdb173853 and options: {}
2020-09-22T12:10:14.228+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-09-22T12:10:14.228+0800 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-09-22T12:10:14.228+0800 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-09-22T12:10:14.228+0800 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-09-22T12:10:14.230+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("0086ec25-42f7-46f2-859c-49f60ef4c632"), lastMod: 0 } took 0 ms
2020-09-22T12:10:14.230+0800 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-09-22T12:10:14.230+0800 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-09-22T12:10:14.230+0800 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-09-22T12:10:14.230+0800 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-09-22T12:10:14.230+0800 I  NETWORK  [listener] Listening on 0.0.0.0
2020-09-22T12:10:14.230+0800 I  NETWORK  [listener] waiting for connections on port 27019
2020-09-22T12:10:15.000+0800 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-09-22T12:10:15.603+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55355 #1 (1 connection now open)
2020-09-22T12:10:15.606+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55356 #2 (2 connections now open)
2020-09-22T12:10:15.622+0800 I  NETWORK  [conn2] received client metadata from 211.162.81.126:55356 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:15.622+0800 I  NETWORK  [conn1] received client metadata from 211.162.81.126:55355 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:15.697+0800 I  NETWORK  [conn1] end connection 211.162.81.126:55355 (1 connection now open)
2020-09-22T12:10:15.697+0800 I  NETWORK  [conn2] end connection 211.162.81.126:55356 (0 connections now open)
2020-09-22T12:10:16.404+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37498 #3 (1 connection now open)
2020-09-22T12:10:16.405+0800 I  NETWORK  [conn3] end connection 120.55.194.98:37498 (0 connections now open)
2020-09-22T12:10:16.406+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37502 #4 (1 connection now open)
2020-09-22T12:10:16.406+0800 I  NETWORK  [conn4] received client metadata from 120.55.194.98:37502 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:16.407+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:16.912+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:59934 #8 (2 connections now open)
2020-09-22T12:10:16.913+0800 I  NETWORK  [conn8] end connection 120.55.192.104:59934 (1 connection now open)
2020-09-22T12:10:16.913+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53724 #10 (2 connections now open)
2020-09-22T12:10:16.913+0800 I  NETWORK  [conn10] end connection 112.124.21.191:53724 (1 connection now open)
2020-09-22T12:10:16.914+0800 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: d5acaaef-3e1f-46b0-af94-f2584f7b2641 and options: {}
2020-09-22T12:10:16.925+0800 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-09-22T12:10:16.926+0800 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "120.55.194.98:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "120.55.192.104:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "112.124.21.191:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5f697928513fac20f0ca1972') } }
2020-09-22T12:10:16.926+0800 I  REPL     [replexec-0] This node is 120.55.192.104:27019 in the config
2020-09-22T12:10:16.926+0800 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-09-22T12:10:16.926+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:10:16.926+0800 I  REPL     [replexec-0] Starting replication storage threads
2020-09-22T12:10:16.927+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:16.929+0800 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 662fc4dc-116c-4ed7-9022-a87ca5e4f4af and options: { temp: true }
2020-09-22T12:10:16.931+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53728 #12 (2 connections now open)
2020-09-22T12:10:16.931+0800 I  NETWORK  [conn12] received client metadata from 112.124.21.191:53728 conn12: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:16.933+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state STARTUP2
2020-09-22T12:10:16.941+0800 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-09-22T12:10:16.941+0800 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-09-22T12:10:16.941+0800 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (662fc4dc-116c-4ed7-9022-a87ca5e4f4af).
2020-09-22T12:10:16.942+0800 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 63ee8f40-4db2-4dbb-98b8-2b66119703a6 and options: { temp: true }
2020-09-22T12:10:16.955+0800 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-09-22T12:10:16.955+0800 I  REPL     [replication-0] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:16.955+0800 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-09-22T12:10:16.955+0800 I  REPL     [replication-0] ******
2020-09-22T12:10:16.955+0800 I  REPL     [replication-0] creating replication oplog of size: 1733MB...
2020-09-22T12:10:16.955+0800 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: eb3a0b30-dd23-4eda-a152-18d2f7a8f6a2 and options: { capped: true, size: 1818068582.0, autoIndexId: false }
2020-09-22T12:10:16.963+0800 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-09-22T12:10:16.963+0800 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-09-22T12:10:16.963+0800 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:10:16.963+0800 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-09-22T12:10:17.003+0800 I  REPL     [replication-0] ******
2020-09-22T12:10:17.004+0800 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-09-22T12:10:17.004+0800 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-09-22T12:10:17.016+0800 I  SHARDING [replication-0] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-09-22T12:10:17.016+0800 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.version
2020-09-22T12:10:17.017+0800 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 7e4950ec-424a-4bdd-ab0e-79368851545a and options: { uuid: UUID("7e4950ec-424a-4bdd-ab0e-79368851545a") }
2020-09-22T12:10:17.030+0800 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-09-22T12:10:17.030+0800 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:17.033+0800 I  COMMAND  [repl-writer-worker-1] setting featureCompatibilityVersion to 4.2
2020-09-22T12:10:17.033+0800 I  NETWORK  [repl-writer-worker-1] Skip closing connection for connection # 12
2020-09-22T12:10:17.033+0800 I  NETWORK  [repl-writer-worker-1] Skip closing connection for connection # 4
2020-09-22T12:10:17.033+0800 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-09-22T12:10:17.033+0800 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-09-22T12:10:17.036+0800 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
2020-09-22T12:10:17.037+0800 I  INITSYNC [replication-0] Finished cloning data: OK. Beginning oplog replay.
2020-09-22T12:10:17.037+0800 I  INITSYNC [replication-1] No need to apply operations. (currently at { : Timestamp(1600747816, 1) })
2020-09-22T12:10:17.038+0800 I  SHARDING [replication-0] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-09-22T12:10:17.038+0800 I  CONNPOOL [replication-0] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:17.039+0800 I  INITSYNC [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
2020-09-22T12:10:17.039+0800 I  INITSYNC [replication-0] Initial sync attempt finishing up.
2020-09-22T12:10:17.039+0800 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1600747816941), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1600747816, 1), initialSyncOplogEnd: Timestamp(1600747816, 1), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1600747817015), end: new Date(1600747817037), elapsedMillis: 22, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1600747817016), end: new Date(1600747817037), elapsedMillis: 21, receivedBatches: 1 } } } }
2020-09-22T12:10:17.039+0800 I  STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (63ee8f40-4db2-4dbb-98b8-2b66119703a6).
2020-09-22T12:10:17.043+0800 I  SHARDING [replication-1] Marking collection config.transactions as collection version: <unsharded>
2020-09-22T12:10:17.046+0800 I  INITSYNC [replication-1] initial sync done; took 0s.
2020-09-22T12:10:17.046+0800 I  REPL     [replication-1] transition to RECOVERING from STARTUP2
2020-09-22T12:10:17.046+0800 I  REPL     [replication-1] Starting replication fetcher thread
2020-09-22T12:10:17.046+0800 I  REPL     [replication-1] Starting replication applier thread
2020-09-22T12:10:17.046+0800 I  REPL     [rsSync-0] Starting oplog application
2020-09-22T12:10:17.046+0800 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-09-22T12:10:17.046+0800 I  REPL     [replication-1] Starting replication reporter thread
2020-09-22T12:10:17.046+0800 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-09-22T12:10:17.046+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:17.047+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:10:17.534+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747816, 1), t: -1 } }
2020-09-22T12:10:17.534+0800 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-09-22T12:10:17.536+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747816, 1), t: -1 } }
2020-09-22T12:10:17.536+0800 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-09-22T12:10:17.547+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:17.582+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55357 #16 (3 connections now open)
2020-09-22T12:10:17.582+0800 I  NETWORK  [conn16] received client metadata from 211.162.81.126:55357 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:17.593+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56253 #17 (4 connections now open)
2020-09-22T12:10:17.594+0800 I  NETWORK  [conn17] received client metadata from 211.162.81.126:56253 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:17.812+0800 I  NETWORK  [conn16] end connection 211.162.81.126:55357 (3 connections now open)
2020-09-22T12:10:17.812+0800 I  NETWORK  [conn17] end connection 211.162.81.126:56253 (2 connections now open)
2020-09-22T12:10:18.564+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60352 #18 (3 connections now open)
2020-09-22T12:10:18.565+0800 I  NETWORK  [conn18] received client metadata from 47.96.5.198:60352 conn18: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.573+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60362 #19 (4 connections now open)
2020-09-22T12:10:18.573+0800 I  NETWORK  [conn19] received client metadata from 47.96.5.198:60362 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.579+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38080 #20 (5 connections now open)
2020-09-22T12:10:18.579+0800 I  NETWORK  [conn20] received client metadata from 47.96.16.32:38080 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.582+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37508 #21 (6 connections now open)
2020-09-22T12:10:18.582+0800 I  NETWORK  [conn21] received client metadata from 120.55.194.98:37508 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.585+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37518 #22 (7 connections now open)
2020-09-22T12:10:18.585+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37520 #23 (8 connections now open)
2020-09-22T12:10:18.586+0800 I  NETWORK  [conn23] received client metadata from 120.55.194.98:37520 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.586+0800 I  NETWORK  [conn22] received client metadata from 120.55.194.98:37518 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.588+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38090 #24 (9 connections now open)
2020-09-22T12:10:18.588+0800 I  NETWORK  [conn24] received client metadata from 47.96.16.32:38090 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.588+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38084 #25 (10 connections now open)
2020-09-22T12:10:18.588+0800 I  NETWORK  [conn25] received client metadata from 47.96.16.32:38084 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.589+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37054 #26 (11 connections now open)
2020-09-22T12:10:18.589+0800 I  NETWORK  [conn26] received client metadata from 118.31.43.238:37054 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.736+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53736 #27 (12 connections now open)
2020-09-22T12:10:18.737+0800 I  NETWORK  [conn27] received client metadata from 112.124.21.191:53736 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.739+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53744 #28 (13 connections now open)
2020-09-22T12:10:18.739+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53746 #29 (14 connections now open)
2020-09-22T12:10:18.739+0800 I  NETWORK  [conn29] received client metadata from 112.124.21.191:53746 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.739+0800 I  NETWORK  [conn28] received client metadata from 112.124.21.191:53744 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:19.047+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:19.048+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:10:19.048+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:10:19.050+0800 I  STORAGE  [repl-writer-worker-3] createCollection: config.transactions with provided UUID: 4053617d-d9e7-479b-91cd-0abf68267354 and options: { uuid: UUID("4053617d-d9e7-479b-91cd-0abf68267354") }
2020-09-22T12:10:19.062+0800 I  INDEX    [repl-writer-worker-3] index build: done building index _id_ on ns config.transactions
2020-09-22T12:10:19.064+0800 I  STORAGE  [repl-writer-worker-7] createCollection: config.chunks with provided UUID: a101121e-0946-4ee4-9c3c-7bb6281db167 and options: { uuid: UUID("a101121e-0946-4ee4-9c3c-7bb6281db167") }
2020-09-22T12:10:19.076+0800 I  INDEX    [repl-writer-worker-7] index build: done building index _id_ on ns config.chunks
2020-09-22T12:10:19.094+0800 I  INDEX    [repl-writer-worker-11] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.094+0800 I  INDEX    [repl-writer-worker-11] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.094+0800 I  STORAGE  [repl-writer-worker-11] Index build initialized: 9c87f3d2-6ba6-4b1b-b112-15bf23aefc48: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.116+0800 I  INDEX    [repl-writer-worker-15] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.116+0800 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.116+0800 I  STORAGE  [repl-writer-worker-15] Index build initialized: 9116eb48-72b1-4056-a4b4-a8cf66eb1e08: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.116+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.117+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.120+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-09-22T12:10:19.123+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 9c87f3d2-6ba6-4b1b-b112-15bf23aefc48: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 3
2020-09-22T12:10:19.144+0800 I  INDEX    [repl-writer-worker-4] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.144+0800 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.144+0800 I  STORAGE  [repl-writer-worker-4] Index build initialized: 7a210a54-319f-49a1-a960-169102caa845: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.144+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.145+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.148+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.149+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.151+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-09-22T12:10:19.156+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 7a210a54-319f-49a1-a960-169102caa845: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 3. Indexes in catalog after build: 4
2020-09-22T12:10:19.157+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-09-22T12:10:19.160+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 9116eb48-72b1-4056-a4b4-a8cf66eb1e08: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 4
2020-09-22T12:10:19.161+0800 I  STORAGE  [repl-writer-worker-6] createCollection: config.migrations with provided UUID: 2a18503c-6359-4f56-9f16-29eed137e385 and options: { uuid: UUID("2a18503c-6359-4f56-9f16-29eed137e385") }
2020-09-22T12:10:19.172+0800 I  INDEX    [repl-writer-worker-6] index build: done building index _id_ on ns config.migrations
2020-09-22T12:10:19.193+0800 I  INDEX    [repl-writer-worker-10] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-09-22T12:10:19.193+0800 I  INDEX    [repl-writer-worker-10] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.193+0800 I  STORAGE  [repl-writer-worker-10] Index build initialized: 41f569a2-0802-4ad1-816b-6cf8f66f43b4: config.migrations (2a18503c-6359-4f56-9f16-29eed137e385 ): indexes: 1
2020-09-22T12:10:19.194+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.194+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.196+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-09-22T12:10:19.198+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 41f569a2-0802-4ad1-816b-6cf8f66f43b4: config.migrations ( 2a18503c-6359-4f56-9f16-29eed137e385 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.199+0800 I  STORAGE  [repl-writer-worker-12] createCollection: config.shards with provided UUID: 551d8645-5410-46d3-ac48-3f86cc78c694 and options: { uuid: UUID("551d8645-5410-46d3-ac48-3f86cc78c694") }
2020-09-22T12:10:19.214+0800 I  INDEX    [repl-writer-worker-12] index build: done building index _id_ on ns config.shards
2020-09-22T12:10:19.242+0800 I  INDEX    [repl-writer-worker-0] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-09-22T12:10:19.242+0800 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.242+0800 I  STORAGE  [repl-writer-worker-0] Index build initialized: 99c937b2-3c4e-4514-9f3f-1907e5330ca5: config.shards (551d8645-5410-46d3-ac48-3f86cc78c694 ): indexes: 1
2020-09-22T12:10:19.242+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.243+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.252+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index host_1 on ns config.shards
2020-09-22T12:10:19.255+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 99c937b2-3c4e-4514-9f3f-1907e5330ca5: config.shards ( 551d8645-5410-46d3-ac48-3f86cc78c694 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.256+0800 I  STORAGE  [repl-writer-worker-2] createCollection: config.locks with provided UUID: 75fb8f2f-a2b3-49f4-bb93-400680f69951 and options: { uuid: UUID("75fb8f2f-a2b3-49f4-bb93-400680f69951") }
2020-09-22T12:10:19.267+0800 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns config.locks
2020-09-22T12:10:19.281+0800 I  INDEX    [repl-writer-worker-3] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-09-22T12:10:19.281+0800 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.281+0800 I  STORAGE  [repl-writer-worker-3] Index build initialized: e63e6ba4-85fc-4a42-badd-01ebdffd575e: config.locks (75fb8f2f-a2b3-49f4-bb93-400680f69951 ): indexes: 1
2020-09-22T12:10:19.281+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.282+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.284+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ts_1 on ns config.locks
2020-09-22T12:10:19.285+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: e63e6ba4-85fc-4a42-badd-01ebdffd575e: config.locks ( 75fb8f2f-a2b3-49f4-bb93-400680f69951 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.298+0800 I  INDEX    [repl-writer-worker-7] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-09-22T12:10:19.298+0800 I  INDEX    [repl-writer-worker-7] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.298+0800 I  STORAGE  [repl-writer-worker-7] Index build initialized: 37c15b87-5995-459b-a061-7936cc38ae33: config.locks (75fb8f2f-a2b3-49f4-bb93-400680f69951 ): indexes: 1
2020-09-22T12:10:19.298+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.299+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.301+0800 I  STORAGE  [repl-writer-worker-13] createCollection: config.lockpings with provided UUID: 990ea228-4f92-4ac6-83ef-83a3dd549ffd and options: { uuid: UUID("990ea228-4f92-4ac6-83ef-83a3dd549ffd") }
2020-09-22T12:10:19.302+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index state_1_process_1 on ns config.locks
2020-09-22T12:10:19.315+0800 I  INDEX    [repl-writer-worker-13] index build: done building index _id_ on ns config.lockpings
2020-09-22T12:10:19.316+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 37c15b87-5995-459b-a061-7936cc38ae33: config.locks ( 75fb8f2f-a2b3-49f4-bb93-400680f69951 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-09-22T12:10:19.330+0800 I  INDEX    [repl-writer-worker-1] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-09-22T12:10:19.330+0800 I  INDEX    [repl-writer-worker-1] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.330+0800 I  STORAGE  [repl-writer-worker-1] Index build initialized: 92d89a9e-5fb7-4ef5-877f-9d746161e602: config.lockpings (990ea228-4f92-4ac6-83ef-83a3dd549ffd ): indexes: 1
2020-09-22T12:10:19.330+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.330+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.333+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ping_1 on ns config.lockpings
2020-09-22T12:10:19.334+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 92d89a9e-5fb7-4ef5-877f-9d746161e602: config.lockpings ( 990ea228-4f92-4ac6-83ef-83a3dd549ffd ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.335+0800 I  STORAGE  [repl-writer-worker-15] createCollection: config.tags with provided UUID: 90449d01-a92c-4bc8-b6f6-bf9774d459a2 and options: { uuid: UUID("90449d01-a92c-4bc8-b6f6-bf9774d459a2") }
2020-09-22T12:10:19.356+0800 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.tags
2020-09-22T12:10:19.379+0800 I  INDEX    [repl-writer-worker-8] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-09-22T12:10:19.379+0800 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.379+0800 I  STORAGE  [repl-writer-worker-8] Index build initialized: a58e4753-90d8-4d51-971b-2a04c16cf5fa: config.tags (90449d01-a92c-4bc8-b6f6-bf9774d459a2 ): indexes: 1
2020-09-22T12:10:19.379+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.380+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.382+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_min_1 on ns config.tags
2020-09-22T12:10:19.384+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: a58e4753-90d8-4d51-971b-2a04c16cf5fa: config.tags ( 90449d01-a92c-4bc8-b6f6-bf9774d459a2 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.398+0800 I  STORAGE  [replication-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1600747816, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1600747817, 28)
2020-09-22T12:10:19.398+0800 I  SHARDING [conn19] Marking collection admin.system.keys as collection version: <unsharded>
2020-09-22T12:10:19.405+0800 I  INDEX    [repl-writer-worker-7] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-09-22T12:10:19.405+0800 I  INDEX    [repl-writer-worker-7] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.405+0800 I  STORAGE  [repl-writer-worker-7] Index build initialized: e7d1e255-0e41-4724-9470-bd2a7129a785: config.tags (90449d01-a92c-4bc8-b6f6-bf9774d459a2 ): indexes: 1
2020-09-22T12:10:19.408+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.408+0800 W  STORAGE  [IndexBuildsCoordinatorMongod-0] failed to create WiredTiger bulk cursor: Device or resource busy
2020-09-22T12:10:19.408+0800 W  STORAGE  [IndexBuildsCoordinatorMongod-0] falling back to non-bulk cursor for index table:index-57-1434489999893539919
2020-09-22T12:10:19.408+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.408+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-09-22T12:10:19.408+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: e7d1e255-0e41-4724-9470-bd2a7129a785: config.tags ( 90449d01-a92c-4bc8-b6f6-bf9774d459a2 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-09-22T12:10:19.408+0800 I  COMMAND  [conn19] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 823ms
2020-09-22T12:10:19.408+0800 I  COMMAND  [conn22] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 811ms
2020-09-22T12:10:19.408+0800 I  COMMAND  [conn25] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 808ms
2020-09-22T12:10:19.408+0800 I  COMMAND  [conn28] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 658ms
2020-09-22T12:10:19.409+0800 I  STORAGE  [repl-writer-worker-13] createCollection: config.version with provided UUID: 040e4fca-70a7-4d42-aac8-66895ee93871 and options: { uuid: UUID("040e4fca-70a7-4d42-aac8-66895ee93871") }
2020-09-22T12:10:19.440+0800 I  INDEX    [repl-writer-worker-13] index build: done building index _id_ on ns config.version
2020-09-22T12:10:19.441+0800 I  SHARDING [repl-writer-worker-11] Marking collection config.lockpings as collection version: <unsharded>
2020-09-22T12:10:19.442+0800 I  SHARDING [repl-writer-worker-11] Marking collection config.version as collection version: <unsharded>
2020-09-22T12:10:19.443+0800 I  SHARDING [conn23] Marking collection config.shards as collection version: <unsharded>
2020-09-22T12:10:19.443+0800 I  COMMAND  [conn23] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 856ms
2020-09-22T12:10:19.443+0800 I  COMMAND  [conn24] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 853ms
2020-09-22T12:10:19.443+0800 I  COMMAND  [conn29] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 703ms
2020-09-22T12:10:19.444+0800 I  STORAGE  [repl-writer-worker-4] createCollection: admin.system.keys with provided UUID: 394a26b5-28ef-428f-a02a-72801fb5a7a6 and options: { uuid: UUID("394a26b5-28ef-428f-a02a-72801fb5a7a6") }
2020-09-22T12:10:19.469+0800 I  INDEX    [repl-writer-worker-4] index build: done building index _id_ on ns admin.system.keys
2020-09-22T12:10:19.846+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:59948 #31 (15 connections now open)
2020-09-22T12:10:19.846+0800 I  NETWORK  [conn31] received client metadata from 120.55.192.104:59948 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:19.848+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:59960 #32 (16 connections now open)
2020-09-22T12:10:19.848+0800 I  NETWORK  [conn32] received client metadata from 120.55.192.104:59960 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:20.381+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37068 #33 (17 connections now open)
2020-09-22T12:10:20.381+0800 I  NETWORK  [conn33] received client metadata from 118.31.43.238:37068 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:20.384+0800 I  SHARDING [conn33] Marking collection config.settings as collection version: <unsharded>
2020-09-22T12:10:20.399+0800 I  SHARDING [conn33] Marking collection config.collections as collection version: <unsharded>
2020-09-22T12:10:20.412+0800 I  STORAGE  [repl-writer-worker-7] createCollection: config.mongos with provided UUID: 282775af-a43f-4c57-858a-851b59ec70fc and options: { uuid: UUID("282775af-a43f-4c57-858a-851b59ec70fc") }
2020-09-22T12:10:20.425+0800 I  INDEX    [repl-writer-worker-7] index build: done building index _id_ on ns config.mongos
2020-09-22T12:10:20.426+0800 I  SHARDING [repl-writer-worker-13] Marking collection config.mongos as collection version: <unsharded>
2020-09-22T12:10:23.012+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60368 #34 (18 connections now open)
2020-09-22T12:10:23.012+0800 I  NETWORK  [conn34] received client metadata from 47.96.5.198:60368 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.014+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37072 #35 (19 connections now open)
2020-09-22T12:10:23.014+0800 I  NETWORK  [conn35] received client metadata from 118.31.43.238:37072 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.015+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38096 #36 (20 connections now open)
2020-09-22T12:10:23.015+0800 I  NETWORK  [conn36] received client metadata from 47.96.16.32:38096 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.021+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38102 #37 (21 connections now open)
2020-09-22T12:10:23.021+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38100 #38 (22 connections now open)
2020-09-22T12:10:23.021+0800 I  NETWORK  [conn38] received client metadata from 47.96.16.32:38100 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.022+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37078 #39 (23 connections now open)
2020-09-22T12:10:23.022+0800 I  NETWORK  [conn39] received client metadata from 118.31.43.238:37078 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.022+0800 I  NETWORK  [conn37] received client metadata from 47.96.16.32:38102 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.022+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37080 #40 (24 connections now open)
2020-09-22T12:10:23.022+0800 I  NETWORK  [conn40] received client metadata from 118.31.43.238:37080 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.035+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60370 #41 (25 connections now open)
2020-09-22T12:10:23.035+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60376 #42 (26 connections now open)
2020-09-22T12:10:23.035+0800 I  NETWORK  [conn42] received client metadata from 47.96.5.198:60376 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.035+0800 I  NETWORK  [conn41] received client metadata from 47.96.5.198:60370 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.041+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60380 #43 (27 connections now open)
2020-09-22T12:10:23.041+0800 I  NETWORK  [conn43] received client metadata from 47.96.5.198:60380 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.093+0800 I  STORAGE  [repl-writer-worker-11] createCollection: config.changelog with provided UUID: 4eb1c795-cfa4-4b19-801d-0eab6874e47f and options: { uuid: UUID("4eb1c795-cfa4-4b19-801d-0eab6874e47f"), capped: true, size: 209715200 }
2020-09-22T12:10:23.105+0800 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.changelog
2020-09-22T12:10:23.109+0800 I  SHARDING [repl-writer-worker-0] Marking collection config.changelog as collection version: <unsharded>
2020-09-22T12:10:23.229+0800 I  SHARDING [repl-writer-worker-5] Marking collection config.locks as collection version: <unsharded>
2020-09-22T12:10:23.256+0800 I  STORAGE  [repl-writer-worker-2] createCollection: config.databases with provided UUID: 4d7c98cb-17cc-41c8-adb8-aa748e2229f3 and options: { uuid: UUID("4d7c98cb-17cc-41c8-adb8-aa748e2229f3") }
2020-09-22T12:10:23.268+0800 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns config.databases
2020-09-22T12:10:23.269+0800 I  SHARDING [repl-writer-worker-9] Marking collection config.databases as collection version: <unsharded>
2020-09-22T12:10:23.459+0800 I  SHARDING [repl-writer-worker-9] Marking collection config.chunks as collection version: <unsharded>
2020-09-22T12:10:23.482+0800 I  STORAGE  [repl-writer-worker-12] createCollection: config.collections with provided UUID: aff6d799-d8e5-42bb-9d1a-d8dc37c3bc27 and options: { uuid: UUID("aff6d799-d8e5-42bb-9d1a-d8dc37c3bc27") }
2020-09-22T12:10:23.496+0800 I  INDEX    [repl-writer-worker-12] index build: done building index _id_ on ns config.collections
2020-09-22T12:10:26.011+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55358 #44 (28 connections now open)
2020-09-22T12:10:26.011+0800 I  NETWORK  [conn44] received client metadata from 211.162.81.126:55358 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:26.012+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55359 #45 (29 connections now open)
2020-09-22T12:10:26.016+0800 I  NETWORK  [conn45] received client metadata from 211.162.81.126:55359 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:26.081+0800 I  NETWORK  [conn44] end connection 211.162.81.126:55358 (28 connections now open)
2020-09-22T12:10:26.083+0800 I  NETWORK  [conn45] end connection 211.162.81.126:55359 (27 connections now open)
2020-09-22T12:10:34.127+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56254 #46 (28 connections now open)
2020-09-22T12:10:34.128+0800 I  NETWORK  [conn46] received client metadata from 211.162.81.126:56254 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.128+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55360 #47 (29 connections now open)
2020-09-22T12:10:34.130+0800 I  NETWORK  [conn47] received client metadata from 211.162.81.126:55360 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.188+0800 I  NETWORK  [conn46] end connection 211.162.81.126:56254 (28 connections now open)
2020-09-22T12:10:34.188+0800 I  NETWORK  [conn47] end connection 211.162.81.126:55360 (27 connections now open)
2020-09-22T12:10:34.717+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56255 #48 (28 connections now open)
2020-09-22T12:10:34.718+0800 I  NETWORK  [conn48] received client metadata from 211.162.81.126:56255 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.718+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55361 #49 (29 connections now open)
2020-09-22T12:10:34.719+0800 I  NETWORK  [conn49] received client metadata from 211.162.81.126:55361 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.786+0800 I  NETWORK  [conn48] end connection 211.162.81.126:56255 (28 connections now open)
2020-09-22T12:10:34.786+0800 I  NETWORK  [conn49] end connection 211.162.81.126:55361 (27 connections now open)
2020-09-22T12:10:35.624+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55362 #50 (28 connections now open)
2020-09-22T12:10:35.625+0800 I  NETWORK  [conn50] received client metadata from 211.162.81.126:55362 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:35.632+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55363 #51 (29 connections now open)
2020-09-22T12:10:35.633+0800 I  NETWORK  [conn51] received client metadata from 211.162.81.126:55363 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:35.687+0800 I  NETWORK  [conn50] end connection 211.162.81.126:55362 (28 connections now open)
2020-09-22T12:10:35.688+0800 I  NETWORK  [conn51] end connection 211.162.81.126:55363 (27 connections now open)
2020-09-22T12:10:38.630+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56256 #52 (28 connections now open)
2020-09-22T12:10:38.630+0800 I  NETWORK  [conn52] received client metadata from 211.162.81.126:56256 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:38.634+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56257 #53 (29 connections now open)
2020-09-22T12:10:38.635+0800 I  NETWORK  [conn53] received client metadata from 211.162.81.126:56257 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:38.695+0800 I  NETWORK  [conn52] end connection 211.162.81.126:56256 (28 connections now open)
2020-09-22T12:10:38.697+0800 I  NETWORK  [conn53] end connection 211.162.81.126:56257 (27 connections now open)
2020-09-22T12:10:39.700+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.700+0800 I  ELECTION [conn12] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-09-22T12:10:39.702+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.702+0800 I  ELECTION [conn12] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-09-22T12:10:40.456+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:40.456+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:40.456+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 518 timed out, deadline was 2020-09-22T12:10:40.456+0800, op was RemoteCommand 518 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:10:40.456+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "120.55.192.104:27019", fromId: 1, term: 1 }
2020-09-22T12:10:41.318+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747831, 5), t: 1 }, latest oplog optime of sync source: { ts: Timestamp(1600747831, 5), t: 1 } (sync source does not know the primary)
2020-09-22T12:10:41.318+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747831, 5), t: 1 }, its sync source index:-1
2020-09-22T12:10:41.318+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747831, 5), t: 1 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:10:41.318+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:10:41.318+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:10:41.318+0800 I  CONNPOOL [RS] Connecting to 112.124.21.191:27019
2020-09-22T12:10:41.320+0800 I  REPL     [rsBackgroundSync] Changed sync source from 120.55.194.98:27019 to 112.124.21.191:27019
2020-09-22T12:10:41.320+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source changed from 120.55.194.98:27019 to 112.124.21.191:27019
2020-09-22T12:10:41.323+0800 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 112.124.21.191:27019, my last fetched oplog optime: { ts: Timestamp(1600747840, 1), t: 2 }, latest oplog optime of sync source: { ts: Timestamp(1600747840, 1), t: 2 } (sync source does not know the primary)
2020-09-22T12:10:41.323+0800 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 112.124.21.191:27019, OpTime { ts: Timestamp(1600747840, 1), t: 2 }, its sync source index:-1
2020-09-22T12:10:41.323+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 112.124.21.191:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747840, 1), t: 2 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:10:41.323+0800 I  REPL     [rsBackgroundSync] Clearing sync source 112.124.21.191:27019 to choose a new one.
2020-09-22T12:10:41.323+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:41.324+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:41.434+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:41.434+0800 I  ELECTION [conn4] Sending vote response: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747831, 5), t: 1 }, my last applied OpTime: { ts: Timestamp..." }
2020-09-22T12:10:41.717+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.717+0800 I  ELECTION [conn12] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-09-22T12:10:41.719+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.719+0800 I  ELECTION [conn12] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-09-22T12:10:41.823+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:10:41.824+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:10:41.824+0800 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-09-22T12:10:43.921+0800
2020-09-22T12:10:42.323+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:10:42.325+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:10:43.249+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747842, 3), t: 3 } }
2020-09-22T12:10:43.249+0800 I  ELECTION [conn4] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-09-22T12:10:43.251+0800 I  REPL     [conn4] Canceling priority takeover callback
2020-09-22T12:10:43.251+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747842, 3), t: 3 } }
2020-09-22T12:10:43.251+0800 I  ELECTION [conn4] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-09-22T12:10:43.332+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 112.124.21.191:27019, my last fetched oplog optime: { ts: Timestamp(1600747842, 3), t: 3 }, latest oplog optime of sync source: { ts: Timestamp(1600747842, 3), t: 3 } (sync source does not know the primary)
2020-09-22T12:10:43.332+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 112.124.21.191:27019, OpTime { ts: Timestamp(1600747842, 3), t: 3 }, its sync source index:-1
2020-09-22T12:10:43.332+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 112.124.21.191:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747842, 3), t: 3 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:10:43.332+0800 I  REPL     [rsBackgroundSync] Clearing sync source 112.124.21.191:27019 to choose a new one.
2020-09-22T12:10:43.332+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:43.333+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:10:43.333+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:43.832+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:10:44.176+0800 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:10:44.177+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 47.96.5.198:27018
2020-09-22T12:10:44.177+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 118.31.43.238:27018
2020-09-22T12:10:44.177+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 47.96.16.32:27018
2020-09-22T12:10:44.184+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:10:44.333+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:44.334+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:10:47.005+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56258 #60 (28 connections now open)
2020-09-22T12:10:47.006+0800 I  NETWORK  [conn60] received client metadata from 211.162.81.126:56258 conn60: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:47.007+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55364 #61 (29 connections now open)
2020-09-22T12:10:47.007+0800 I  NETWORK  [conn61] received client metadata from 211.162.81.126:55364 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:47.066+0800 I  NETWORK  [conn60] end connection 211.162.81.126:56258 (28 connections now open)
2020-09-22T12:10:47.067+0800 I  NETWORK  [conn61] end connection 211.162.81.126:55364 (27 connections now open)
2020-09-22T12:10:47.881+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.881+0800 I  ELECTION [conn12] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-09-22T12:10:47.883+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.883+0800 I  ELECTION [conn12] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-09-22T12:10:48.158+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56259 #62 (28 connections now open)
2020-09-22T12:10:48.158+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55365 #63 (29 connections now open)
2020-09-22T12:10:48.159+0800 I  NETWORK  [conn62] received client metadata from 211.162.81.126:56259 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:48.159+0800 I  NETWORK  [conn63] received client metadata from 211.162.81.126:55365 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:48.213+0800 I  NETWORK  [conn62] end connection 211.162.81.126:56259 (28 connections now open)
2020-09-22T12:10:48.213+0800 I  NETWORK  [conn63] end connection 211.162.81.126:55365 (27 connections now open)
2020-09-22T12:10:48.333+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:10:48.333+0800 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-09-22T12:10:50.417+0800
2020-09-22T12:10:48.337+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:48.654+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747844, 1), t: 4 }, latest oplog optime of sync source: { ts: Timestamp(1600747844, 1), t: 4 } (112.124.21.191:27019 is)
2020-09-22T12:10:48.654+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747844, 1), t: 4 }, its sync source index:-1
2020-09-22T12:10:48.654+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747844, 1), t: 4 }; sync source index: -1; primary index: 2) is no longer valid
2020-09-22T12:10:48.654+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:10:48.654+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:48.953+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56260 #64 (28 connections now open)
2020-09-22T12:10:48.954+0800 I  NETWORK  [conn64] received client metadata from 211.162.81.126:56260 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:48.963+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55366 #65 (29 connections now open)
2020-09-22T12:10:48.964+0800 I  NETWORK  [conn65] received client metadata from 211.162.81.126:55366 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.022+0800 I  NETWORK  [conn64] end connection 211.162.81.126:56260 (28 connections now open)
2020-09-22T12:10:49.022+0800 I  NETWORK  [conn65] end connection 211.162.81.126:55366 (27 connections now open)
2020-09-22T12:10:49.152+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:10:49.553+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56261 #66 (28 connections now open)
2020-09-22T12:10:49.553+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55367 #67 (29 connections now open)
2020-09-22T12:10:49.553+0800 I  NETWORK  [conn67] received client metadata from 211.162.81.126:55367 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.554+0800 I  NETWORK  [conn66] received client metadata from 211.162.81.126:56261 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.610+0800 I  NETWORK  [conn67] end connection 211.162.81.126:55367 (28 connections now open)
2020-09-22T12:10:49.610+0800 I  NETWORK  [conn66] end connection 211.162.81.126:56261 (27 connections now open)
2020-09-22T12:10:49.654+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:10:49.656+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:10:50.417+0800 I  REPL     [replexec-2] Canceling priority takeover callback
2020-09-22T12:10:50.417+0800 I  ELECTION [replexec-2] Starting an election for a priority takeover
2020-09-22T12:10:50.417+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 5
2020-09-22T12:10:50.417+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 601 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.417+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 602 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.417+0800 I  ELECTION [replexec-3] VoteRequester(term 5 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000005') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747850, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 1) }
2020-09-22T12:10:50.418+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 6
2020-09-22T12:10:50.419+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 603 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.419+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 604 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.421+0800 I  ELECTION [replexec-1] VoteRequester(term 6) received a yes vote from 120.55.194.98:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000004') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747850, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 1) }
2020-09-22T12:10:50.421+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 6
2020-09-22T12:10:50.421+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:10:50.421+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was 112.124.21.191:27019
2020-09-22T12:10:50.421+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:10:50.421+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:10:50.421+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:50.422+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:10:50.422+0800 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747850, 1), t: 5 }. My Last Applied: { ts: Timestamp(1600747850, 1), t: 5 }
2020-09-22T12:10:50.422+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:10:50.422+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:10:50.423+0800 I  CONNPOOL [RS] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:50.423+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 6
2020-09-22T12:10:50.423+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 6
2020-09-22T12:10:50.423+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:10:50.423+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:50.423+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:50.423+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:50.424+0800 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-09-22T12:10:50.424+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:50.425+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:50.425+0800 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-09-22T12:10:50.426+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:50.426+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:50.426+0800 I  CONNPOOL [ShardRegistry] Connecting to 118.31.43.238:27018
2020-09-22T12:10:50.426+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-1] Refresh for database jepsendb from version {} to version { uuid: UUID("ab627ffa-6894-4fde-896e-17748d17e74b"), lastMod: 1 } took 0 ms
2020-09-22T12:10:50.427+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-1] Refresh for collection jepsendb.jepsencoll to version 1|6||5f69792fb532ea868744a14e took 0 ms
2020-09-22T12:10:50.428+0800 I  CONNPOOL [TaskExecutorPool-0] Connecting to 47.96.16.32:27018
2020-09-22T12:10:50.428+0800 I  CONNPOOL [TaskExecutorPool-0] Connecting to 47.96.5.198:27018
2020-09-22T12:10:50.434+0800 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-09-22T12:10:50.439+0800 I  SHARDING [Balancer] Marking collection config.tags as collection version: <unsharded>
2020-09-22T12:10:50.567+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:10:50.575+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56263 #73 (28 connections now open)
2020-09-22T12:10:50.576+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56262 #74 (29 connections now open)
2020-09-22T12:10:50.577+0800 I  NETWORK  [conn73] received client metadata from 211.162.81.126:56263 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:50.577+0800 I  NETWORK  [conn74] received client metadata from 211.162.81.126:56262 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:50.637+0800 I  NETWORK  [conn73] end connection 211.162.81.126:56263 (28 connections now open)
2020-09-22T12:10:50.638+0800 I  NETWORK  [conn74] end connection 211.162.81.126:56262 (27 connections now open)
2020-09-22T12:10:51.422+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:10:51.535+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.535+0800 I  ELECTION [conn12] Sending vote response: { term: 6, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp..." }
2020-09-22T12:10:51.538+0800 I  REPL     [conn12] stepping down from primary, because a new term has begun: 7
2020-09-22T12:10:51.538+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:51.538+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:51.538+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:10:51.538+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:10:51.538+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:10:51.539+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.539+0800 I  ELECTION [conn12] Sending vote response: { term: 7, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp..." }
2020-09-22T12:10:51.539+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:10:51.570+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37592 #75 (28 connections now open)
2020-09-22T12:10:51.570+0800 I  NETWORK  [conn75] received client metadata from 120.55.194.98:37592 conn75: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:51.572+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37594 #76 (29 connections now open)
2020-09-22T12:10:51.572+0800 I  NETWORK  [conn76] received client metadata from 120.55.194.98:37594 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:51.699+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56264 #77 (30 connections now open)
2020-09-22T12:10:51.699+0800 I  NETWORK  [conn77] received client metadata from 211.162.81.126:56264 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:51.709+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56265 #78 (31 connections now open)
2020-09-22T12:10:51.710+0800 I  NETWORK  [conn78] received client metadata from 211.162.81.126:56265 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:51.766+0800 I  NETWORK  [conn77] end connection 211.162.81.126:56264 (30 connections now open)
2020-09-22T12:10:51.766+0800 I  NETWORK  [conn78] end connection 211.162.81.126:56265 (29 connections now open)
2020-09-22T12:10:52.614+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 8), t: 6 } }
2020-09-22T12:10:52.614+0800 I  ELECTION [conn4] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-09-22T12:10:52.616+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 8), t: 6 } }
2020-09-22T12:10:52.616+0800 I  ELECTION [conn4] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-09-22T12:10:52.921+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:53.422+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:53.422+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:10:53.539+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:53.543+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:10:54.095+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56266 #79 (30 connections now open)
2020-09-22T12:10:54.096+0800 I  NETWORK  [conn79] received client metadata from 211.162.81.126:56266 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:54.096+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56422 #80 (31 connections now open)
2020-09-22T12:10:54.096+0800 I  NETWORK  [conn80] received client metadata from 211.162.81.126:56422 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:54.150+0800 I  NETWORK  [conn79] end connection 211.162.81.126:56266 (30 connections now open)
2020-09-22T12:10:54.150+0800 I  NETWORK  [conn80] end connection 211.162.81.126:56422 (29 connections now open)
2020-09-22T12:10:54.421+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:10:54.543+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53834 #82 (30 connections now open)
2020-09-22T12:10:54.544+0800 I  NETWORK  [conn82] received client metadata from 112.124.21.191:53834 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:54.547+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53836 #83 (31 connections now open)
2020-09-22T12:10:54.548+0800 I  NETWORK  [conn83] received client metadata from 112.124.21.191:53836 conn83: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:54.613+0800 I  NETWORK  [conn83] end connection 112.124.21.191:53836 (30 connections now open)
2020-09-22T12:10:54.975+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:10:54.975+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 8
2020-09-22T12:10:54.975+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 637 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.975+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 638 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.976+0800 I  ELECTION [replexec-4] VoteRequester(term 8 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1600747853, 9), $clusterTime: { clusterTime: Timestamp(1600747854, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747853, 9) }
2020-09-22T12:10:54.976+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 9
2020-09-22T12:10:54.976+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:54.976+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:54.977+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 639 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.977+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 640 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.978+0800 I  ELECTION [replexec-5] VoteRequester(term 9) received a yes vote from 112.124.21.191:27019; response message: { term: 9, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1600747853, 9), $clusterTime: { clusterTime: Timestamp(1600747854, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747853, 9) }
2020-09-22T12:10:54.978+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 9
2020-09-22T12:10:54.979+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:10:54.979+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:10:54.979+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:10:55.424+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53832 #84 (31 connections now open)
2020-09-22T12:10:55.424+0800 I  NETWORK  [conn84] received client metadata from 112.124.21.191:53832 conn84: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:55.979+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:10:55.979+0800 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-09-22T12:10:55.979+0800 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-09-22T12:10:55.979+0800 I  REPL     [replexec-3] Stopping replication producer
2020-09-22T12:10:55.979+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:55.979+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:10:55.979+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 9
2020-09-22T12:10:55.979+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 9
2020-09-22T12:10:55.979+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:55.979+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:55.979+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:10:55.980+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:10:55.980+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:55.981+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:55.981+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:55.981+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:55.986+0800 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-09-22T12:10:55.986+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:10:55.986+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:10:56.333+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:60036 #85 (32 connections now open)
2020-09-22T12:10:56.334+0800 I  NETWORK  [conn85] received client metadata from 120.55.192.104:60036 conn85: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:58.482+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55523 #86 (33 connections now open)
2020-09-22T12:10:58.483+0800 I  NETWORK  [conn86] received client metadata from 211.162.81.126:55523 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:58.486+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56423 #87 (34 connections now open)
2020-09-22T12:10:58.487+0800 I  NETWORK  [conn87] received client metadata from 211.162.81.126:56423 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:58.548+0800 I  NETWORK  [conn86] end connection 211.162.81.126:55523 (33 connections now open)
2020-09-22T12:10:58.549+0800 I  NETWORK  [conn87] end connection 211.162.81.126:56423 (32 connections now open)
2020-09-22T12:10:58.622+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37600 #88 (33 connections now open)
2020-09-22T12:10:58.622+0800 I  NETWORK  [conn88] received client metadata from 120.55.194.98:37600 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:00.244+0800 I  ELECTION [conn88] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:00.244+0800 I  ELECTION [conn88] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-09-22T12:11:00.246+0800 I  REPL     [conn88] stepping down from primary, because a new term has begun: 10
2020-09-22T12:11:00.246+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:00.247+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:00.247+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:11:00.247+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:11:00.247+0800 I  ELECTION [conn88] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:00.247+0800 I  ELECTION [conn88] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-09-22T12:11:00.248+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:00.249+0800 I  NETWORK  [conn88] end connection 120.55.194.98:37600 (32 connections now open)
2020-09-22T12:11:00.249+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37604 #89 (33 connections now open)
2020-09-22T12:11:00.249+0800 I  NETWORK  [conn89] received client metadata from 120.55.194.98:37604 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:00.305+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56424 #90 (34 connections now open)
2020-09-22T12:11:00.306+0800 I  NETWORK  [conn90] received client metadata from 211.162.81.126:56424 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:00.308+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55524 #91 (35 connections now open)
2020-09-22T12:11:00.310+0800 I  NETWORK  [conn91] received client metadata from 211.162.81.126:55524 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:00.366+0800 I  NETWORK  [conn90] end connection 211.162.81.126:56424 (34 connections now open)
2020-09-22T12:11:00.366+0800 I  NETWORK  [conn91] end connection 211.162.81.126:55524 (33 connections now open)
2020-09-22T12:11:00.482+0800 I  NETWORK  [conn76] end connection 120.55.194.98:37594 (32 connections now open)
2020-09-22T12:11:01.008+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:01.125+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56425 #92 (33 connections now open)
2020-09-22T12:11:01.126+0800 I  NETWORK  [conn92] received client metadata from 211.162.81.126:56425 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:01.128+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55525 #93 (34 connections now open)
2020-09-22T12:11:01.128+0800 I  NETWORK  [conn93] received client metadata from 211.162.81.126:55525 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:01.161+0800 I  NETWORK  [conn4] end connection 120.55.194.98:37502 (33 connections now open)
2020-09-22T12:11:01.178+0800 I  NETWORK  [conn92] end connection 211.162.81.126:56425 (32 connections now open)
2020-09-22T12:11:01.179+0800 I  NETWORK  [conn93] end connection 211.162.81.126:55525 (31 connections now open)
2020-09-22T12:11:01.335+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:01.335+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 10
2020-09-22T12:11:01.335+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 651 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:01.335+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 652 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:01.335+0800 I  ELECTION [replexec-4] VoteRequester(term 10 dry run) received a no vote from 112.124.21.191:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747859, 5), t: 9 }, my last applied OpTime: { ts: Timestamp(1600747860, 2), t: 10 }"; response message: { term: 10, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747859, 5), t: 9 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1600747860, 2), $clusterTime: { clusterTime: Timestamp(1600747860, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747860, 2) }
2020-09-22T12:11:01.988+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56426 #94 (32 connections now open)
2020-09-22T12:11:01.988+0800 I  NETWORK  [conn94] received client metadata from 211.162.81.126:56426 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:01.993+0800 I  ELECTION [replexec-4] VoteRequester(term 10 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747859, 5), t: 9 }, my last applied OpTime: { ts: Timestamp(1600747860, 2), t: 10 }"; response message: { term: 10, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747859, 5), t: 9 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1600747860, 2), $clusterTime: { clusterTime: Timestamp(1600747860, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747860, 2) }
2020-09-22T12:11:01.993+0800 I  ELECTION [replexec-4] not running for primary, we received insufficient votes
2020-09-22T12:11:01.993+0800 I  ELECTION [replexec-4] Lost dry run election due to internal error
2020-09-22T12:11:01.994+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55526 #97 (33 connections now open)
2020-09-22T12:11:01.995+0800 I  NETWORK  [conn97] received client metadata from 211.162.81.126:55526 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.052+0800 I  NETWORK  [conn94] end connection 211.162.81.126:56426 (32 connections now open)
2020-09-22T12:11:02.055+0800 I  NETWORK  [conn97] end connection 211.162.81.126:55526 (31 connections now open)
2020-09-22T12:11:02.248+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:11:02.249+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:11:02.249+0800 I  CONNPOOL [RS] Connecting to 112.124.21.191:27019
2020-09-22T12:11:02.483+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:02.566+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55527 #99 (32 connections now open)
2020-09-22T12:11:02.567+0800 I  NETWORK  [conn99] received client metadata from 211.162.81.126:55527 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.570+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55528 #100 (33 connections now open)
2020-09-22T12:11:02.571+0800 I  NETWORK  [conn100] received client metadata from 211.162.81.126:55528 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.631+0800 I  NETWORK  [conn99] end connection 211.162.81.126:55527 (32 connections now open)
2020-09-22T12:11:02.631+0800 I  NETWORK  [conn100] end connection 211.162.81.126:55528 (31 connections now open)
2020-09-22T12:11:03.555+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.555+0800 I  ELECTION [conn12] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-09-22T12:11:03.557+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.557+0800 I  ELECTION [conn12] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-09-22T12:11:04.483+0800 I  REPL     [replexec-6] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:11:04.483+0800 I  ELECTION [replexec-6] Scheduling priority takeover at 2020-09-22T12:11:06.498+0800
2020-09-22T12:11:04.684+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:05.759+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37608 #101 (32 connections now open)
2020-09-22T12:11:05.759+0800 I  NETWORK  [conn101] received client metadata from 120.55.194.98:37608 conn101: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:05.762+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37610 #102 (33 connections now open)
2020-09-22T12:11:05.762+0800 I  NETWORK  [conn102] received client metadata from 120.55.194.98:37610 conn102: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:05.891+0800 I  NETWORK  [conn102] end connection 120.55.194.98:37610 (32 connections now open)
2020-09-22T12:11:06.076+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56428 #103 (33 connections now open)
2020-09-22T12:11:06.077+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56427 #104 (34 connections now open)
2020-09-22T12:11:06.078+0800 I  NETWORK  [conn103] received client metadata from 211.162.81.126:56428 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:06.078+0800 I  NETWORK  [conn104] received client metadata from 211.162.81.126:56427 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:06.133+0800 I  NETWORK  [conn103] end connection 211.162.81.126:56428 (33 connections now open)
2020-09-22T12:11:06.134+0800 I  NETWORK  [conn104] end connection 211.162.81.126:56427 (32 connections now open)
2020-09-22T12:11:06.498+0800 I  REPL     [replexec-6] Canceling priority takeover callback
2020-09-22T12:11:06.498+0800 I  ELECTION [replexec-6] Starting an election for a priority takeover
2020-09-22T12:11:06.498+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 11
2020-09-22T12:11:06.498+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 697 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.498+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 698 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.498+0800 I  ELECTION [replexec-1] VoteRequester(term 11 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1600747865, 1), $clusterTime: { clusterTime: Timestamp(1600747866, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747865, 1) }
2020-09-22T12:11:06.499+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 12
2020-09-22T12:11:06.499+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:06.500+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 699 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.500+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 700 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.502+0800 I  ELECTION [replexec-6] VoteRequester(term 12) received a yes vote from 120.55.194.98:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1600747865, 1), $clusterTime: { clusterTime: Timestamp(1600747866, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747865, 1) }
2020-09-22T12:11:06.502+0800 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 12
2020-09-22T12:11:06.502+0800 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-09-22T12:11:06.502+0800 I  REPL     [replexec-6] Resetting sync source to empty, which was 112.124.21.191:27019
2020-09-22T12:11:06.502+0800 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-09-22T12:11:06.502+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:11:06.502+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:06.503+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:06.503+0800 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747865, 1), t: 11 }. My Last Applied: { ts: Timestamp(1600747865, 1), t: 11 }
2020-09-22T12:11:06.503+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:11:06.503+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:11:06.503+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 12
2020-09-22T12:11:06.503+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:06.504+0800 I  CONNPOOL [RS] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:06.504+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:06.504+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:06.504+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:11:06.505+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:06.505+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:06.506+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:06.506+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:06.506+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:06.508+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:06.508+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:06.600+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:11:08.953+0800 I  ELECTION [conn89] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:08.953+0800 I  ELECTION [conn89] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-09-22T12:11:08.955+0800 I  REPL     [conn89] stepping down from primary, because a new term has begun: 13
2020-09-22T12:11:08.955+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:08.955+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:08.955+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:11:08.955+0800 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-09-22T12:11:08.956+0800 I  ELECTION [conn89] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:08.956+0800 I  ELECTION [conn89] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-09-22T12:11:08.956+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:08.957+0800 I  NETWORK  [conn89] end connection 120.55.194.98:37604 (31 connections now open)
2020-09-22T12:11:08.957+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37612 #106 (32 connections now open)
2020-09-22T12:11:08.957+0800 I  NETWORK  [conn106] received client metadata from 120.55.194.98:37612 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:09.010+0800 I  NETWORK  [conn101] end connection 120.55.194.98:37608 (31 connections now open)
2020-09-22T12:11:09.926+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55529 #107 (32 connections now open)
2020-09-22T12:11:09.927+0800 I  NETWORK  [conn107] received client metadata from 211.162.81.126:55529 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:09.928+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56429 #108 (33 connections now open)
2020-09-22T12:11:09.929+0800 I  NETWORK  [conn108] received client metadata from 211.162.81.126:56429 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:09.994+0800 I  NETWORK  [conn107] end connection 211.162.81.126:55529 (32 connections now open)
2020-09-22T12:11:09.994+0800 I  NETWORK  [conn108] end connection 211.162.81.126:56429 (31 connections now open)
2020-09-22T12:11:10.087+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:10.087+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 13
2020-09-22T12:11:10.087+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 708 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:10.087+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 709 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:10.087+0800 I  ELECTION [replexec-4] VoteRequester(term 13 dry run) received a no vote from 112.124.21.191:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747866, 7), t: 12 }, my last applied OpTime: { ts: Timestamp(1600747869, 11), t: 13 }"; response message: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747866, 7), t: 12 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1600747869, 11), $clusterTime: { clusterTime: Timestamp(1600747869, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747869, 11) }
2020-09-22T12:11:10.087+0800 I  ELECTION [replexec-0] VoteRequester(term 13 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747866, 7), t: 12 }, my last applied OpTime: { ts: Timestamp(1600747869, 11), t: 13 }"; response message: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747866, 7), t: 12 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000d') }, lastCommittedOpTime: Timestamp(1600747869, 11), $clusterTime: { clusterTime: Timestamp(1600747869, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747869, 11) }
2020-09-22T12:11:10.088+0800 I  ELECTION [replexec-0] not running for primary, we received insufficient votes
2020-09-22T12:11:10.088+0800 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-09-22T12:11:10.502+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:10.957+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:11:10.958+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:11:10.958+0800 I  CONNPOOL [RS] Connecting to 112.124.21.191:27019
2020-09-22T12:11:10.962+0800 I  COMMAND  [conn23] command config.settings command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747869, 1), t: 13 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747869, 1), signature: { hash: BinData(0, 963A59D77EC7296A2ACDC4B2ACA90C0C2101FB02), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747869, 1), t: 13 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 1706ms
2020-09-22T12:11:10.962+0800 I  COMMAND  [conn85] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747869, 11), t: 13 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747869, 11), signature: { hash: BinData(0, 963A59D77EC7296A2ACDC4B2ACA90C0C2101FB02), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747869, 11), t: 13 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 974ms
2020-09-22T12:11:10.963+0800 I  COMMAND  [conn37] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1616299817, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747869, 1), t: 13 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747869, 14), signature: { hash: BinData(0, 963A59D77EC7296A2ACDC4B2ACA90C0C2101FB02), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747869, 1), t: 13 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 hasSortStage:1 cursorExhausted:1 numYields:0 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 342ms
2020-09-22T12:11:11.705+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56430 #110 (32 connections now open)
2020-09-22T12:11:11.705+0800 I  NETWORK  [conn110] received client metadata from 211.162.81.126:56430 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:11.706+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55530 #111 (33 connections now open)
2020-09-22T12:11:11.706+0800 I  NETWORK  [conn111] received client metadata from 211.162.81.126:55530 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:11.761+0800 I  NETWORK  [conn110] end connection 211.162.81.126:56430 (32 connections now open)
2020-09-22T12:11:11.762+0800 I  NETWORK  [conn111] end connection 211.162.81.126:55530 (31 connections now open)
2020-09-22T12:11:13.627+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55531 #112 (32 connections now open)
2020-09-22T12:11:13.628+0800 I  NETWORK  [conn112] received client metadata from 211.162.81.126:55531 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:13.628+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56431 #113 (33 connections now open)
2020-09-22T12:11:13.629+0800 I  NETWORK  [conn113] received client metadata from 211.162.81.126:56431 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:13.693+0800 I  NETWORK  [conn112] end connection 211.162.81.126:55531 (32 connections now open)
2020-09-22T12:11:13.693+0800 I  NETWORK  [conn113] end connection 211.162.81.126:56431 (31 connections now open)
2020-09-22T12:11:14.179+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:14.226+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55532 #114 (32 connections now open)
2020-09-22T12:11:14.226+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56432 #115 (33 connections now open)
2020-09-22T12:11:14.226+0800 I  NETWORK  [conn114] received client metadata from 211.162.81.126:55532 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.226+0800 I  NETWORK  [conn115] received client metadata from 211.162.81.126:56432 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.291+0800 I  NETWORK  [conn114] end connection 211.162.81.126:55532 (32 connections now open)
2020-09-22T12:11:14.291+0800 I  NETWORK  [conn115] end connection 211.162.81.126:56432 (31 connections now open)
2020-09-22T12:11:14.806+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55533 #116 (32 connections now open)
2020-09-22T12:11:14.807+0800 I  NETWORK  [conn116] received client metadata from 211.162.81.126:55533 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.808+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56433 #117 (33 connections now open)
2020-09-22T12:11:14.809+0800 I  NETWORK  [conn117] received client metadata from 211.162.81.126:56433 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.864+0800 I  NETWORK  [conn116] end connection 211.162.81.126:55533 (32 connections now open)
2020-09-22T12:11:14.865+0800 I  NETWORK  [conn117] end connection 211.162.81.126:56433 (31 connections now open)
2020-09-22T12:11:16.685+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56434 #118 (32 connections now open)
2020-09-22T12:11:16.686+0800 I  NETWORK  [conn118] received client metadata from 211.162.81.126:56434 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:16.687+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55534 #119 (33 connections now open)
2020-09-22T12:11:16.687+0800 I  NETWORK  [conn119] received client metadata from 211.162.81.126:55534 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:16.746+0800 I  NETWORK  [conn118] end connection 211.162.81.126:56434 (32 connections now open)
2020-09-22T12:11:16.747+0800 I  NETWORK  [conn119] end connection 211.162.81.126:55534 (31 connections now open)
2020-09-22T12:11:17.779+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.779+0800 I  ELECTION [conn12] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-09-22T12:11:17.781+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.781+0800 I  ELECTION [conn12] Sending vote response: { term: 14, voteGranted: true, reason: "" }
2020-09-22T12:11:18.004+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:18.004+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:18.004+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 764 timed out, deadline was 2020-09-22T12:11:18.004+0800, op was RemoteCommand 764 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:11:18.004+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "120.55.192.104:27019", fromId: 1, term: 13 }
2020-09-22T12:11:18.589+0800 I  NETWORK  [conn106] end connection 120.55.194.98:37612 (30 connections now open)
2020-09-22T12:11:18.958+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37618 #120 (31 connections now open)
2020-09-22T12:11:18.958+0800 I  NETWORK  [conn120] received client metadata from 120.55.194.98:37618 conn120: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:19.003+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:11:19.003+0800 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-09-22T12:11:21.074+0800
2020-09-22T12:11:19.010+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55535 #122 (32 connections now open)
2020-09-22T12:11:19.011+0800 I  NETWORK  [conn122] received client metadata from 211.162.81.126:55535 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.011+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56435 #123 (33 connections now open)
2020-09-22T12:11:19.012+0800 I  NETWORK  [conn123] received client metadata from 211.162.81.126:56435 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.068+0800 I  NETWORK  [conn123] end connection 211.162.81.126:56435 (32 connections now open)
2020-09-22T12:11:19.068+0800 I  NETWORK  [conn122] end connection 211.162.81.126:55535 (31 connections now open)
2020-09-22T12:11:19.409+0800 I  NETWORK  [conn22] end connection 120.55.194.98:37518 (30 connections now open)
2020-09-22T12:11:19.410+0800 I  NETWORK  [conn25] end connection 47.96.16.32:38084 (29 connections now open)
2020-09-22T12:11:19.586+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56436 #124 (30 connections now open)
2020-09-22T12:11:19.586+0800 I  NETWORK  [conn124] received client metadata from 211.162.81.126:56436 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.588+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56437 #125 (31 connections now open)
2020-09-22T12:11:19.589+0800 I  NETWORK  [conn125] received client metadata from 211.162.81.126:56437 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.642+0800 I  NETWORK  [conn124] end connection 211.162.81.126:56436 (30 connections now open)
2020-09-22T12:11:19.643+0800 I  NETWORK  [conn125] end connection 211.162.81.126:56437 (29 connections now open)
2020-09-22T12:11:19.778+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37620 #126 (30 connections now open)
2020-09-22T12:11:19.780+0800 I  NETWORK  [conn126] received client metadata from 120.55.194.98:37620 conn126: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:20.004+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:20.926+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55536 #127 (31 connections now open)
2020-09-22T12:11:20.926+0800 I  NETWORK  [conn127] received client metadata from 211.162.81.126:55536 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:20.929+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56438 #128 (32 connections now open)
2020-09-22T12:11:20.929+0800 I  NETWORK  [conn128] received client metadata from 211.162.81.126:56438 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:20.981+0800 I  NETWORK  [conn127] end connection 211.162.81.126:55536 (31 connections now open)
2020-09-22T12:11:20.982+0800 I  NETWORK  [conn128] end connection 211.162.81.126:56438 (30 connections now open)
2020-09-22T12:11:21.074+0800 I  REPL     [replexec-4] Canceling priority takeover callback
2020-09-22T12:11:21.074+0800 I  ELECTION [replexec-4] Starting an election for a priority takeover
2020-09-22T12:11:21.074+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 14
2020-09-22T12:11:21.074+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 808 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.074+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 809 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.074+0800 I  ELECTION [replexec-2] VoteRequester(term 14 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000e') }, lastCommittedOpTime: Timestamp(1600747880, 82), $clusterTime: { clusterTime: Timestamp(1600747880, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747880, 82) }
2020-09-22T12:11:21.074+0800 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 15
2020-09-22T12:11:21.075+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:21.075+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:21.076+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 810 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.076+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 811 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.078+0800 I  ELECTION [replexec-4] VoteRequester(term 15) received a yes vote from 120.55.194.98:27019; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000d') }, lastCommittedOpTime: Timestamp(1600747880, 82), $clusterTime: { clusterTime: Timestamp(1600747880, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747880, 82) }
2020-09-22T12:11:21.078+0800 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 15
2020-09-22T12:11:21.078+0800 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-09-22T12:11:21.078+0800 I  REPL     [replexec-4] Resetting sync source to empty, which was 112.124.21.191:27019
2020-09-22T12:11:21.078+0800 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-09-22T12:11:21.078+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:11:21.078+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:21.080+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:21.080+0800 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747880, 82), t: 14 }. My Last Applied: { ts: Timestamp(1600747880, 82), t: 14 }
2020-09-22T12:11:21.080+0800 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-09-22T12:11:21.080+0800 I  REPL     [replexec-0] Stopping replication producer
2020-09-22T12:11:21.080+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 15
2020-09-22T12:11:21.080+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 15
2020-09-22T12:11:21.080+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:21.080+0800 I  CONNPOOL [RS] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:21.080+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:21.080+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:21.080+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:11:21.081+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:21.081+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:21.082+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:21.082+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:21.083+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:21.083+0800 I  CONNPOOL [ShardRegistry] Connecting to 47.96.5.198:27018
2020-09-22T12:11:21.085+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:21.085+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:21.471+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:11:22.984+0800 I  ELECTION [conn120] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:22.984+0800 I  ELECTION [conn120] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-09-22T12:11:22.986+0800 I  REPL     [conn120] stepping down from primary, because a new term has begun: 16
2020-09-22T12:11:22.987+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:22.987+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:22.987+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:11:22.987+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:11:22.987+0800 I  ELECTION [conn120] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:22.987+0800 I  ELECTION [conn120] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-09-22T12:11:22.988+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:22.989+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37624 #132 (31 connections now open)
2020-09-22T12:11:22.989+0800 I  NETWORK  [conn132] received client metadata from 120.55.194.98:37624 conn132: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:22.990+0800 I  NETWORK  [conn120] end connection 120.55.194.98:37618 (30 connections now open)
2020-09-22T12:11:23.025+0800 I  NETWORK  [conn39] end connection 118.31.43.238:37078 (29 connections now open)
2020-09-22T12:11:23.026+0800 I  NETWORK  [conn38] end connection 47.96.16.32:38100 (28 connections now open)
2020-09-22T12:11:23.039+0800 I  NETWORK  [conn41] end connection 47.96.5.198:60370 (27 connections now open)
2020-09-22T12:11:23.043+0800 I  NETWORK  [conn42] end connection 47.96.5.198:60376 (26 connections now open)
2020-09-22T12:11:23.079+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:23.103+0800 I  NETWORK  [conn75] end connection 120.55.194.98:37592 (25 connections now open)
2020-09-22T12:11:23.154+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56439 #133 (26 connections now open)
2020-09-22T12:11:23.155+0800 I  NETWORK  [conn133] received client metadata from 211.162.81.126:56439 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:23.156+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55537 #134 (27 connections now open)
2020-09-22T12:11:23.156+0800 I  NETWORK  [conn134] received client metadata from 211.162.81.126:55537 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:23.211+0800 I  NETWORK  [conn133] end connection 211.162.81.126:56439 (26 connections now open)
2020-09-22T12:11:23.212+0800 I  NETWORK  [conn134] end connection 211.162.81.126:55537 (25 connections now open)
2020-09-22T12:11:23.988+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:24.205+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.205+0800 I  ELECTION [conn12] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-09-22T12:11:24.207+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.207+0800 I  ELECTION [conn12] Sending vote response: { term: 17, voteGranted: true, reason: "" }
2020-09-22T12:11:24.579+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:24.579+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:24.579+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 819 timed out, deadline was 2020-09-22T12:11:24.579+0800, op was RemoteCommand 819 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:11:24.579+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "120.55.192.104:27019", fromId: 1, term: 16 }
2020-09-22T12:11:25.336+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:25.336+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 17
2020-09-22T12:11:25.336+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 823 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:25.336+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 824 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:25.336+0800 I  ELECTION [replexec-3] VoteRequester(term 17 dry run) received a no vote from 112.124.21.191:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747881, 3), t: 15 }, my last applied OpTime: { ts: Timestamp(1600747884, 10), t: 17 }"; response message: { term: 17, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747881, 3), t: 15 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000011') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747884, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747884, 10) }
2020-09-22T12:11:25.577+0800 I  ELECTION [replexec-6] VoteRequester(term 17 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747881, 3), t: 15 }, my last applied OpTime: { ts: Timestamp(1600747883, 3), t: 16 }"; response message: { term: 17, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747881, 3), t: 15 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000010') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747884, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747883, 3) }
2020-09-22T12:11:25.577+0800 I  ELECTION [replexec-6] not running for primary, we received insufficient votes
2020-09-22T12:11:25.577+0800 I  ELECTION [replexec-6] Lost dry run election due to internal error
2020-09-22T12:11:25.621+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:25.621+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:11:25.624+0800 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747883, 3), t: 16 }, latest oplog optime of sync source: { ts: Timestamp(1600747883, 3), t: 16 } (sync source does not know the primary)
2020-09-22T12:11:25.624+0800 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747883, 3), t: 16 }, its sync source index:-1
2020-09-22T12:11:25.624+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747883, 3), t: 16 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:25.624+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:11:25.624+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:25.624+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:25.656+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55538 #137 (26 connections now open)
2020-09-22T12:11:25.656+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56440 #138 (27 connections now open)
2020-09-22T12:11:25.656+0800 I  NETWORK  [conn137] received client metadata from 211.162.81.126:55538 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:25.657+0800 I  NETWORK  [conn138] received client metadata from 211.162.81.126:56440 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:25.714+0800 I  NETWORK  [conn137] end connection 211.162.81.126:55538 (26 connections now open)
2020-09-22T12:11:25.715+0800 I  NETWORK  [conn138] end connection 211.162.81.126:56440 (25 connections now open)
2020-09-22T12:11:26.100+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55539 #139 (26 connections now open)
2020-09-22T12:11:26.101+0800 I  NETWORK  [conn139] received client metadata from 211.162.81.126:55539 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.101+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56441 #140 (27 connections now open)
2020-09-22T12:11:26.102+0800 I  NETWORK  [conn140] received client metadata from 211.162.81.126:56441 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.124+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:26.126+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37628 #141 (28 connections now open)
2020-09-22T12:11:26.126+0800 I  NETWORK  [conn141] received client metadata from 120.55.194.98:37628 conn141: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.147+0800 I  NETWORK  [conn139] end connection 211.162.81.126:55539 (27 connections now open)
2020-09-22T12:11:26.157+0800 I  NETWORK  [conn140] end connection 211.162.81.126:56441 (26 connections now open)
2020-09-22T12:11:26.351+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.351+0800 I  ELECTION [conn12] Sending vote response: { term: 17, voteGranted: true, reason: "" }
2020-09-22T12:11:26.355+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.355+0800 I  ELECTION [conn12] Sending vote response: { term: 18, voteGranted: true, reason: "" }
2020-09-22T12:11:26.448+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56442 #142 (27 connections now open)
2020-09-22T12:11:26.449+0800 I  NETWORK  [conn142] received client metadata from 211.162.81.126:56442 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.449+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55540 #143 (28 connections now open)
2020-09-22T12:11:26.450+0800 I  NETWORK  [conn143] received client metadata from 211.162.81.126:55540 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.523+0800 I  NETWORK  [conn142] end connection 211.162.81.126:56442 (27 connections now open)
2020-09-22T12:11:26.524+0800 I  NETWORK  [conn143] end connection 211.162.81.126:55540 (26 connections now open)
2020-09-22T12:11:26.624+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:11:26.624+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state ROLLBACK
2020-09-22T12:11:26.625+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:11:26.625+0800 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-09-22T12:11:28.726+0800
2020-09-22T12:11:26.625+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:11:26.625+0800 I  CONNPOOL [RS] Connecting to 112.124.21.191:27019
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1600747883, 3), t: 16 }. source's GTE: { ts: Timestamp(1600747884, 3), t: 17 }
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1600747881, 3), t: 15 }
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: 112.124.21.191:27019)
2020-09-22T12:11:26.626+0800 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 27 }
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-09-22T12:11:26.626+0800 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 141
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 132
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 126
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 85
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 84
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 18
2020-09-22T12:11:26.626+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 12
2020-09-22T12:11:26.626+0800 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-09-22T12:11:26.626+0800 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-09-22T12:11:26.626+0800 I  ROLLBACK [rsBackgroundSync] finding common point
2020-09-22T12:11:28.104+0800 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1600747881, 3), t: 15 }
2020-09-22T12:11:28.106+0800 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-09-22T12:11:28.106+0800 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-09-22T12:11:28.106+0800 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 990ea228-4f92-4ac6-83ef-83a3dd549ffd to /var/lib/mongodb/rollback/config.lockpings/removed.2020-09-22T04-11-28.0.bson
2020-09-22T12:11:28.106+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-09-22T12:11:28.106+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-09-22T12:11:28.106+0800 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-09-22T12:11:28.107+0800 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-09-22T12:11:28.117+0800 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1600747881, 3) Initial Data Timestamp: Timestamp(1600747816, 1)
2020-09-22T12:11:28.117+0800 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-09-22T12:11:28.123+0800 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-09-22T12:11:28.123+0800 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 191 records totaling to 42408 bytes
2020-09-22T12:11:28.123+0800 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:11:28.124+0800 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-09-22T12:11:28.126+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-09-22T12:11:28.126+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-09-22T12:11:28.135+0800 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-09-22T12:11:28.135+0800 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-09-22T12:11:28.135+0800 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1600747881, 3)
2020-09-22T12:11:28.135+0800 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 3 update operations and 0 delete operations.
2020-09-22T12:11:28.135+0800 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1600747882, 12), t: 16 }
2020-09-22T12:11:28.136+0800 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1600747882, 12) }
2020-09-22T12:11:28.136+0800 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1600747881, 3) (top of oplog: { ts: Timestamp(1600747881, 3), t: 15 }, appliedThrough: { ts: Timestamp(1600747881, 3), t: 15 }, TruncateAfter: Timestamp(0, 0))
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1600747881, 3)
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-09-22T12:11:26.626+0800
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-09-22T12:11:28.137+0800
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	sync source: 112.124.21.191:27019
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1600747883, 3), t: 16 }
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1600747881, 3), t: 15 }
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-09-22T12:11:23.555+0800
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-09-22T12:11:22.992+0800
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1600747882, 12)
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1600747881, 3)
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 		update: 3
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 4
2020-09-22T12:11:28.137+0800 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was 112.124.21.191:27019
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Rollback successful.
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-09-22T12:11:28.137+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:11:28.138+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:11:28.624+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:28.625+0800 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-09-22T12:11:30.719+0800
2020-09-22T12:11:29.399+0800 I  ELECTION [conn132] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 18, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:29.399+0800 I  ELECTION [conn132] Sending vote response: { term: 18, voteGranted: true, reason: "" }
2020-09-22T12:11:29.401+0800 I  REPL     [conn132] Canceling priority takeover callback
2020-09-22T12:11:29.401+0800 I  ELECTION [conn132] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 19, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:29.401+0800 I  ELECTION [conn132] Sending vote response: { term: 19, voteGranted: true, reason: "" }
2020-09-22T12:11:29.519+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55541 #146 (27 connections now open)
2020-09-22T12:11:29.519+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56443 #147 (28 connections now open)
2020-09-22T12:11:29.520+0800 I  NETWORK  [conn147] received client metadata from 211.162.81.126:56443 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:29.520+0800 I  NETWORK  [conn146] received client metadata from 211.162.81.126:55541 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:29.587+0800 I  NETWORK  [conn147] end connection 211.162.81.126:56443 (27 connections now open)
2020-09-22T12:11:29.587+0800 I  NETWORK  [conn146] end connection 211.162.81.126:55541 (26 connections now open)
2020-09-22T12:11:29.642+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 112.124.21.191:27019, my last fetched oplog optime: { ts: Timestamp(1600747887, 5), t: 18 }, latest oplog optime of sync source: { ts: Timestamp(1600747887, 5), t: 18 } (sync source does not know the primary)
2020-09-22T12:11:29.642+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 112.124.21.191:27019, OpTime { ts: Timestamp(1600747887, 5), t: 18 }, its sync source index:-1
2020-09-22T12:11:29.642+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 112.124.21.191:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747887, 5), t: 18 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:29.642+0800 I  REPL     [rsBackgroundSync] Clearing sync source 112.124.21.191:27019 to choose a new one.
2020-09-22T12:11:29.642+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:29.643+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:29.643+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:30.142+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:11:30.642+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:30.646+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:30.649+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747889, 2), t: 19 }, latest oplog optime of sync source: { ts: Timestamp(1600747889, 2), t: 19 } (sync source does not know the primary)
2020-09-22T12:11:30.649+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747889, 2), t: 19 }, its sync source index:-1
2020-09-22T12:11:30.649+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747889, 2), t: 19 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:30.649+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:11:30.649+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:30.649+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:30.649+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:11:30.649+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:30.649+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:30.651+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:30.662+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:30.662+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 19
2020-09-22T12:11:30.662+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 874 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747889, 2), t: 19 } }
2020-09-22T12:11:30.662+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 875 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747889, 2), t: 19 } }
2020-09-22T12:11:30.662+0800 I  ELECTION [replexec-0] VoteRequester(term 19 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 19, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000013') }, lastCommittedOpTime: Timestamp(1600747887, 5), $clusterTime: { clusterTime: Timestamp(1600747890, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747889, 2) }
2020-09-22T12:11:30.662+0800 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 20
2020-09-22T12:11:30.663+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 876 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747889, 2), t: 19 } }
2020-09-22T12:11:30.663+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 877 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747889, 2), t: 19 } }
2020-09-22T12:11:30.665+0800 I  ELECTION [replexec-2] VoteRequester(term 20) received a yes vote from 112.124.21.191:27019; response message: { term: 20, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000012') }, lastCommittedOpTime: Timestamp(1600747887, 5), $clusterTime: { clusterTime: Timestamp(1600747890, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747887, 5) }
2020-09-22T12:11:30.665+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 20
2020-09-22T12:11:30.665+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:11:30.665+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:11:30.665+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:11:30.665+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:30.667+0800 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747889, 2), t: 19 }. My Last Applied: { ts: Timestamp(1600747889, 2), t: 19 }
2020-09-22T12:11:30.667+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:11:30.667+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:11:30.667+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 20
2020-09-22T12:11:30.667+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 20
2020-09-22T12:11:30.667+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:30.667+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:30.667+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:30.668+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:30.668+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:30.669+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:30.669+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:30.669+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:30.669+0800 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:30.671+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:30.764+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:30.764+0800 I  ELECTION [conn12] Sending vote response: { term: 20, voteGranted: false, reason: "candidate's term (19) is lower than mine (20)" }
2020-09-22T12:11:30.974+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37644 #151 (27 connections now open)
2020-09-22T12:11:30.975+0800 I  NETWORK  [conn151] received client metadata from 120.55.194.98:37644 conn151: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:31.148+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:31.150+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60502 #152 (28 connections now open)
2020-09-22T12:11:31.150+0800 I  NETWORK  [conn152] received client metadata from 47.96.5.198:60502 conn152: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:31.407+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:31.407+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:31.407+0800 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 577ms
2020-09-22T12:11:31.407+0800 I  COMMAND  [conn85] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 577ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 574ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 569ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 536ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn32] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-02:27017" }, u: { $set: { _id: "Jepsen-Node-02:27017", ping: new Date(1600747890973), up: 69, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 434ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn151] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "iZbp157vvbma2xfbxku74xZ:27017" }, u: { $set: { _id: "iZbp157vvbma2xfbxku74xZ:27017", ping: new Date(1600747890973), up: 69, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 432ms
2020-09-22T12:11:31.408+0800 I  COMMAND  [conn19] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 3), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 259ms
2020-09-22T12:11:31.409+0800 I  COMMAND  [conn152] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747890, 3), signature: { hash: BinData(0, 292ABAAA8B3832AC42CB09CB50A5D02A90892744), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747887, 5), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 257ms
2020-09-22T12:11:31.427+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53872 #153 (29 connections now open)
2020-09-22T12:11:31.428+0800 I  NETWORK  [conn153] received client metadata from 112.124.21.191:53872 conn153: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:31.760+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55542 #155 (30 connections now open)
2020-09-22T12:11:31.760+0800 I  NETWORK  [conn155] received client metadata from 211.162.81.126:55542 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:31.761+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55543 #156 (31 connections now open)
2020-09-22T12:11:31.762+0800 I  NETWORK  [conn156] received client metadata from 211.162.81.126:55543 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:31.823+0800 I  NETWORK  [conn156] end connection 211.162.81.126:55543 (30 connections now open)
2020-09-22T12:11:31.826+0800 I  NETWORK  [conn155] end connection 211.162.81.126:55542 (29 connections now open)
2020-09-22T12:11:33.709+0800 I  ELECTION [conn132] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 20, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747892, 1), t: 20 } }
2020-09-22T12:11:33.709+0800 I  ELECTION [conn132] Sending vote response: { term: 20, voteGranted: true, reason: "" }
2020-09-22T12:11:33.711+0800 I  REPL     [conn132] stepping down from primary, because a new term has begun: 21
2020-09-22T12:11:33.712+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:33.712+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:33.712+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:11:33.712+0800 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-09-22T12:11:33.712+0800 I  ELECTION [conn132] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 21, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747892, 1), t: 20 } }
2020-09-22T12:11:33.712+0800 I  ELECTION [conn132] Sending vote response: { term: 21, voteGranted: true, reason: "" }
2020-09-22T12:11:33.713+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:34.063+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55544 #157 (30 connections now open)
2020-09-22T12:11:34.063+0800 I  NETWORK  [conn157] received client metadata from 211.162.81.126:55544 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:34.064+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55545 #158 (31 connections now open)
2020-09-22T12:11:34.064+0800 I  NETWORK  [conn158] received client metadata from 211.162.81.126:55545 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:34.118+0800 I  NETWORK  [conn158] end connection 211.162.81.126:55545 (30 connections now open)
2020-09-22T12:11:34.118+0800 I  NETWORK  [conn157] end connection 211.162.81.126:55544 (29 connections now open)
2020-09-22T12:11:34.667+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:34.713+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:34.714+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:35.904+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56445 #159 (30 connections now open)
2020-09-22T12:11:35.905+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56444 #160 (31 connections now open)
2020-09-22T12:11:35.905+0800 I  NETWORK  [conn159] received client metadata from 211.162.81.126:56445 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:35.905+0800 I  NETWORK  [conn160] received client metadata from 211.162.81.126:56444 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:35.960+0800 I  NETWORK  [conn159] end connection 211.162.81.126:56445 (30 connections now open)
2020-09-22T12:11:35.961+0800 I  NETWORK  [conn160] end connection 211.162.81.126:56444 (29 connections now open)
2020-09-22T12:11:39.827+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55546 #161 (30 connections now open)
2020-09-22T12:11:39.827+0800 I  NETWORK  [conn161] received client metadata from 211.162.81.126:55546 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:39.830+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56446 #162 (31 connections now open)
2020-09-22T12:11:39.830+0800 I  NETWORK  [conn162] received client metadata from 211.162.81.126:56446 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:39.886+0800 I  NETWORK  [conn161] end connection 211.162.81.126:55546 (30 connections now open)
2020-09-22T12:11:39.888+0800 I  NETWORK  [conn162] end connection 211.162.81.126:56446 (29 connections now open)
2020-09-22T12:11:40.612+0800 I  ELECTION [conn153] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.612+0800 I  ELECTION [conn153] Sending vote response: { term: 21, voteGranted: true, reason: "" }
2020-09-22T12:11:40.614+0800 I  ELECTION [conn153] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.614+0800 I  ELECTION [conn153] Sending vote response: { term: 22, voteGranted: true, reason: "" }
2020-09-22T12:11:41.165+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:11:41.165+0800 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-09-22T12:11:43.303+0800
2020-09-22T12:11:42.167+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:42.167+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:42.167+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 935 timed out, deadline was 2020-09-22T12:11:42.167+0800, op was RemoteCommand 935 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:11:42.167+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "120.55.192.104:27019", fromId: 1, term: 22 }
2020-09-22T12:11:42.284+0800 I  REPL     [replexec-3] Canceling priority takeover callback
2020-09-22T12:11:42.284+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:42.284+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 22
2020-09-22T12:11:42.284+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 936 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:42.284+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 937 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:42.284+0800 I  ELECTION [replexec-4] VoteRequester(term 22 dry run) received a no vote from 112.124.21.191:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timestamp(1600747901, 1), t: 22 }"; response message: { term: 22, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000016') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747901, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747901, 1) }
2020-09-22T12:11:43.165+0800 I  REPL     [replexec-5] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:43.239+0800 I  ELECTION [conn153] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.239+0800 I  ELECTION [conn153] Sending vote response: { term: 22, voteGranted: true, reason: "" }
2020-09-22T12:11:43.241+0800 I  ELECTION [conn153] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.241+0800 I  ELECTION [conn153] Sending vote response: { term: 23, voteGranted: true, reason: "" }
2020-09-22T12:11:43.284+0800 I  ELECTION [replexec-6] VoteRequester(term 22 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:11:43.284+0800 I  ELECTION [replexec-6] not running for primary, we have been superseded already during dry run. original term: 22, current term: 23
2020-09-22T12:11:43.284+0800 I  ELECTION [replexec-6] Lost dry run election due to internal error
2020-09-22T12:11:44.361+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:44.361+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 23
2020-09-22T12:11:44.361+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 940 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:44.361+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 941 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:44.361+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:44.361+0800 I  ELECTION [replexec-1] VoteRequester(term 23 dry run) received a no vote from 112.124.21.191:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timestamp(1600747904, 1), t: 23 }"; response message: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000017') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747904, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747904, 1) }
2020-09-22T12:11:44.926+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56447 #163 (30 connections now open)
2020-09-22T12:11:44.926+0800 I  NETWORK  [conn163] received client metadata from 211.162.81.126:56447 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:44.930+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56448 #164 (31 connections now open)
2020-09-22T12:11:44.930+0800 I  NETWORK  [conn164] received client metadata from 211.162.81.126:56448 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:44.988+0800 I  NETWORK  [conn163] end connection 211.162.81.126:56447 (30 connections now open)
2020-09-22T12:11:44.989+0800 I  NETWORK  [conn164] end connection 211.162.81.126:56448 (29 connections now open)
2020-09-22T12:11:45.053+0800 I  NETWORK  [conn132] end connection 120.55.194.98:37624 (28 connections now open)
2020-09-22T12:11:45.074+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:45.074+0800 I  REPL     [replication-1] Restarting oplog query due to error: NetworkInterfaceExceededTimeLimit: error in fetcher batch callback :: caused by :: Request 932 timed out, deadline was 2020-09-22T12:11:45.074+0800, op was RemoteCommand 932 -- target:[120.55.194.98:27019] db:local expDate:2020-09-22T12:11:45.074+0800 cmd:{ getMore: 3338622486990688920, collection: "oplog.rs", batchSize: 13981010, maxTimeMS: 500, term: 21, lastKnownCommittedOpTime: { ts: Timestamp(1600747897, 14), t: 21 } }. Last fetched optime: { ts: Timestamp(1600747897, 14), t: 21 }. Restarts remaining: 1
2020-09-22T12:11:45.074+0800 I  REPL     [replication-1] Scheduled new oplog query Fetcher source: 120.55.194.98:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1600747897, 14) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 23, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 942 -- target:120.55.194.98:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1600747897, 14) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 23, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-09-22T12:11:45.076+0800 I  REPL     [replication-0] Error returned from oplog query (no more query restarts left): StaleTerm: error in fetcher batch callback :: caused by :: Replication term of this node was stale; retry query
2020-09-22T12:11:45.076+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: StaleTerm: error in fetcher batch callback :: caused by :: Replication term of this node was stale; retry query
2020-09-22T12:11:45.076+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:11:45.076+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:11:45.077+0800 I  REPL     [rsBackgroundSync] Changed sync source from 120.55.194.98:27019 to 112.124.21.191:27019
2020-09-22T12:11:45.079+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 112.124.21.191:27019, my last fetched oplog optime: { ts: Timestamp(1600747904, 1), t: 23 }, latest oplog optime of sync source: { ts: Timestamp(1600747904, 1), t: 23 } (sync source does not know the primary)
2020-09-22T12:11:45.079+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 112.124.21.191:27019, OpTime { ts: Timestamp(1600747904, 1), t: 23 }, its sync source index:-1
2020-09-22T12:11:45.080+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 112.124.21.191:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747904, 1), t: 23 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:45.080+0800 I  REPL     [rsBackgroundSync] Clearing sync source 112.124.21.191:27019 to choose a new one.
2020-09-22T12:11:45.080+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:45.169+0800 I  ELECTION [replexec-1] VoteRequester(term 23 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 23, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747904, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747897, 14) }
2020-09-22T12:11:45.169+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 24
2020-09-22T12:11:45.171+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 949 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 24, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747904, 1), t: 23 } }
2020-09-22T12:11:45.171+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 950 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 24, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747904, 1), t: 23 } }
2020-09-22T12:11:45.172+0800 I  ELECTION [replexec-3] VoteRequester(term 24) received a yes vote from 112.124.21.191:27019; response message: { term: 24, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000017') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747904, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747904, 1) }
2020-09-22T12:11:45.172+0800 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 24
2020-09-22T12:11:45.172+0800 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-09-22T12:11:45.172+0800 I  REPL     [replexec-3] Resetting sync source to empty, which was :27017
2020-09-22T12:11:45.173+0800 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-09-22T12:11:45.173+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:45.363+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:45.364+0800 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747904, 1), t: 23 }. My Last Applied: { ts: Timestamp(1600747904, 1), t: 23 }
2020-09-22T12:11:45.364+0800 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-09-22T12:11:45.364+0800 I  REPL     [replexec-2] Stopping replication producer
2020-09-22T12:11:45.364+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 24
2020-09-22T12:11:45.364+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 24
2020-09-22T12:11:45.364+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:45.364+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:45.364+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:45.365+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:45.365+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:45.366+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:45.366+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:45.366+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:45.726+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37648 #168 (29 connections now open)
2020-09-22T12:11:45.726+0800 I  NETWORK  [conn168] received client metadata from 120.55.194.98:37648 conn168: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:45.752+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55547 #169 (30 connections now open)
2020-09-22T12:11:45.752+0800 I  NETWORK  [conn169] received client metadata from 211.162.81.126:55547 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:45.754+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56449 #170 (31 connections now open)
2020-09-22T12:11:45.755+0800 I  NETWORK  [conn170] received client metadata from 211.162.81.126:56449 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:45.816+0800 I  NETWORK  [conn169] end connection 211.162.81.126:55547 (30 connections now open)
2020-09-22T12:11:45.816+0800 I  NETWORK  [conn170] end connection 211.162.81.126:56449 (29 connections now open)
2020-09-22T12:11:46.351+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56450 #171 (30 connections now open)
2020-09-22T12:11:46.351+0800 I  NETWORK  [conn171] received client metadata from 211.162.81.126:56450 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:46.359+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55548 #172 (31 connections now open)
2020-09-22T12:11:46.360+0800 I  NETWORK  [conn172] received client metadata from 211.162.81.126:55548 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:46.421+0800 I  NETWORK  [conn171] end connection 211.162.81.126:56450 (30 connections now open)
2020-09-22T12:11:46.422+0800 I  NETWORK  [conn172] end connection 211.162.81.126:55548 (29 connections now open)
2020-09-22T12:11:47.224+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:47.243+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:47.243+0800 I  REPL     [replexec-3] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:47.243+0800 I  REPL     [replexec-3] Stepping down from primary in response to heartbeat
2020-09-22T12:11:47.243+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:47.243+0800 W  COMMAND  [conn152] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.243+0800 I  COMMAND  [conn152] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 20), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1567ms
2020-09-22T12:11:47.244+0800 W  COMMAND  [conn85] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.244+0800 I  COMMAND  [conn85] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 20), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1565ms
2020-09-22T12:11:47.244+0800 W  COMMAND  [conn32] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.244+0800 I  COMMAND  [conn32] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-02:27017" }, u: { $set: { _id: "Jepsen-Node-02:27017", ping: new Date(1600747901410), up: 79, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 20), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1566ms
2020-09-22T12:11:47.245+0800 W  COMMAND  [conn29] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.245+0800 I  COMMAND  [conn29] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 28), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1659ms
2020-09-22T12:11:47.245+0800 W  COMMAND  [conn23] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.245+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "iZbp157vvbma2xfbxku74xZ:27017" }, u: { $set: { _id: "iZbp157vvbma2xfbxku74xZ:27017", ping: new Date(1600747901410), up: 80, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 19), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1828ms
2020-09-22T12:11:47.246+0800 W  COMMAND  [conn24] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.246+0800 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 27), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 1394ms
2020-09-22T12:11:47.246+0800 W  COMMAND  [conn33] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.246+0800 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 16), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1390ms
2020-09-22T12:11:47.247+0800 W  COMMAND  [conn151] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.247+0800 I  COMMAND  [conn151] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 19), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1830ms
2020-09-22T12:11:47.248+0800 W  COMMAND  [conn28] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:47.248+0800 I  COMMAND  [conn28] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-01:27017" }, u: { $set: { _id: "Jepsen-Node-01:27017", ping: new Date(1600747902922), up: 81, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747905, 28), signature: { hash: BinData(0, BC25122917555B01DDF020F77DEB081D8052A1F8), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1662ms
2020-09-22T12:11:47.248+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:47.248+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 9, userOpsRunning: 0 }
2020-09-22T12:11:47.248+0800 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-09-22T12:11:47.248+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:11:47.249+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:48.173+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:48.176+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:48.291+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53882 #173 (30 connections now open)
2020-09-22T12:11:48.292+0800 I  NETWORK  [conn173] received client metadata from 112.124.21.191:53882 conn173: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:48.293+0800 I  NETWORK  [conn84] end connection 112.124.21.191:53832 (29 connections now open)
2020-09-22T12:11:48.296+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53886 #174 (30 connections now open)
2020-09-22T12:11:48.296+0800 I  NETWORK  [conn174] received client metadata from 112.124.21.191:53886 conn174: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:48.353+0800 I  NETWORK  [conn168] end connection 120.55.194.98:37648 (29 connections now open)
2020-09-22T12:11:48.418+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56451 #175 (30 connections now open)
2020-09-22T12:11:48.418+0800 I  NETWORK  [conn175] received client metadata from 211.162.81.126:56451 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:48.424+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55549 #176 (31 connections now open)
2020-09-22T12:11:48.425+0800 I  NETWORK  [conn176] received client metadata from 211.162.81.126:55549 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:48.486+0800 I  NETWORK  [conn175] end connection 211.162.81.126:56451 (30 connections now open)
2020-09-22T12:11:48.492+0800 I  NETWORK  [conn176] end connection 211.162.81.126:55549 (29 connections now open)
2020-09-22T12:11:48.722+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37654 #177 (30 connections now open)
2020-09-22T12:11:48.722+0800 I  NETWORK  [conn177] received client metadata from 120.55.194.98:37654 conn177: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:48.794+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37656 #178 (31 connections now open)
2020-09-22T12:11:48.794+0800 I  NETWORK  [conn178] received client metadata from 120.55.194.98:37656 conn178: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:49.050+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37658 #179 (32 connections now open)
2020-09-22T12:11:49.050+0800 I  NETWORK  [conn179] received client metadata from 120.55.194.98:37658 conn179: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:49.249+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:49.251+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:49.254+0800 I  COMMAND  [conn33] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747908, 55), t: 25 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747908, 56), signature: { hash: BinData(0, 9DBC6A9AE6438855FEDBE0A76DD6790F745D17E1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 55), t: 25 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 663ms
2020-09-22T12:11:49.254+0800 I  COMMAND  [conn24] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747908, 55), t: 25 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747908, 56), signature: { hash: BinData(0, 9DBC6A9AE6438855FEDBE0A76DD6790F745D17E1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 55), t: 25 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 666ms
2020-09-22T12:11:49.309+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:49.309+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 25
2020-09-22T12:11:49.309+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 966 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:49.309+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 967 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:49.309+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:11:49.309+0800 I  ELECTION [replexec-2] VoteRequester(term 25 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 25, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747909, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747908, 56) }
2020-09-22T12:11:49.310+0800 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 26
2020-09-22T12:11:49.310+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 968 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 26, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:49.311+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 969 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 26, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:49.312+0800 I  ELECTION [replexec-5] VoteRequester(term 26) received a yes vote from 120.55.194.98:27019; response message: { term: 26, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747909, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747908, 56) }
2020-09-22T12:11:49.312+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 26
2020-09-22T12:11:49.312+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:11:49.312+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:11:49.312+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:11:49.312+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:11:49.673+0800 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747908, 56), t: 25 }. My Last Applied: { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:49.673+0800 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-09-22T12:11:49.673+0800 I  REPL     [replexec-3] Stopping replication producer
2020-09-22T12:11:49.673+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 26
2020-09-22T12:11:49.673+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 26
2020-09-22T12:11:49.673+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:49.673+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:49.673+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:49.673+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:49.673+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:49.674+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:49.674+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:49.675+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:49.675+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:49.675+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:49.676+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37660 #180 (33 connections now open)
2020-09-22T12:11:49.677+0800 I  NETWORK  [conn180] received client metadata from 120.55.194.98:37660 conn180: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:49.751+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:60090 #181 (34 connections now open)
2020-09-22T12:11:49.752+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:60092 #182 (35 connections now open)
2020-09-22T12:11:49.752+0800 I  NETWORK  [conn181] received client metadata from 120.55.192.104:60090 conn181: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:49.752+0800 I  NETWORK  [conn182] received client metadata from 120.55.192.104:60092 conn182: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:49.775+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55550 #183 (36 connections now open)
2020-09-22T12:11:49.776+0800 I  NETWORK  [conn183] received client metadata from 211.162.81.126:55550 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:49.776+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56452 #184 (37 connections now open)
2020-09-22T12:11:49.777+0800 I  NETWORK  [conn184] received client metadata from 211.162.81.126:56452 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:49.834+0800 I  NETWORK  [conn183] end connection 211.162.81.126:55550 (36 connections now open)
2020-09-22T12:11:49.835+0800 I  NETWORK  [conn184] end connection 211.162.81.126:56452 (35 connections now open)
2020-09-22T12:11:50.058+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:60094 #185 (36 connections now open)
2020-09-22T12:11:50.058+0800 I  NETWORK  [conn185] received client metadata from 120.55.192.104:60094 conn185: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:50.399+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:37204 #186 (37 connections now open)
2020-09-22T12:11:50.400+0800 I  NETWORK  [conn186] received client metadata from 118.31.43.238:37204 conn186: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:50.724+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:50.726+0800 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:50.726+0800 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-09-22T12:11:50.726+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:50.726+0800 W  COMMAND  [conn152] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.726+0800 I  COMMAND  [conn152] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.02:27017:1600747818:7156575011715358840" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 18), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1043ms
2020-09-22T12:11:50.727+0800 W  COMMAND  [conn182] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.727+0800 I  COMMAND  [conn182] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 15), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 973ms
2020-09-22T12:11:50.727+0800 W  COMMAND  [conn85] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.727+0800 I  COMMAND  [conn85] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-02:27017" }, u: { $set: { _id: "Jepsen-Node-02:27017", ping: new Date(1600747901410), up: 79, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 15), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 976ms
2020-09-22T12:11:50.728+0800 W  COMMAND  [conn32] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.728+0800 I  COMMAND  [conn32] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 15), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 976ms
2020-09-22T12:11:50.728+0800 W  COMMAND  [conn179] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.728+0800 I  COMMAND  [conn179] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 17), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1052ms
2020-09-22T12:11:50.729+0800 W  COMMAND  [conn23] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.729+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 17), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1052ms
2020-09-22T12:11:50.729+0800 W  COMMAND  [conn180] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.729+0800 I  COMMAND  [conn180] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "iZbp157vvbma2xfbxku74xZ:27017:1600747818:7332321692021962316" }, update: { $set: { ping: new Date(1600747909674) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 17), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:766 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1052ms
2020-09-22T12:11:50.730+0800 W  COMMAND  [conn181] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.730+0800 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 15), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 977ms
2020-09-22T12:11:50.731+0800 W  COMMAND  [conn178] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.731+0800 I  COMMAND  [conn178] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "iZbp157vvbma2xfbxku74xZ:27017" }, u: { $set: { _id: "iZbp157vvbma2xfbxku74xZ:27017", ping: new Date(1600747901410), up: 80, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 17), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1054ms
2020-09-22T12:11:50.731+0800 W  COMMAND  [conn24] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.731+0800 I  COMMAND  [conn24] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.00:27017:1600747818:2541039578456057690" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 18), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1049ms
2020-09-22T12:11:50.732+0800 W  COMMAND  [conn33] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.732+0800 I  COMMAND  [conn33] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.01:27017:1600747818:3466407884530610701" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 18), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1049ms
2020-09-22T12:11:50.733+0800 W  COMMAND  [conn151] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.733+0800 I  COMMAND  [conn151] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 17), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1057ms
2020-09-22T12:11:50.734+0800 W  COMMAND  [conn174] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.734+0800 I  COMMAND  [conn174] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Jepsen-Node-01:27017:1600747818:8589022375712416522" }, update: { $set: { ping: new Date(1600747909674) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747909, 14), signature: { hash: BinData(0, 0C8A916BD523623DF1E4832C74BA0AC0585E6011), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:757 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1058ms
2020-09-22T12:11:50.735+0800 W  COMMAND  [conn185] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:50.735+0800 I  COMMAND  [conn185] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Jepsen-Node-02:27017:1600747819:-4663412768929081412" }, update: { $set: { ping: new Date(1600747910393) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747910, 1), signature: { hash: BinData(0, 004BF278760F14F13938C75EA3AFA222D719AAF3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:758 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 342ms
2020-09-22T12:11:50.736+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:50.736+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 14, userOpsRunning: 0 }
2020-09-22T12:11:50.736+0800 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-09-22T12:11:50.737+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:11:50.737+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:51.841+0800 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-09-22T12:11:52.313+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:52.313+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:52.670+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37666 #187 (38 connections now open)
2020-09-22T12:11:52.671+0800 I  NETWORK  [conn187] received client metadata from 120.55.194.98:37666 conn187: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:52.671+0800 I  ELECTION [conn187] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:52.671+0800 I  ELECTION [conn187] Sending vote response: { term: 27, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747908, 56), t: 25 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:11:52.724+0800 I  NETWORK  [conn177] end connection 120.55.194.98:37654 (37 connections now open)
2020-09-22T12:11:52.900+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55551 #188 (38 connections now open)
2020-09-22T12:11:52.900+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56608 #189 (39 connections now open)
2020-09-22T12:11:52.901+0800 I  NETWORK  [conn188] received client metadata from 211.162.81.126:55551 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:52.901+0800 I  NETWORK  [conn189] received client metadata from 211.162.81.126:56608 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:52.955+0800 I  NETWORK  [conn188] end connection 211.162.81.126:55551 (38 connections now open)
2020-09-22T12:11:52.955+0800 I  NETWORK  [conn189] end connection 211.162.81.126:56608 (37 connections now open)
2020-09-22T12:11:53.160+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:53.313+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:53.759+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:53.759+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 27
2020-09-22T12:11:53.759+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 982 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747910, 2), t: 26 } }
2020-09-22T12:11:53.759+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 983 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747910, 2), t: 26 } }
2020-09-22T12:11:53.759+0800 I  ELECTION [replexec-1] VoteRequester(term 27 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 27, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747913, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747910, 2) }
2020-09-22T12:11:53.760+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 28
2020-09-22T12:11:53.761+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 984 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 28, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747910, 2), t: 26 } }
2020-09-22T12:11:53.761+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 985 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 28, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747910, 2), t: 26 } }
2020-09-22T12:11:53.762+0800 I  ELECTION [replexec-4] VoteRequester(term 28) received a yes vote from 120.55.194.98:27019; response message: { term: 28, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747913, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747910, 2) }
2020-09-22T12:11:53.762+0800 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 28
2020-09-22T12:11:53.762+0800 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-09-22T12:11:53.762+0800 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-09-22T12:11:53.763+0800 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-09-22T12:11:54.173+0800 I  REPL     [replexec-6] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747910, 2), t: 26 }. My Last Applied: { ts: Timestamp(1600747910, 2), t: 26 }
2020-09-22T12:11:54.173+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:11:54.173+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:11:54.173+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 28
2020-09-22T12:11:54.173+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 28
2020-09-22T12:11:54.173+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:54.173+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:54.173+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:54.174+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:54.174+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:54.175+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:54.175+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:54.175+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:54.206+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37662 #191 (38 connections now open)
2020-09-22T12:11:54.206+0800 I  NETWORK  [conn191] received client metadata from 120.55.194.98:37662 conn191: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:54.383+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53896 #192 (39 connections now open)
2020-09-22T12:11:54.384+0800 I  NETWORK  [conn192] received client metadata from 112.124.21.191:53896 conn192: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:54.390+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37664 #193 (40 connections now open)
2020-09-22T12:11:54.390+0800 I  NETWORK  [conn193] received client metadata from 120.55.194.98:37664 conn193: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:54.414+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55552 #194 (41 connections now open)
2020-09-22T12:11:54.415+0800 I  NETWORK  [conn194] received client metadata from 211.162.81.126:55552 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:54.421+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55553 #195 (42 connections now open)
2020-09-22T12:11:54.421+0800 I  NETWORK  [conn195] received client metadata from 211.162.81.126:55553 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:54.486+0800 I  NETWORK  [conn194] end connection 211.162.81.126:55552 (41 connections now open)
2020-09-22T12:11:54.489+0800 I  NETWORK  [conn195] end connection 211.162.81.126:55553 (40 connections now open)
2020-09-22T12:11:54.567+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53898 #196 (41 connections now open)
2020-09-22T12:11:54.567+0800 I  NETWORK  [conn196] received client metadata from 112.124.21.191:53898 conn196: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:54.799+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53884 #197 (42 connections now open)
2020-09-22T12:11:54.800+0800 I  NETWORK  [conn197] received client metadata from 112.124.21.191:53884 conn197: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.175+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53900 #198 (43 connections now open)
2020-09-22T12:11:55.176+0800 I  NETWORK  [conn27] end connection 112.124.21.191:53736 (42 connections now open)
2020-09-22T12:11:55.176+0800 I  NETWORK  [conn198] received client metadata from 112.124.21.191:53900 conn198: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.245+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55709 #199 (43 connections now open)
2020-09-22T12:11:55.245+0800 I  NETWORK  [conn199] received client metadata from 211.162.81.126:55709 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:55.247+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55710 #200 (44 connections now open)
2020-09-22T12:11:55.248+0800 I  NETWORK  [conn200] received client metadata from 211.162.81.126:55710 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:55.299+0800 I  NETWORK  [conn199] end connection 211.162.81.126:55709 (43 connections now open)
2020-09-22T12:11:55.300+0800 I  NETWORK  [conn200] end connection 211.162.81.126:55710 (42 connections now open)
2020-09-22T12:11:55.584+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38236 #201 (43 connections now open)
2020-09-22T12:11:55.585+0800 I  NETWORK  [conn201] received client metadata from 47.96.16.32:38236 conn201: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.661+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:60524 #202 (44 connections now open)
2020-09-22T12:11:55.662+0800 I  NETWORK  [conn202] received client metadata from 47.96.5.198:60524 conn202: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.697+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:55.697+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:55.697+0800 I  COMMAND  [conn185] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1463ms
2020-09-22T12:11:55.697+0800 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1463ms
2020-09-22T12:11:55.697+0800 I  COMMAND  [conn32] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Jepsen-Node-02:27017:1600747819:-4663412768929081412" }, update: { $set: { ping: new Date(1600747910393) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:640 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 9 } storage:{} protocol:op_msg 1463ms
2020-09-22T12:11:55.697+0800 I  COMMAND  [conn85] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1463ms
2020-09-22T12:11:55.698+0800 I  COMMAND  [conn192] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747910, 1), signature: { hash: BinData(0, 004BF278760F14F13938C75EA3AFA222D719AAF3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1313ms
2020-09-22T12:11:55.698+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1194ms
2020-09-22T12:11:55.698+0800 I  COMMAND  [conn178] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1194ms
2020-09-22T12:11:55.698+0800 I  COMMAND  [conn151] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1194ms
2020-09-22T12:11:55.698+0800 I  COMMAND  [conn193] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1195ms
2020-09-22T12:11:55.699+0800 I  COMMAND  [conn191] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "iZbp157vvbma2xfbxku74xZ:27017:1600747818:7332321692021962316" }, update: { $set: { ping: new Date(1600747909674) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:648 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1195ms
2020-09-22T12:11:55.699+0800 I  COMMAND  [conn180] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 1132ms
2020-09-22T12:11:55.699+0800 I  COMMAND  [conn196] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 19), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1130ms
2020-09-22T12:11:55.699+0800 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 19), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1058ms
2020-09-22T12:11:55.699+0800 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1058ms
2020-09-22T12:11:55.700+0800 I  COMMAND  [conn19] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1040ms
2020-09-22T12:11:55.700+0800 I  COMMAND  [conn152] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1057ms
2020-09-22T12:11:55.700+0800 I  COMMAND  [conn201] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 1E01AF2E1334702AA4191CEDF469A69D969F48C1), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 112ms
2020-09-22T12:11:56.321+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:56.525+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56609 #205 (45 connections now open)
2020-09-22T12:11:56.526+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55711 #206 (46 connections now open)
2020-09-22T12:11:56.526+0800 I  NETWORK  [conn205] received client metadata from 211.162.81.126:56609 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:56.526+0800 I  NETWORK  [conn206] received client metadata from 211.162.81.126:55711 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:56.583+0800 I  NETWORK  [conn205] end connection 211.162.81.126:56609 (45 connections now open)
2020-09-22T12:11:56.583+0800 I  NETWORK  [conn206] end connection 211.162.81.126:55711 (44 connections now open)
2020-09-22T12:11:57.640+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:57.640+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:57.640+0800 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:57.640+0800 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-09-22T12:11:57.640+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:57.640+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:57.640+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:57.640+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:11:57.641+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:58.728+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:11:58.763+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:58.763+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:59.263+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:59.385+0800 I  NETWORK  [conn126] end connection 120.55.194.98:37620 (43 connections now open)
2020-09-22T12:11:59.641+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:59.643+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:59.647+0800 I  COMMAND  [conn202] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747918, 9), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747918, 9), signature: { hash: BinData(0, AB47F75ED12C9187BAAB2CF6FB90DB1CB69E2878), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747918, 9), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 1034ms
2020-09-22T12:11:59.647+0800 I  COMMAND  [conn201] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747919, 4), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747919, 10), signature: { hash: BinData(0, A27CC8548C90331A487C486A5DEA832DAD41F95A), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747919, 4), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 371ms
2020-09-22T12:11:59.647+0800 I  COMMAND  [conn33] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747919, 3), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747919, 10), signature: { hash: BinData(0, A27CC8548C90331A487C486A5DEA832DAD41F95A), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747919, 3), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 372ms
2020-09-22T12:11:59.989+0800 I  NETWORK  [conn187] end connection 120.55.194.98:37666 (42 connections now open)
2020-09-22T12:12:00.191+0800 I  ELECTION [conn12] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 25, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:12:00.191+0800 I  ELECTION [conn12] Sending vote response: { term: 29, voteGranted: false, reason: "candidate's term (25) is lower than mine (29)" }
2020-09-22T12:12:00.191+0800 I  ELECTION [conn153] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 24, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:12:00.191+0800 I  ELECTION [conn153] Sending vote response: { term: 29, voteGranted: false, reason: "candidate's term (24) is lower than mine (29)" }
2020-09-22T12:12:00.191+0800 I  NETWORK  [conn12] end connection 112.124.21.191:53728 (41 connections now open)
2020-09-22T12:12:00.192+0800 I  NETWORK  [conn153] end connection 112.124.21.191:53872 (40 connections now open)
2020-09-22T12:12:00.246+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37670 #209 (41 connections now open)
2020-09-22T12:12:00.246+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37672 #210 (42 connections now open)
2020-09-22T12:12:00.246+0800 I  NETWORK  [conn210] received client metadata from 120.55.194.98:37672 conn210: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:00.246+0800 I  NETWORK  [conn209] received client metadata from 120.55.194.98:37670 conn209: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:00.260+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55712 #211 (43 connections now open)
2020-09-22T12:12:00.260+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56610 #212 (44 connections now open)
2020-09-22T12:12:00.260+0800 I  NETWORK  [conn212] received client metadata from 211.162.81.126:56610 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.261+0800 I  NETWORK  [conn211] received client metadata from 211.162.81.126:55712 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.319+0800 I  NETWORK  [conn211] end connection 211.162.81.126:55712 (43 connections now open)
2020-09-22T12:12:00.319+0800 I  NETWORK  [conn212] end connection 211.162.81.126:56610 (42 connections now open)
2020-09-22T12:12:00.851+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56611 #213 (43 connections now open)
2020-09-22T12:12:00.851+0800 I  NETWORK  [conn213] received client metadata from 211.162.81.126:56611 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.852+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56612 #214 (44 connections now open)
2020-09-22T12:12:00.853+0800 I  NETWORK  [conn214] received client metadata from 211.162.81.126:56612 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.909+0800 I  NETWORK  [conn213] end connection 211.162.81.126:56611 (43 connections now open)
2020-09-22T12:12:00.909+0800 I  NETWORK  [conn214] end connection 211.162.81.126:56612 (42 connections now open)
2020-09-22T12:12:01.171+0800 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-09-22T12:12:01.654+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56613 #215 (43 connections now open)
2020-09-22T12:12:01.655+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55713 #216 (44 connections now open)
2020-09-22T12:12:01.655+0800 I  NETWORK  [conn215] received client metadata from 211.162.81.126:56613 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:01.656+0800 I  NETWORK  [conn216] received client metadata from 211.162.81.126:55713 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:01.716+0800 I  NETWORK  [conn215] end connection 211.162.81.126:56613 (43 connections now open)
2020-09-22T12:12:01.717+0800 I  NETWORK  [conn216] end connection 211.162.81.126:55713 (42 connections now open)
2020-09-22T12:12:03.375+0800 I  NETWORK  [conn173] end connection 112.124.21.191:53882 (41 connections now open)
2020-09-22T12:12:04.091+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55714 #217 (42 connections now open)
2020-09-22T12:12:04.092+0800 I  NETWORK  [conn217] received client metadata from 211.162.81.126:55714 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.092+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56614 #218 (43 connections now open)
2020-09-22T12:12:04.093+0800 I  NETWORK  [conn218] received client metadata from 211.162.81.126:56614 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.150+0800 I  NETWORK  [conn218] end connection 211.162.81.126:56614 (42 connections now open)
2020-09-22T12:12:04.150+0800 I  NETWORK  [conn217] end connection 211.162.81.126:55714 (41 connections now open)
2020-09-22T12:12:04.904+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56615 #219 (42 connections now open)
2020-09-22T12:12:04.904+0800 I  NETWORK  [conn219] received client metadata from 211.162.81.126:56615 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.905+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55715 #220 (43 connections now open)
2020-09-22T12:12:04.906+0800 I  NETWORK  [conn220] received client metadata from 211.162.81.126:55715 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.966+0800 I  NETWORK  [conn219] end connection 211.162.81.126:56615 (42 connections now open)
2020-09-22T12:12:04.967+0800 I  NETWORK  [conn220] end connection 211.162.81.126:55715 (41 connections now open)
2020-09-22T12:12:05.760+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53892 #221 (42 connections now open)
2020-09-22T12:12:05.760+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53890 #222 (43 connections now open)
2020-09-22T12:12:05.760+0800 I  NETWORK  [conn222] received client metadata from 112.124.21.191:53890 conn222: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:05.760+0800 I  NETWORK  [conn221] received client metadata from 112.124.21.191:53892 conn221: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:06.154+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:06.154+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 29
2020-09-22T12:12:06.154+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1044 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.154+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1045 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.154+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:06.154+0800 I  ELECTION [replexec-1] VoteRequester(term 29 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 29, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747924, 3), $clusterTime: { clusterTime: Timestamp(1600747924, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747924, 3) }
2020-09-22T12:12:06.155+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 30
2020-09-22T12:12:06.156+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1046 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.156+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1047 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.157+0800 I  ELECTION [replexec-2] VoteRequester(term 30) received a yes vote from 112.124.21.191:27019; response message: { term: 30, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747924, 3), $clusterTime: { clusterTime: Timestamp(1600747924, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747924, 3) }
2020-09-22T12:12:06.157+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 30
2020-09-22T12:12:06.157+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:06.157+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:12:06.157+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:06.158+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:12:06.763+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:12:06.763+0800 I  REPL     [replexec-6] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747924, 3), t: 29 }. My Last Applied: { ts: Timestamp(1600747924, 3), t: 29 }
2020-09-22T12:12:06.763+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:06.763+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:06.763+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:12:06.763+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:06.763+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 30
2020-09-22T12:12:06.763+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 30
2020-09-22T12:12:06.763+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:06.763+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:06.763+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:06.764+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:06.764+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:06.765+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:06.765+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:06.765+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:06.768+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:12:06.768+0800 I  CONNPOOL [ShardRegistry] Connecting to 47.96.16.32:27018
2020-09-22T12:12:07.158+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:07.158+0800 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:07.158+0800 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-09-22T12:12:07.158+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:07.159+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:07.159+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 2, userOpsRunning: 0 }
2020-09-22T12:12:07.159+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:12:07.159+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:12:07.159+0800 I  CONNPOOL [ShardRegistry] Ending connection to host 47.96.16.32:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:12:07.160+0800 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard1 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-09-22T12:12:07.160+0800 W  SHARDING [Balancer] Failed to enforce tag ranges :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-09-22T12:12:07.160+0800 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-09-22T12:12:07.160+0800 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-09-22T12:12:07.161+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:07.286+0800 I  ELECTION [conn222] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:07.286+0800 I  ELECTION [conn222] Sending vote response: { term: 30, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747924, 3), t: 29 }, my last applied OpTime: { ts: Timestam..." }
2020-09-22T12:12:08.158+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:08.305+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:08.305+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 30
2020-09-22T12:12:08.305+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1060 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.305+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1061 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.305+0800 I  ELECTION [replexec-3] VoteRequester(term 30 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 30, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747924, 3), $clusterTime: { clusterTime: Timestamp(1600747928, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747924, 3) }
2020-09-22T12:12:08.305+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 31
2020-09-22T12:12:08.307+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1062 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.307+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1063 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.308+0800 I  ELECTION [replexec-2] VoteRequester(term 31) received a yes vote from 112.124.21.191:27019; response message: { term: 31, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747924, 3), $clusterTime: { clusterTime: Timestamp(1600747928, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747924, 3) }
2020-09-22T12:12:08.308+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 31
2020-09-22T12:12:08.308+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:08.308+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:12:08.308+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:08.560+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55716 #225 (44 connections now open)
2020-09-22T12:12:08.560+0800 I  NETWORK  [conn225] received client metadata from 211.162.81.126:55716 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:08.566+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55717 #226 (45 connections now open)
2020-09-22T12:12:08.566+0800 I  NETWORK  [conn226] received client metadata from 211.162.81.126:55717 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:08.624+0800 I  NETWORK  [conn225] end connection 211.162.81.126:55716 (44 connections now open)
2020-09-22T12:12:08.626+0800 I  NETWORK  [conn226] end connection 211.162.81.126:55717 (43 connections now open)
2020-09-22T12:12:09.084+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37680 #227 (44 connections now open)
2020-09-22T12:12:09.084+0800 I  NETWORK  [conn227] received client metadata from 120.55.194.98:37680 conn227: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:09.158+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:12:09.158+0800 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747926, 2), t: 30 }. My Last Applied: { ts: Timestamp(1600747926, 2), t: 30 }
2020-09-22T12:12:09.158+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:12:09.158+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:12:09.158+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 31
2020-09-22T12:12:09.158+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 31
2020-09-22T12:12:09.159+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:09.159+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:09.159+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:12:09.160+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:09.160+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:09.161+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:09.161+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:09.161+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:09.165+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:12:09.165+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:12:09.513+0800 I  NETWORK  [conn210] end connection 120.55.194.98:37672 (43 connections now open)
2020-09-22T12:12:09.588+0800 I  ELECTION [conn209] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 31, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747929, 1), t: 31 } }
2020-09-22T12:12:09.588+0800 I  ELECTION [conn209] Sending vote response: { term: 31, voteGranted: true, reason: "" }
2020-09-22T12:12:09.592+0800 I  REPL     [conn209] stepping down from primary, because a new term has begun: 32
2020-09-22T12:12:09.592+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:09.592+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:09.592+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:12:09.592+0800 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-09-22T12:12:09.593+0800 I  ELECTION [conn209] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747929, 1), t: 31 } }
2020-09-22T12:12:09.593+0800 I  ELECTION [conn209] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-09-22T12:12:09.593+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:09.666+0800 I  NETWORK  [conn227] end connection 120.55.194.98:37680 (42 connections now open)
2020-09-22T12:12:10.064+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55718 #230 (43 connections now open)
2020-09-22T12:12:10.064+0800 I  NETWORK  [conn230] received client metadata from 211.162.81.126:55718 conn230: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:10.066+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56616 #231 (44 connections now open)
2020-09-22T12:12:10.067+0800 I  NETWORK  [conn231] received client metadata from 211.162.81.126:56616 conn231: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:10.123+0800 I  NETWORK  [conn230] end connection 211.162.81.126:55718 (43 connections now open)
2020-09-22T12:12:10.123+0800 I  NETWORK  [conn231] end connection 211.162.81.126:56616 (42 connections now open)
2020-09-22T12:12:10.593+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:12:10.595+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:12:10.599+0800 I  COMMAND  [conn202] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747929, 5), t: 32 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747929, 5), signature: { hash: BinData(0, 2AEDCA1606B88D39491BB96F6E9E6438AF4DAED3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747929, 5), t: 32 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 937ms
2020-09-22T12:12:10.599+0800 I  COMMAND  [conn201] command config.settings command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747929, 6), t: 32 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747929, 6), signature: { hash: BinData(0, 2AEDCA1606B88D39491BB96F6E9E6438AF4DAED3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747929, 6), t: 32 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 932ms
2020-09-22T12:12:10.599+0800 I  COMMAND  [conn40] command config.settings command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747929, 6), t: 32 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747929, 6), signature: { hash: BinData(0, 2AEDCA1606B88D39491BB96F6E9E6438AF4DAED3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747929, 6), t: 32 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:551 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 718ms
2020-09-22T12:12:10.666+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:10.666+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 32
2020-09-22T12:12:10.666+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1077 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.666+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1078 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.666+0800 I  ELECTION [replexec-3] VoteRequester(term 32 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 32, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 33), $clusterTime: { clusterTime: Timestamp(1600747930, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747930, 33) }
2020-09-22T12:12:10.666+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 33
2020-09-22T12:12:10.668+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1079 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 33, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.668+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1080 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 33, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.669+0800 I  ELECTION [replexec-4] VoteRequester(term 33) received a yes vote from 112.124.21.191:27019; response message: { term: 33, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 33), $clusterTime: { clusterTime: Timestamp(1600747930, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747930, 33) }
2020-09-22T12:12:10.669+0800 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 33
2020-09-22T12:12:10.669+0800 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-09-22T12:12:10.669+0800 I  REPL     [replexec-4] Resetting sync source to empty, which was 112.124.21.191:27019
2020-09-22T12:12:10.669+0800 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-09-22T12:12:10.670+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:10.670+0800 I  REPL     [replexec-6] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747930, 33), t: 32 }. My Last Applied: { ts: Timestamp(1600747930, 33), t: 32 }
2020-09-22T12:12:10.670+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:10.670+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:10.670+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 33
2020-09-22T12:12:10.670+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 33
2020-09-22T12:12:10.670+0800 I  CONNPOOL [RS] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:10.670+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:12:10.670+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:10.670+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:10.671+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:10.672+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:10.672+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:10.673+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:10.673+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:10.673+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:11.600+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55720 #232 (43 connections now open)
2020-09-22T12:12:11.600+0800 I  NETWORK  [conn232] received client metadata from 211.162.81.126:55720 conn232: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:11.602+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55719 #233 (44 connections now open)
2020-09-22T12:12:11.602+0800 I  NETWORK  [conn233] received client metadata from 211.162.81.126:55719 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:11.654+0800 I  NETWORK  [conn232] end connection 211.162.81.126:55720 (43 connections now open)
2020-09-22T12:12:11.654+0800 I  NETWORK  [conn233] end connection 211.162.81.126:55719 (42 connections now open)
2020-09-22T12:12:11.672+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37684 #234 (43 connections now open)
2020-09-22T12:12:11.673+0800 I  NETWORK  [conn234] received client metadata from 120.55.194.98:37684 conn234: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:11.674+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:12:11.674+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:12:11.674+0800 I  COMMAND  [conn202] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747931, 3), signature: { hash: BinData(0, 2B3FE5A962442B52A4A51814988A0C17BA32DE1D), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 33), t: 32 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 240ms
2020-09-22T12:12:12.629+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37686 #235 (44 connections now open)
2020-09-22T12:12:12.629+0800 I  NETWORK  [conn235] received client metadata from 120.55.194.98:37686 conn235: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:12.630+0800 I  REPL     [conn235] stepping down from primary, because a new term has begun: 34
2020-09-22T12:12:12.631+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:12.631+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:12.631+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:12:12.631+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:12:12.631+0800 I  ELECTION [conn235] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:12.631+0800 I  ELECTION [conn235] Sending vote response: { term: 34, voteGranted: true, reason: "" }
2020-09-22T12:12:12.632+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:12.632+0800 I  NETWORK  [conn235] end connection 120.55.194.98:37686 (43 connections now open)
2020-09-22T12:12:12.633+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37688 #236 (44 connections now open)
2020-09-22T12:12:12.633+0800 I  NETWORK  [conn209] end connection 120.55.194.98:37670 (43 connections now open)
2020-09-22T12:12:12.633+0800 I  NETWORK  [conn236] received client metadata from 120.55.194.98:37688 conn236: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:12.634+0800 I  NETWORK  [conn141] end connection 120.55.194.98:37628 (42 connections now open)
2020-09-22T12:12:12.674+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:12.873+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53914 #237 (43 connections now open)
2020-09-22T12:12:12.873+0800 I  NETWORK  [conn237] received client metadata from 112.124.21.191:53914 conn237: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:13.238+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55721 #238 (44 connections now open)
2020-09-22T12:12:13.239+0800 I  NETWORK  [conn238] received client metadata from 211.162.81.126:55721 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:13.239+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56617 #239 (45 connections now open)
2020-09-22T12:12:13.239+0800 I  NETWORK  [conn239] received client metadata from 211.162.81.126:56617 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:13.295+0800 I  NETWORK  [conn238] end connection 211.162.81.126:55721 (44 connections now open)
2020-09-22T12:12:13.296+0800 I  NETWORK  [conn239] end connection 211.162.81.126:56617 (43 connections now open)
2020-09-22T12:12:13.631+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:13.631+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:12:14.193+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:14.193+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 34
2020-09-22T12:12:14.193+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1093 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.193+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1094 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.194+0800 I  ELECTION [replexec-5] VoteRequester(term 34 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 34, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747933, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747930, 56) }
2020-09-22T12:12:14.194+0800 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 35
2020-09-22T12:12:14.195+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1095 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.195+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1096 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.196+0800 I  ELECTION [replexec-2] VoteRequester(term 35) received a yes vote from 112.124.21.191:27019; response message: { term: 35, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747933, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747930, 56) }
2020-09-22T12:12:14.196+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 35
2020-09-22T12:12:14.196+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:14.196+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:12:14.196+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:14.196+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:12:14.674+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:12:14.674+0800 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747930, 56), t: 33 }. My Last Applied: { ts: Timestamp(1600747930, 56), t: 33 }
2020-09-22T12:12:14.674+0800 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-09-22T12:12:14.674+0800 I  REPL     [replexec-3] Stopping replication producer
2020-09-22T12:12:14.674+0800 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: 120.55.194.98:27019
2020-09-22T12:12:14.674+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 35
2020-09-22T12:12:14.674+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 35
2020-09-22T12:12:14.674+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:14.674+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:14.674+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:14.675+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:14.675+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:14.676+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:14.676+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:14.676+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:15.197+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:15.197+0800 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:15.197+0800 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-09-22T12:12:15.197+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:15.197+0800 W  COMMAND  [conn201] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:15.197+0800 I  COMMAND  [conn201] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747934, 2), signature: { hash: BinData(0, 4F62AEB486E58782F7644053A9BAE3BC2E5EF0AC), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 56), t: 33 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 306ms
2020-09-22T12:12:15.198+0800 W  COMMAND  [conn202] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:15.198+0800 I  COMMAND  [conn202] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747934, 7), signature: { hash: BinData(0, 4F62AEB486E58782F7644053A9BAE3BC2E5EF0AC), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 56), t: 33 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 284ms
2020-09-22T12:12:15.198+0800 W  COMMAND  [conn24] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:15.198+0800 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747934, 2), signature: { hash: BinData(0, 4F62AEB486E58782F7644053A9BAE3BC2E5EF0AC), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 56), t: 33 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 308ms
2020-09-22T12:12:15.199+0800 W  COMMAND  [conn33] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:15.199+0800 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747934, 3), signature: { hash: BinData(0, 4F62AEB486E58782F7644053A9BAE3BC2E5EF0AC), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 56), t: 33 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 279ms
2020-09-22T12:12:15.199+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:15.199+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 4, userOpsRunning: 0 }
2020-09-22T12:12:15.199+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:12:15.200+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:12:15.200+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:15.323+0800 I  ELECTION [conn222] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:15.323+0800 I  ELECTION [conn222] Sending vote response: { term: 35, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747930, 56), t: 33 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:15.600+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56618 #240 (44 connections now open)
2020-09-22T12:12:15.600+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55722 #241 (45 connections now open)
2020-09-22T12:12:15.600+0800 I  NETWORK  [conn240] received client metadata from 211.162.81.126:56618 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:15.601+0800 I  NETWORK  [conn241] received client metadata from 211.162.81.126:55722 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:15.657+0800 I  NETWORK  [conn241] end connection 211.162.81.126:55722 (44 connections now open)
2020-09-22T12:12:15.657+0800 I  NETWORK  [conn240] end connection 211.162.81.126:56618 (43 connections now open)
2020-09-22T12:12:16.197+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:16.334+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:16.334+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 35
2020-09-22T12:12:16.334+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1103 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.334+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1104 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.334+0800 I  ELECTION [replexec-6] VoteRequester(term 35 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 35, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747934, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747934, 2) }
2020-09-22T12:12:16.335+0800 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 36
2020-09-22T12:12:16.336+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1105 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 36, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.336+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1106 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 36, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.337+0800 I  ELECTION [replexec-2] VoteRequester(term 36) received a yes vote from 112.124.21.191:27019; response message: { term: 36, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001b') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747934, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747934, 2) }
2020-09-22T12:12:16.338+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 36
2020-09-22T12:12:16.338+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:16.338+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:12:16.338+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:16.384+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37690 #242 (44 connections now open)
2020-09-22T12:12:16.385+0800 I  NETWORK  [conn242] received client metadata from 120.55.194.98:37690 conn242: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:16.386+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37692 #243 (45 connections now open)
2020-09-22T12:12:16.386+0800 I  NETWORK  [conn243] received client metadata from 120.55.194.98:37692 conn243: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:16.425+0800 I  NETWORK  [conn243] end connection 120.55.194.98:37692 (44 connections now open)
2020-09-22T12:12:16.432+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37694 #244 (45 connections now open)
2020-09-22T12:12:16.432+0800 I  NETWORK  [conn244] received client metadata from 120.55.194.98:37694 conn244: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:16.528+0800 I  NETWORK  [conn244] end connection 120.55.194.98:37694 (44 connections now open)
2020-09-22T12:12:16.578+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:53920 #245 (45 connections now open)
2020-09-22T12:12:16.579+0800 I  NETWORK  [conn245] received client metadata from 112.124.21.191:53920 conn245: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:16.615+0800 I  NETWORK  [conn245] end connection 112.124.21.191:53920 (44 connections now open)
2020-09-22T12:12:17.198+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:12:17.198+0800 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747934, 2), t: 35 }. My Last Applied: { ts: Timestamp(1600747934, 2), t: 35 }
2020-09-22T12:12:17.198+0800 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-09-22T12:12:17.198+0800 I  REPL     [replexec-2] Stopping replication producer
2020-09-22T12:12:17.198+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 36
2020-09-22T12:12:17.198+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 36
2020-09-22T12:12:17.198+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:17.198+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:17.198+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:12:17.199+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:17.199+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:17.200+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:17.200+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:17.200+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:17.203+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:12:17.203+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:12:17.392+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:38250 #249 (45 connections now open)
2020-09-22T12:12:17.392+0800 I  NETWORK  [conn249] received client metadata from 47.96.16.32:38250 conn249: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:17.504+0800 I  ELECTION [conn236] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 36, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:17.504+0800 I  ELECTION [conn236] Sending vote response: { term: 36, voteGranted: true, reason: "" }
2020-09-22T12:12:17.506+0800 I  REPL     [conn236] stepping down from primary, because a new term has begun: 37
2020-09-22T12:12:17.506+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:17.506+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:17.506+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:12:17.506+0800 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-09-22T12:12:17.507+0800 I  ELECTION [conn236] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 37, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:17.507+0800 I  ELECTION [conn236] Sending vote response: { term: 37, voteGranted: true, reason: "" }
2020-09-22T12:12:17.507+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:17.508+0800 I  NETWORK  [conn236] end connection 120.55.194.98:37688 (44 connections now open)
2020-09-22T12:12:17.508+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:37696 #250 (45 connections now open)
2020-09-22T12:12:17.509+0800 I  NETWORK  [conn250] received client metadata from 120.55.194.98:37696 conn250: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:17.776+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56620 #251 (46 connections now open)
2020-09-22T12:12:17.776+0800 I  NETWORK  [conn251] received client metadata from 211.162.81.126:56620 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:17.777+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56619 #252 (47 connections now open)
2020-09-22T12:12:17.778+0800 I  NETWORK  [conn252] received client metadata from 211.162.81.126:56619 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:17.829+0800 I  NETWORK  [conn252] end connection 211.162.81.126:56619 (46 connections now open)
2020-09-22T12:12:17.829+0800 I  NETWORK  [conn251] end connection 211.162.81.126:56620 (45 connections now open)
2020-09-22T12:12:17.892+0800 I  NETWORK  [conn242] end connection 120.55.194.98:37690 (44 connections now open)
2020-09-22T12:12:18.371+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56621 #253 (45 connections now open)
2020-09-22T12:12:18.372+0800 I  NETWORK  [conn253] received client metadata from 211.162.81.126:56621 conn253: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:18.375+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56622 #254 (46 connections now open)
2020-09-22T12:12:18.376+0800 I  NETWORK  [conn254] received client metadata from 211.162.81.126:56622 conn254: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:18.440+0800 I  NETWORK  [conn253] end connection 211.162.81.126:56621 (45 connections now open)
2020-09-22T12:12:18.442+0800 I  NETWORK  [conn254] end connection 211.162.81.126:56622 (44 connections now open)
2020-09-22T12:12:18.619+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:18.619+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 37
2020-09-22T12:12:18.619+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1116 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:18.619+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1117 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:18.620+0800 I  ELECTION [replexec-5] VoteRequester(term 37 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747937, 2), t: 36 }, my last applied OpTime: { ts: Timestamp(1600747937, 25), t: 37 }"; response message: { term: 37, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747937, 2), t: 36 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000025') }, lastCommittedOpTime: Timestamp(1600747937, 25), $clusterTime: { clusterTime: Timestamp(1600747937, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747937, 25) }
2020-09-22T12:12:18.664+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:12:18.675+0800 I  REPL     [rsBackgroundSync] sync source candidate: 112.124.21.191:27019
2020-09-22T12:12:19.198+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:19.619+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:19.619+0800 I  ELECTION [replexec-0] VoteRequester(term 37 dry run) failed to receive response from 112.124.21.191:27019: NetworkInterfaceExceededTimeLimit: Request 1117 timed out, deadline was 2020-09-22T12:12:19.619+0800, op was RemoteCommand 1117 -- target:[112.124.21.191:27019] db:admin expDate:2020-09-22T12:12:19.619+0800 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:19.619+0800 I  ELECTION [replexec-0] not running for primary, we received insufficient votes
2020-09-22T12:12:19.619+0800 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-09-22T12:12:19.838+0800 I  CONNPOOL [Replication] Ending connection to host 112.124.21.191:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:12:19.838+0800 I  CONNPOOL [Replication] Connecting to 112.124.21.191:27019
2020-09-22T12:12:19.838+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state RS_DOWN - Request 1119 timed out, deadline was 2020-09-22T12:12:19.838+0800, op was RemoteCommand 1119 -- target:[112.124.21.191:27019] db:admin expDate:2020-09-22T12:12:19.838+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "120.55.192.104:27019", fromId: 1, term: 37 }
2020-09-22T12:12:20.305+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 112.124.21.191:27019
2020-09-22T12:12:20.308+0800 I  COMMAND  [conn33] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747939, 12), t: 37 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747939, 12), signature: { hash: BinData(0, 9D4457C4CAB55DE912FEA82CBB50F5A3236B23CF), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747939, 12), t: 37 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 623ms
2020-09-22T12:12:20.486+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55723 #256 (45 connections now open)
2020-09-22T12:12:20.487+0800 I  NETWORK  [conn256] received client metadata from 211.162.81.126:55723 conn256: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:20.488+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55724 #257 (46 connections now open)
2020-09-22T12:12:20.488+0800 I  NETWORK  [conn257] received client metadata from 211.162.81.126:55724 conn257: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:20.542+0800 I  NETWORK  [conn256] end connection 211.162.81.126:55723 (45 connections now open)
2020-09-22T12:12:20.542+0800 I  NETWORK  [conn257] end connection 211.162.81.126:55724 (44 connections now open)
2020-09-22T12:12:21.068+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56623 #259 (45 connections now open)
2020-09-22T12:12:21.069+0800 I  NETWORK  [conn259] received client metadata from 211.162.81.126:56623 conn259: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.076+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55725 #260 (46 connections now open)
2020-09-22T12:12:21.077+0800 I  NETWORK  [conn260] received client metadata from 211.162.81.126:55725 conn260: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.130+0800 I  NETWORK  [conn259] end connection 211.162.81.126:56623 (45 connections now open)
2020-09-22T12:12:21.134+0800 I  NETWORK  [conn260] end connection 211.162.81.126:55725 (44 connections now open)
2020-09-22T12:12:21.766+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56624 #261 (45 connections now open)
2020-09-22T12:12:21.767+0800 I  NETWORK  [conn261] received client metadata from 211.162.81.126:56624 conn261: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.768+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55726 #262 (46 connections now open)
2020-09-22T12:12:21.768+0800 I  NETWORK  [conn262] received client metadata from 211.162.81.126:55726 conn262: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.834+0800 I  NETWORK  [conn262] end connection 211.162.81.126:55726 (45 connections now open)
2020-09-22T12:12:21.834+0800 I  NETWORK  [conn261] end connection 211.162.81.126:56624 (44 connections now open)
2020-09-22T12:12:21.838+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:21.843+0800 I  NETWORK  [conn222] end connection 112.124.21.191:53890 (43 connections now open)
2020-09-22T12:12:22.729+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.729+0800 I  ELECTION [conn221] Sending vote response: { term: 37, voteGranted: true, reason: "" }
2020-09-22T12:12:22.731+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 38, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.731+0800 I  ELECTION [conn221] Sending vote response: { term: 38, voteGranted: true, reason: "" }
2020-09-22T12:12:23.198+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:12:23.756+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55727 #263 (44 connections now open)
2020-09-22T12:12:23.757+0800 I  NETWORK  [conn263] received client metadata from 211.162.81.126:55727 conn263: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:23.759+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56625 #264 (45 connections now open)
2020-09-22T12:12:23.760+0800 I  NETWORK  [conn264] received client metadata from 211.162.81.126:56625 conn264: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:23.822+0800 I  NETWORK  [conn263] end connection 211.162.81.126:55727 (44 connections now open)
2020-09-22T12:12:23.823+0800 I  NETWORK  [conn264] end connection 211.162.81.126:56625 (43 connections now open)
2020-09-22T12:12:23.838+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state PRIMARY
2020-09-22T12:12:23.838+0800 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-09-22T12:12:25.845+0800
2020-09-22T12:12:24.756+0800 I  ELECTION [conn250] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 38, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:24.756+0800 I  ELECTION [conn250] Sending vote response: { term: 38, voteGranted: true, reason: "" }
2020-09-22T12:12:24.758+0800 I  REPL     [conn250] Canceling priority takeover callback
2020-09-22T12:12:24.758+0800 I  ELECTION [conn250] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 39, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:24.758+0800 I  ELECTION [conn250] Sending vote response: { term: 39, voteGranted: true, reason: "" }
2020-09-22T12:12:24.766+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55729 #265 (44 connections now open)
2020-09-22T12:12:24.767+0800 I  NETWORK  [conn265] received client metadata from 211.162.81.126:55729 conn265: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:24.767+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55728 #266 (45 connections now open)
2020-09-22T12:12:24.768+0800 I  NETWORK  [conn266] received client metadata from 211.162.81.126:55728 conn266: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:24.825+0800 I  NETWORK  [conn265] end connection 211.162.81.126:55729 (44 connections now open)
2020-09-22T12:12:24.826+0800 I  NETWORK  [conn266] end connection 211.162.81.126:55728 (43 connections now open)
2020-09-22T12:12:25.160+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 112.124.21.191:27019, my last fetched oplog optime: { ts: Timestamp(1600747942, 17), t: 38 }, latest oplog optime of sync source: { ts: Timestamp(1600747942, 17), t: 38 } (120.55.194.98:27019 is)
2020-09-22T12:12:25.160+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 112.124.21.191:27019, OpTime { ts: Timestamp(1600747942, 17), t: 38 }, its sync source index:-1
2020-09-22T12:12:25.160+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 112.124.21.191:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747942, 17), t: 38 }; sync source index: -1; primary index: 0) is no longer valid
2020-09-22T12:12:25.160+0800 I  REPL     [rsBackgroundSync] Clearing sync source 112.124.21.191:27019 to choose a new one.
2020-09-22T12:12:25.160+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:12:25.161+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:25.161+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:25.364+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:56626 #267 (44 connections now open)
2020-09-22T12:12:25.365+0800 I  NETWORK  [conn267] received client metadata from 211.162.81.126:56626 conn267: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:25.366+0800 I  NETWORK  [listener] connection accepted from 211.162.81.126:55730 #268 (45 connections now open)
2020-09-22T12:12:25.366+0800 I  NETWORK  [conn268] received client metadata from 211.162.81.126:55730 conn268: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:25.424+0800 I  NETWORK  [conn267] end connection 211.162.81.126:56626 (44 connections now open)
2020-09-22T12:12:25.424+0800 I  NETWORK  [conn268] end connection 211.162.81.126:55730 (43 connections now open)
2020-09-22T12:12:25.661+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 112.124.21.191:27019: InvalidSyncSource: Sync source was cleared. Was 112.124.21.191:27019
2020-09-22T12:12:26.161+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:26.250+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:26.250+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 39
2020-09-22T12:12:26.250+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1173 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 39, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.250+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1174 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 39, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.250+0800 I  ELECTION [replexec-3] VoteRequester(term 39 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 39, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747944, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:26.250+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 40
2020-09-22T12:12:26.251+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:26.252+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1175 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.252+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1176 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.252+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:26.253+0800 I  ELECTION [replexec-5] VoteRequester(term 40) received a yes vote from 112.124.21.191:27019; response message: { term: 40, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747944, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:26.253+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 40
2020-09-22T12:12:26.253+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:12:26.253+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-09-22T12:12:26.253+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:12:26.253+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:12:26.661+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:12:26.661+0800 I  REPL     [replexec-6] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747942, 17), t: 38 }. My Last Applied: { ts: Timestamp(1600747942, 17), t: 38 }
2020-09-22T12:12:26.661+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:26.661+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:26.661+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 40
2020-09-22T12:12:26.661+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 40
2020-09-22T12:12:26.661+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:26.661+0800 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: 120.55.194.98:27019
2020-09-22T12:12:26.661+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:26.661+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:26.661+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:26.662+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:26.662+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:26.663+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:26.663+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:26.663+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:27.254+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:27.254+0800 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:27.254+0800 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-09-22T12:12:27.254+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:27.254+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:27.254+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:27.254+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:12:27.254+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:27.255+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:27.388+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:27.388+0800 I  ELECTION [conn221] Sending vote response: { term: 40, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:28.254+0800 I  REPL     [replexec-5] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:28.327+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:28.327+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 40
2020-09-22T12:12:28.327+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1183 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.327+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1184 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.329+0800 I  ELECTION [replexec-0] VoteRequester(term 40 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 40, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747946, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:28.329+0800 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 41
2020-09-22T12:12:28.330+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1185 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.330+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1186 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.332+0800 I  ELECTION [replexec-5] VoteRequester(term 41) received a yes vote from 112.124.21.191:27019; response message: { term: 41, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747946, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:28.332+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 41
2020-09-22T12:12:28.332+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:12:28.332+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-09-22T12:12:28.332+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:12:29.332+0800 I  REPL     [replexec-1] Catchup timed out after becoming primary.
2020-09-22T12:12:29.332+0800 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-09-22T12:12:29.332+0800 I  REPL     [replexec-1] Stopping replication producer
2020-09-22T12:12:29.332+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 41
2020-09-22T12:12:29.332+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 41
2020-09-22T12:12:29.332+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:29.332+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:29.332+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:29.333+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:29.333+0800 I  REPL     [replexec-3] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:29.333+0800 I  REPL     [replexec-3] Stepping down from primary in response to heartbeat
2020-09-22T12:12:29.333+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:29.333+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:12:29.334+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:29.334+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:29.334+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:29.334+0800 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-09-22T12:12:29.334+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:29.335+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:29.335+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:29.335+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:29.336+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:29.357+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:29.357+0800 I  ELECTION [conn221] Sending vote response: { term: 41, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:30.333+0800 I  REPL     [replexec-5] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:30.341+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:30.341+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 41
2020-09-22T12:12:30.341+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1190 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.341+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1191 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.341+0800 I  ELECTION [replexec-4] VoteRequester(term 41 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 41, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747949, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:30.341+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 42
2020-09-22T12:12:30.342+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1192 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.342+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1193 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.344+0800 I  ELECTION [replexec-5] VoteRequester(term 42) received a yes vote from 112.124.21.191:27019; response message: { term: 42, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747949, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:30.344+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 42
2020-09-22T12:12:30.344+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:12:30.344+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-09-22T12:12:30.344+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] Catchup timed out after becoming primary.
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-09-22T12:12:31.344+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 42
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:31.344+0800 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:31.344+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:31.437+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:31.437+0800 I  ELECTION [conn221] Sending vote response: { term: 42, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:32.344+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:32.353+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:32.353+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 42
2020-09-22T12:12:32.353+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1197 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.353+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1198 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.353+0800 I  ELECTION [replexec-2] VoteRequester(term 42 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 42, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747950, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:32.353+0800 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 43
2020-09-22T12:12:32.354+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1199 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.354+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1200 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.356+0800 I  ELECTION [replexec-4] VoteRequester(term 43) received a yes vote from 112.124.21.191:27019; response message: { term: 43, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747950, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:32.356+0800 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 43
2020-09-22T12:12:32.356+0800 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-09-22T12:12:32.356+0800 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-09-22T12:12:32.356+0800 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] Catchup timed out after becoming primary.
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-09-22T12:12:33.356+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 43
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:33.356+0800 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:33.356+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:33.502+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:33.502+0800 I  ELECTION [conn221] Sending vote response: { term: 43, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:34.356+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:34.473+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:34.473+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 43
2020-09-22T12:12:34.473+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1204 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.473+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1205 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.473+0800 I  ELECTION [replexec-0] VoteRequester(term 43 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 43, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747952, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:34.473+0800 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 44
2020-09-22T12:12:34.475+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1206 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.475+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1207 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.476+0800 I  ELECTION [replexec-2] VoteRequester(term 44) received a yes vote from 112.124.21.191:27019; response message: { term: 44, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747952, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:34.476+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 44
2020-09-22T12:12:34.476+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:34.476+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:12:34.476+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:35.476+0800 I  REPL     [replexec-6] Catchup timed out after becoming primary.
2020-09-22T12:12:35.476+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:12:35.476+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:12:35.476+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 44
2020-09-22T12:12:35.476+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 44
2020-09-22T12:12:35.476+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:35.476+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:35.476+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:35.477+0800 I  REPL     [replexec-5] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:35.477+0800 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:35.477+0800 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-09-22T12:12:35.477+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:35.477+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:12:35.478+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:35.478+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:35.478+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:35.478+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:12:35.478+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:35.478+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:35.478+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:35.478+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:35.478+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:35.539+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:35.539+0800 I  ELECTION [conn221] Sending vote response: { term: 44, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:36.477+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:36.488+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:36.488+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 44
2020-09-22T12:12:36.488+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1211 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.488+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1212 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.488+0800 I  ELECTION [replexec-1] VoteRequester(term 44 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 44, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747955, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:36.488+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 45
2020-09-22T12:12:36.489+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1213 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.489+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1214 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.491+0800 I  ELECTION [replexec-2] VoteRequester(term 45) received a yes vote from 112.124.21.191:27019; response message: { term: 45, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747955, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:36.491+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 45
2020-09-22T12:12:36.491+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:36.491+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-09-22T12:12:36.491+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] Catchup timed out after becoming primary.
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-09-22T12:12:37.491+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 45
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:37.491+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:37.491+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:37.502+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:37.502+0800 I  ELECTION [conn221] Sending vote response: { term: 45, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:38.491+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:38.573+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:38.573+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 45
2020-09-22T12:12:38.573+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1221 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.573+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1222 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.573+0800 I  ELECTION [replexec-4] VoteRequester(term 45 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 45, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747956, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 46
2020-09-22T12:12:38.574+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:38.574+0800 I  ELECTION [conn221] Sending vote response: { term: 46, voteGranted: false, reason: "candidate's term (45) is lower than mine (46)" }
2020-09-22T12:12:38.575+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1223 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.575+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1224 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.576+0800 I  ELECTION [replexec-1] VoteRequester(term 46) received a yes vote from 112.124.21.191:27019; response message: { term: 46, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747956, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:38.576+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 46
2020-09-22T12:12:38.576+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:12:38.576+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:12:38.576+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:12:39.576+0800 I  REPL     [replexec-5] Catchup timed out after becoming primary.
2020-09-22T12:12:39.576+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:12:39.576+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:12:39.576+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 46
2020-09-22T12:12:39.576+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 46
2020-09-22T12:12:39.576+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:39.576+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:39.576+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:39.577+0800 I  REPL     [replexec-6] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:39.577+0800 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:39.577+0800 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-09-22T12:12:39.577+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:39.577+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:12:39.578+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:39.578+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:39.578+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:39.578+0800 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-09-22T12:12:39.578+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:39.578+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:39.578+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:39.578+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:39.578+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:39.603+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:39.603+0800 I  ELECTION [conn221] Sending vote response: { term: 46, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:40.577+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:40.639+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:40.639+0800 I  ELECTION [conn221] Sending vote response: { term: 46, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:40.712+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:40.712+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 46
2020-09-22T12:12:40.712+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1228 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.712+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1229 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.712+0800 I  ELECTION [replexec-0] VoteRequester(term 46 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 46, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747959, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:40.713+0800 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 47
2020-09-22T12:12:40.714+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1230 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.714+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1231 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.720+0800 I  ELECTION [replexec-1] VoteRequester(term 47) received a yes vote from 112.124.21.191:27019; response message: { term: 47, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747959, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:40.720+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 47
2020-09-22T12:12:40.720+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:12:40.720+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:12:40.720+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:12:41.720+0800 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-09-22T12:12:41.720+0800 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-09-22T12:12:41.720+0800 I  REPL     [replexec-2] Stopping replication producer
2020-09-22T12:12:41.720+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 47
2020-09-22T12:12:41.720+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 47
2020-09-22T12:12:41.720+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:41.720+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:41.720+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:41.721+0800 I  REPL     [replexec-4] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:41.721+0800 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:41.721+0800 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-09-22T12:12:41.721+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:41.721+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:12:41.722+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:41.722+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:41.722+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:41.722+0800 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-09-22T12:12:41.722+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:41.722+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:41.722+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:41.722+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:41.722+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:41.783+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:41.783+0800 I  ELECTION [conn221] Sending vote response: { term: 47, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:42.721+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:42.763+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:42.763+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 47
2020-09-22T12:12:42.763+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1235 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.763+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1236 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.764+0800 I  ELECTION [replexec-3] VoteRequester(term 47 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 47, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747961, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:42.764+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 48
2020-09-22T12:12:42.765+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1237 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.765+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1238 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.766+0800 I  ELECTION [replexec-1] VoteRequester(term 48) received a yes vote from 112.124.21.191:27019; response message: { term: 48, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747961, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:42.766+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 48
2020-09-22T12:12:42.766+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:12:42.766+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:12:42.766+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:12:43.766+0800 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-09-22T12:12:43.766+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:12:43.766+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:12:43.766+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 48
2020-09-22T12:12:43.766+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 48
2020-09-22T12:12:43.766+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:43.766+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:43.766+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:43.768+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:43.768+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:43.769+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:43.769+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:43.769+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:44.762+0800 I  REPL     [replexec-0] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:44.762+0800 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:44.762+0800 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-09-22T12:12:44.762+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:44.762+0800 W  COMMAND  [conn152] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.762+0800 I  COMMAND  [conn152] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.02:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.02:27017", ping: new Date(1600747950621), up: 129, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.02" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747950, 1), signature: { hash: BinData(0, 8AC6094F7FD44DB8447818411C90F7C8EF1B8284), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 929ms
2020-09-22T12:12:44.763+0800 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.763+0800 I  COMMAND  [conn37] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.00:27018:1600747823:-5900587996018832451" }, update: { $set: { ping: new Date(1600747948233) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747963, 1), signature: { hash: BinData(0, A01A7D8320AF7FD68640FEA90EC890321336B19E), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 524ms
2020-09-22T12:12:44.763+0800 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.763+0800 I  COMMAND  [conn43] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.02:27018:1600747823:-4430192164990820571" }, update: { $set: { ping: new Date(1600747948233) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747947, 42), signature: { hash: BinData(0, 8FE8DA24944323703D3655BE94B00FC7374B8EA2), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 525ms
2020-09-22T12:12:44.764+0800 W  COMMAND  [conn40] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.764+0800 I  COMMAND  [conn40] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.01:27018:1600747823:-5358775017967458485" }, update: { $set: { ping: new Date(1600747947736) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747963, 1), signature: { hash: BinData(0, A01A7D8320AF7FD68640FEA90EC890321336B19E), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 522ms
2020-09-22T12:12:44.764+0800 W  COMMAND  [conn24] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.764+0800 I  COMMAND  [conn24] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.00:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.00:27017", ping: new Date(1600747950614), up: 129, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.00" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747950, 1), signature: { hash: BinData(0, 8AC6094F7FD44DB8447818411C90F7C8EF1B8284), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 644ms
2020-09-22T12:12:44.765+0800 W  COMMAND  [conn33] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:12:44.765+0800 I  COMMAND  [conn33] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.01:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.01:27017", ping: new Date(1600747950314), up: 129, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.01" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747949, 1), signature: { hash: BinData(0, D6EA77437CA8DEB049FFCD007F35A83F3F60E99B), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747942, 17), t: 38 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 944ms
2020-09-22T12:12:44.766+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:44.766+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 6, userOpsRunning: 0 }
2020-09-22T12:12:44.766+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:12:44.766+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:12:44.766+0800 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1600747964180) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:497 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 586ms
2020-09-22T12:12:44.766+0800 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:12:44.767+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:44.767+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:44.817+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:44.817+0800 I  ELECTION [conn221] Sending vote response: { term: 48, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:45.826+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:45.826+0800 I  ELECTION [conn221] Sending vote response: { term: 48, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:45.828+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:45.828+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 48
2020-09-22T12:12:45.828+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1248 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.828+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1249 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.828+0800 I  ELECTION [replexec-1] VoteRequester(term 48 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 48, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747964, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:45.828+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 49
2020-09-22T12:12:45.830+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1250 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.830+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1251 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.833+0800 I  ELECTION [replexec-0] VoteRequester(term 49) received a yes vote from 112.124.21.191:27019; response message: { term: 49, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747964, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:45.833+0800 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 49
2020-09-22T12:12:45.833+0800 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-09-22T12:12:45.833+0800 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-09-22T12:12:45.833+0800 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-09-22T12:12:46.252+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:46.766+0800 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747942, 17), t: 38 }. My Last Applied: { ts: Timestamp(1600747964, 5), t: 48 }
2020-09-22T12:12:46.766+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:12:46.766+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:12:46.766+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 49
2020-09-22T12:12:46.766+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 49
2020-09-22T12:12:46.766+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:46.766+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:46.766+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:46.767+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:46.767+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:46.768+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:46.833+0800 I  REPL     [replexec-2] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:46.833+0800 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:46.833+0800 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-09-22T12:12:46.833+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:46.836+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:46.836+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 6, userOpsRunning: 0 }
2020-09-22T12:12:46.836+0800 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-09-22T12:12:46.836+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:12:46.837+0800 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: Error waiting for snapshot not less than { ts: Timestamp(1600747964, 2), t: 48 }, current relevant optime is { ts: Timestamp(1600747942, 17), t: 38 }. :: caused by :: operation was interrupted
2020-09-22T12:12:46.837+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:46.837+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:46.837+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:46.876+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:46.876+0800 I  ELECTION [conn221] Sending vote response: { term: 49, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:47.833+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:47.956+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:47.956+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 49
2020-09-22T12:12:47.956+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1255 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.956+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1256 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.956+0800 I  ELECTION [replexec-5] VoteRequester(term 49 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 49, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747966, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:47.956+0800 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 50
2020-09-22T12:12:47.958+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1257 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.958+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1258 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.959+0800 I  ELECTION [replexec-1] VoteRequester(term 50) received a yes vote from 112.124.21.191:27019; response message: { term: 50, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747966, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:47.959+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 50
2020-09-22T12:12:47.959+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:12:47.959+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:12:47.959+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:12:48.959+0800 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-09-22T12:12:48.959+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:12:48.959+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:12:48.959+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 50
2020-09-22T12:12:48.959+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 50
2020-09-22T12:12:48.959+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:48.959+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:48.959+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:48.960+0800 I  REPL     [replexec-3] Member 112.124.21.191:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:12:48.960+0800 I  REPL     [replexec-3] can't see a majority of the set, relinquishing primary
2020-09-22T12:12:48.960+0800 I  REPL     [replexec-3] Stepping down from primary in response to heartbeat
2020-09-22T12:12:48.960+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:48.960+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:12:48.961+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:48.961+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:48.961+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:48.961+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:48.961+0800 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-09-22T12:12:48.961+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:48.961+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:48.961+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:48.961+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:12:49.091+0800 I  ELECTION [conn221] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:49.091+0800 I  ELECTION [conn221] Sending vote response: { term: 50, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:12:49.960+0800 I  REPL     [replexec-1] Member 112.124.21.191:27019 is now in state SECONDARY
2020-09-22T12:12:50.019+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:50.019+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 50
2020-09-22T12:12:50.019+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1262 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.019+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1263 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.020+0800 I  ELECTION [replexec-2] VoteRequester(term 50 dry run) received a yes vote from 112.124.21.191:27019; response message: { term: 50, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747968, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:50.020+0800 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 51
2020-09-22T12:12:50.022+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1264 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 51, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.022+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1265 -- target:112.124.21.191:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 51, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.024+0800 I  ELECTION [replexec-1] VoteRequester(term 51) received a yes vote from 112.124.21.191:27019; response message: { term: 51, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000026') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747968, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747942, 17) }
2020-09-22T12:12:50.024+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 51
2020-09-22T12:12:50.024+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:12:50.024+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:12:50.024+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
