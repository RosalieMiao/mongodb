2020-09-22T12:10:13.620+0800 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-09-22T12:10:13.630+0800 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] MongoDB starting : pid=3422 port=27019 dbpath=/var/lib/mongodb 64-bit host=Jepsen-Node-01
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] db version v4.2.6
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0g  2 Nov 2017
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] modules: none
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] build environment:
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten]     distmod: debian92
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten]     distarch: x86_64
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-09-22T12:10:13.630+0800 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-09-22T12:10:13.630+0800 I  STORAGE  [initandlisten] 
2020-09-22T12:10:13.630+0800 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-09-22T12:10:13.630+0800 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-09-22T12:10:13.630+0800 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=487M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-09-22T12:10:14.324+0800 I  STORAGE  [initandlisten] WiredTiger message [1600747814:324534][3422:0x7f11291ddb00], txn-recover: Set global recovery timestamp: (0, 0)
2020-09-22T12:10:14.339+0800 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-09-22T12:10:14.356+0800 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-09-22T12:10:14.366+0800 I  CONTROL  [initandlisten] 
2020-09-22T12:10:14.366+0800 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-09-22T12:10:14.366+0800 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-09-22T12:10:14.366+0800 I  CONTROL  [initandlisten] 
2020-09-22T12:10:14.367+0800 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-09-22T12:10:14.367+0800 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-09-22T12:10:14.367+0800 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-09-22T12:10:14.367+0800 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-09-22T12:10:14.368+0800 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: d151d9e2-f4f6-41be-b68f-4cca6947be99 and options: { capped: true, size: 10485760 }
2020-09-22T12:10:14.382+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-09-22T12:10:14.382+0800 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-09-22T12:10:14.382+0800 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-09-22T12:10:14.386+0800 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 8102d3d7-7799-4210-957f-4566478bc17a and options: {}
2020-09-22T12:10:14.387+0800 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-09-22T12:10:14.387+0800 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-09-22T12:10:14.397+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-09-22T12:10:14.398+0800 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 1482664b-f70f-4d8e-8e67-56a6eda728f6 and options: {}
2020-09-22T12:10:14.409+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-09-22T12:10:14.409+0800 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-09-22T12:10:14.409+0800 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: e52dd110-1cb2-4eae-9445-b34ccfc2a62b and options: {}
2020-09-22T12:10:14.421+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-09-22T12:10:14.421+0800 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-09-22T12:10:14.421+0800 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-09-22T12:10:14.421+0800 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-09-22T12:10:14.421+0800 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 7a82fc02-8106-49e2-9d28-24b2decc723f and options: {}
2020-09-22T12:10:14.432+0800 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-09-22T12:10:14.432+0800 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-09-22T12:10:14.432+0800 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-09-22T12:10:14.432+0800 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-09-22T12:10:14.434+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("c52122bf-8280-4b3c-88d5-945fa4d132d2"), lastMod: 0 } took 0 ms
2020-09-22T12:10:14.434+0800 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-09-22T12:10:14.434+0800 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-09-22T12:10:14.434+0800 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-09-22T12:10:14.434+0800 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-09-22T12:10:14.434+0800 I  NETWORK  [listener] Listening on 0.0.0.0
2020-09-22T12:10:14.434+0800 I  NETWORK  [listener] waiting for connections on port 27019
2020-09-22T12:10:15.000+0800 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-09-22T12:10:15.734+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58310 #1 (1 connection now open)
2020-09-22T12:10:15.734+0800 I  NETWORK  [conn1] received client metadata from 114.212.84.175:58310 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:15.739+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58312 #2 (2 connections now open)
2020-09-22T12:10:15.740+0800 I  NETWORK  [conn2] received client metadata from 114.212.84.175:58312 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:15.858+0800 I  NETWORK  [conn1] end connection 114.212.84.175:58310 (1 connection now open)
2020-09-22T12:10:15.859+0800 I  NETWORK  [conn2] end connection 114.212.84.175:58312 (0 connections now open)
2020-09-22T12:10:16.405+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:60960 #3 (1 connection now open)
2020-09-22T12:10:16.406+0800 I  NETWORK  [conn3] end connection 120.55.194.98:60960 (0 connections now open)
2020-09-22T12:10:16.406+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:60964 #4 (1 connection now open)
2020-09-22T12:10:16.406+0800 I  NETWORK  [conn4] received client metadata from 120.55.194.98:60964 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:16.407+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:16.913+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34632 #8 (2 connections now open)
2020-09-22T12:10:16.914+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:59294 #10 (3 connections now open)
2020-09-22T12:10:16.914+0800 I  NETWORK  [conn8] end connection 120.55.192.104:34632 (2 connections now open)
2020-09-22T12:10:16.914+0800 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: b2abe12d-e007-4f4c-9c8d-f0dd82157e48 and options: {}
2020-09-22T12:10:16.915+0800 I  NETWORK  [conn10] end connection 112.124.21.191:59294 (1 connection now open)
2020-09-22T12:10:16.927+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34634 #11 (2 connections now open)
2020-09-22T12:10:16.928+0800 I  NETWORK  [conn11] received client metadata from 120.55.192.104:34634 conn11: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:16.929+0800 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-09-22T12:10:16.930+0800 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "120.55.194.98:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "120.55.192.104:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "112.124.21.191:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5f697928513fac20f0ca1972') } }
2020-09-22T12:10:16.930+0800 I  REPL     [replexec-0] This node is 112.124.21.191:27019 in the config
2020-09-22T12:10:16.930+0800 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-09-22T12:10:16.930+0800 I  CONNPOOL [Replication] Connecting to 120.55.192.104:27019
2020-09-22T12:10:16.931+0800 I  REPL     [replexec-0] Starting replication storage threads
2020-09-22T12:10:16.931+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:16.932+0800 I  REPL     [replexec-1] Member 120.55.192.104:27019 is now in state STARTUP2
2020-09-22T12:10:16.935+0800 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: f517813e-808a-4f7e-8995-b4335b78036a and options: { temp: true }
2020-09-22T12:10:16.948+0800 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-09-22T12:10:16.948+0800 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-09-22T12:10:16.948+0800 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (f517813e-808a-4f7e-8995-b4335b78036a).
2020-09-22T12:10:16.950+0800 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 338dd8c5-0518-4382-9151-abd48e4b7f4b and options: { temp: true }
2020-09-22T12:10:16.966+0800 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-09-22T12:10:16.967+0800 I  REPL     [replication-0] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:16.967+0800 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-09-22T12:10:16.967+0800 I  REPL     [replication-0] ******
2020-09-22T12:10:16.967+0800 I  REPL     [replication-0] creating replication oplog of size: 990MB...
2020-09-22T12:10:16.967+0800 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: 477d0d41-d086-4de0-8032-fc0065aabf88 and options: { capped: true, size: 1038090240, autoIndexId: false }
2020-09-22T12:10:16.972+0800 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-09-22T12:10:16.972+0800 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-09-22T12:10:16.972+0800 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:10:16.972+0800 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-09-22T12:10:17.006+0800 I  REPL     [replication-0] ******
2020-09-22T12:10:17.007+0800 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-09-22T12:10:17.007+0800 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-09-22T12:10:17.017+0800 I  SHARDING [replication-0] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-09-22T12:10:17.017+0800 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.version
2020-09-22T12:10:17.018+0800 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 7e4950ec-424a-4bdd-ab0e-79368851545a and options: { uuid: UUID("7e4950ec-424a-4bdd-ab0e-79368851545a") }
2020-09-22T12:10:17.031+0800 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-09-22T12:10:17.031+0800 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:17.033+0800 I  COMMAND  [repl-writer-worker-4] setting featureCompatibilityVersion to 4.2
2020-09-22T12:10:17.033+0800 I  NETWORK  [repl-writer-worker-4] Skip closing connection for connection # 11
2020-09-22T12:10:17.033+0800 I  NETWORK  [repl-writer-worker-4] Skip closing connection for connection # 4
2020-09-22T12:10:17.033+0800 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-09-22T12:10:17.033+0800 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-09-22T12:10:17.036+0800 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
2020-09-22T12:10:17.037+0800 I  INITSYNC [replication-0] Finished cloning data: OK. Beginning oplog replay.
2020-09-22T12:10:17.037+0800 I  INITSYNC [replication-1] No need to apply operations. (currently at { : Timestamp(1600747816, 1) })
2020-09-22T12:10:17.038+0800 I  SHARDING [replication-0] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-09-22T12:10:17.038+0800 I  CONNPOOL [replication-0] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:17.038+0800 I  INITSYNC [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
2020-09-22T12:10:17.038+0800 I  INITSYNC [replication-0] Initial sync attempt finishing up.
2020-09-22T12:10:17.038+0800 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1600747816948), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1600747816, 1), initialSyncOplogEnd: Timestamp(1600747816, 1), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1600747817016), end: new Date(1600747817037), elapsedMillis: 21, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1600747817017), end: new Date(1600747817037), elapsedMillis: 20, receivedBatches: 1 } } } }
2020-09-22T12:10:17.038+0800 I  STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (338dd8c5-0518-4382-9151-abd48e4b7f4b).
2020-09-22T12:10:17.040+0800 I  SHARDING [replication-1] Marking collection config.transactions as collection version: <unsharded>
2020-09-22T12:10:17.041+0800 I  INITSYNC [replication-1] initial sync done; took 0s.
2020-09-22T12:10:17.041+0800 I  REPL     [replication-1] transition to RECOVERING from STARTUP2
2020-09-22T12:10:17.041+0800 I  REPL     [replication-1] Starting replication fetcher thread
2020-09-22T12:10:17.041+0800 I  REPL     [replication-1] Starting replication applier thread
2020-09-22T12:10:17.041+0800 I  REPL     [rsSync-0] Starting oplog application
2020-09-22T12:10:17.041+0800 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-09-22T12:10:17.041+0800 I  REPL     [replication-1] Starting replication reporter thread
2020-09-22T12:10:17.041+0800 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-09-22T12:10:17.041+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:17.534+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747816, 1), t: -1 } }
2020-09-22T12:10:17.534+0800 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-09-22T12:10:17.536+0800 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747816, 1), t: -1 } }
2020-09-22T12:10:17.536+0800 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-09-22T12:10:17.538+0800 I  NETWORK  [conn4] end connection 120.55.194.98:60964 (1 connection now open)
2020-09-22T12:10:17.539+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:60966 #16 (2 connections now open)
2020-09-22T12:10:17.539+0800 I  NETWORK  [conn16] received client metadata from 120.55.194.98:60966 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:17.542+0800 I  REPL     [replexec-3] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:10:17.542+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:17.621+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58334 #17 (3 connections now open)
2020-09-22T12:10:17.622+0800 I  NETWORK  [conn17] received client metadata from 114.212.84.175:58334 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:17.633+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58348 #18 (4 connections now open)
2020-09-22T12:10:17.634+0800 I  NETWORK  [conn18] received client metadata from 114.212.84.175:58348 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:17.862+0800 I  NETWORK  [conn17] end connection 114.212.84.175:58334 (3 connections now open)
2020-09-22T12:10:17.871+0800 I  NETWORK  [conn18] end connection 114.212.84.175:58348 (2 connections now open)
2020-09-22T12:10:18.564+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36104 #19 (3 connections now open)
2020-09-22T12:10:18.564+0800 I  NETWORK  [conn19] received client metadata from 47.96.5.198:36104 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.573+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36110 #20 (4 connections now open)
2020-09-22T12:10:18.573+0800 I  NETWORK  [conn20] received client metadata from 47.96.5.198:36110 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.579+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51638 #21 (5 connections now open)
2020-09-22T12:10:18.579+0800 I  NETWORK  [conn21] received client metadata from 47.96.16.32:51638 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.582+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:60970 #22 (6 connections now open)
2020-09-22T12:10:18.582+0800 I  NETWORK  [conn22] received client metadata from 120.55.194.98:60970 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.588+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51648 #23 (7 connections now open)
2020-09-22T12:10:18.588+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49054 #24 (8 connections now open)
2020-09-22T12:10:18.588+0800 I  NETWORK  [conn23] received client metadata from 47.96.16.32:51648 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.588+0800 I  NETWORK  [conn24] received client metadata from 118.31.43.238:49054 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:18.736+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:59306 #25 (9 connections now open)
2020-09-22T12:10:18.737+0800 I  NETWORK  [conn25] received client metadata from 112.124.21.191:59306 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:19.042+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:19.043+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:10:19.043+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:10:19.045+0800 I  STORAGE  [repl-writer-worker-2] createCollection: config.transactions with provided UUID: 4053617d-d9e7-479b-91cd-0abf68267354 and options: { uuid: UUID("4053617d-d9e7-479b-91cd-0abf68267354") }
2020-09-22T12:10:19.058+0800 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns config.transactions
2020-09-22T12:10:19.059+0800 I  STORAGE  [repl-writer-worker-9] createCollection: config.chunks with provided UUID: a101121e-0946-4ee4-9c3c-7bb6281db167 and options: { uuid: UUID("a101121e-0946-4ee4-9c3c-7bb6281db167") }
2020-09-22T12:10:19.076+0800 I  INDEX    [repl-writer-worker-9] index build: done building index _id_ on ns config.chunks
2020-09-22T12:10:19.097+0800 I  INDEX    [repl-writer-worker-11] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.097+0800 I  INDEX    [repl-writer-worker-11] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.097+0800 I  STORAGE  [repl-writer-worker-11] Index build initialized: d11041ad-c8bc-4ece-82ee-f7a426cd506d: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.118+0800 I  INDEX    [repl-writer-worker-15] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.118+0800 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.118+0800 I  STORAGE  [repl-writer-worker-15] Index build initialized: 5d5827dc-4d61-409b-9c46-c7a60221b2e3: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.119+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.119+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.121+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-09-22T12:10:19.123+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: d11041ad-c8bc-4ece-82ee-f7a426cd506d: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 3
2020-09-22T12:10:19.125+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.126+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.128+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-09-22T12:10:19.132+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 5d5827dc-4d61-409b-9c46-c7a60221b2e3: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-09-22T12:10:19.149+0800 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-09-22T12:10:19.149+0800 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.149+0800 I  STORAGE  [repl-writer-worker-3] Index build initialized: 5617877c-d918-4cbc-a4b1-d96f077b861a: config.chunks (a101121e-0946-4ee4-9c3c-7bb6281db167 ): indexes: 1
2020-09-22T12:10:19.149+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.150+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.151+0800 I  STORAGE  [repl-writer-worker-8] createCollection: config.migrations with provided UUID: 2a18503c-6359-4f56-9f16-29eed137e385 and options: { uuid: UUID("2a18503c-6359-4f56-9f16-29eed137e385") }
2020-09-22T12:10:19.153+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-09-22T12:10:19.164+0800 I  INDEX    [repl-writer-worker-8] index build: done building index _id_ on ns config.migrations
2020-09-22T12:10:19.169+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 5617877c-d918-4cbc-a4b1-d96f077b861a: config.chunks ( a101121e-0946-4ee4-9c3c-7bb6281db167 ). Index specs built: 1. Indexes in catalog before build: 3. Indexes in catalog after build: 4
2020-09-22T12:10:19.186+0800 I  INDEX    [repl-writer-worker-5] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-09-22T12:10:19.186+0800 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.186+0800 I  STORAGE  [repl-writer-worker-5] Index build initialized: 527d88a3-715d-4ff0-b434-fcd9384e5555: config.migrations (2a18503c-6359-4f56-9f16-29eed137e385 ): indexes: 1
2020-09-22T12:10:19.186+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.186+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.187+0800 I  STORAGE  [repl-writer-worker-12] createCollection: config.shards with provided UUID: 551d8645-5410-46d3-ac48-3f86cc78c694 and options: { uuid: UUID("551d8645-5410-46d3-ac48-3f86cc78c694") }
2020-09-22T12:10:19.189+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_min_1 on ns config.migrations
2020-09-22T12:10:19.200+0800 I  INDEX    [repl-writer-worker-12] index build: done building index _id_ on ns config.shards
2020-09-22T12:10:19.203+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 527d88a3-715d-4ff0-b434-fcd9384e5555: config.migrations ( 2a18503c-6359-4f56-9f16-29eed137e385 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.220+0800 I  INDEX    [repl-writer-worker-15] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-09-22T12:10:19.220+0800 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.220+0800 I  STORAGE  [repl-writer-worker-15] Index build initialized: dd999331-f85e-48fb-9ee9-3a90d885b05c: config.shards (551d8645-5410-46d3-ac48-3f86cc78c694 ): indexes: 1
2020-09-22T12:10:19.220+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.220+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.221+0800 I  STORAGE  [repl-writer-worker-4] createCollection: config.locks with provided UUID: 75fb8f2f-a2b3-49f4-bb93-400680f69951 and options: { uuid: UUID("75fb8f2f-a2b3-49f4-bb93-400680f69951") }
2020-09-22T12:10:19.223+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index host_1 on ns config.shards
2020-09-22T12:10:19.234+0800 I  INDEX    [repl-writer-worker-4] index build: done building index _id_ on ns config.locks
2020-09-22T12:10:19.240+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: dd999331-f85e-48fb-9ee9-3a90d885b05c: config.shards ( 551d8645-5410-46d3-ac48-3f86cc78c694 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.250+0800 I  INDEX    [repl-writer-worker-2] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-09-22T12:10:19.250+0800 I  INDEX    [repl-writer-worker-2] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.250+0800 I  STORAGE  [repl-writer-worker-2] Index build initialized: abc8c513-9b9e-4c18-abde-89502bfb3fa1: config.locks (75fb8f2f-a2b3-49f4-bb93-400680f69951 ): indexes: 1
2020-09-22T12:10:19.250+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.251+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.253+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ts_1 on ns config.locks
2020-09-22T12:10:19.255+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: abc8c513-9b9e-4c18-abde-89502bfb3fa1: config.locks ( 75fb8f2f-a2b3-49f4-bb93-400680f69951 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.269+0800 I  INDEX    [repl-writer-worker-6] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-09-22T12:10:19.269+0800 I  INDEX    [repl-writer-worker-6] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.269+0800 I  STORAGE  [repl-writer-worker-6] Index build initialized: 65cc1009-9da4-4f26-872a-4cb68ad630ca: config.locks (75fb8f2f-a2b3-49f4-bb93-400680f69951 ): indexes: 1
2020-09-22T12:10:19.270+0800 I  STORAGE  [repl-writer-worker-13] createCollection: config.lockpings with provided UUID: 990ea228-4f92-4ac6-83ef-83a3dd549ffd and options: { uuid: UUID("990ea228-4f92-4ac6-83ef-83a3dd549ffd") }
2020-09-22T12:10:19.270+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.282+0800 I  INDEX    [repl-writer-worker-13] index build: done building index _id_ on ns config.lockpings
2020-09-22T12:10:19.285+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.287+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index state_1_process_1 on ns config.locks
2020-09-22T12:10:19.288+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: 65cc1009-9da4-4f26-872a-4cb68ad630ca: config.locks ( 75fb8f2f-a2b3-49f4-bb93-400680f69951 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-09-22T12:10:19.302+0800 I  INDEX    [repl-writer-worker-0] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-09-22T12:10:19.302+0800 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.302+0800 I  STORAGE  [repl-writer-worker-0] Index build initialized: 3014c0e4-e0a6-41b2-b7cd-d902f96c0a3b: config.lockpings (990ea228-4f92-4ac6-83ef-83a3dd549ffd ): indexes: 1
2020-09-22T12:10:19.302+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.303+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.306+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ping_1 on ns config.lockpings
2020-09-22T12:10:19.306+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 3014c0e4-e0a6-41b2-b7cd-d902f96c0a3b: config.lockpings ( 990ea228-4f92-4ac6-83ef-83a3dd549ffd ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.308+0800 I  STORAGE  [repl-writer-worker-1] createCollection: config.tags with provided UUID: 90449d01-a92c-4bc8-b6f6-bf9774d459a2 and options: { uuid: UUID("90449d01-a92c-4bc8-b6f6-bf9774d459a2") }
2020-09-22T12:10:19.320+0800 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.tags
2020-09-22T12:10:19.337+0800 I  INDEX    [repl-writer-worker-9] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-09-22T12:10:19.337+0800 I  INDEX    [repl-writer-worker-9] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.337+0800 I  STORAGE  [repl-writer-worker-9] Index build initialized: ef49aa9e-c9ec-4ab8-a903-aee451cf7326: config.tags (90449d01-a92c-4bc8-b6f6-bf9774d459a2 ): indexes: 1
2020-09-22T12:10:19.338+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.338+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.343+0800 I  INDEX    [IndexBuildsCoordinatorMongod-1] index build: done building index ns_1_min_1 on ns config.tags
2020-09-22T12:10:19.344+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-1] Index build completed successfully: ef49aa9e-c9ec-4ab8-a903-aee451cf7326: config.tags ( 90449d01-a92c-4bc8-b6f6-bf9774d459a2 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-09-22T12:10:19.357+0800 I  INDEX    [repl-writer-worker-5] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-09-22T12:10:19.357+0800 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-09-22T12:10:19.357+0800 I  STORAGE  [repl-writer-worker-5] Index build initialized: 932566a1-bd11-4fc1-9df9-57d6ffe5adf5: config.tags (90449d01-a92c-4bc8-b6f6-bf9774d459a2 ): indexes: 1
2020-09-22T12:10:19.357+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-09-22T12:10:19.358+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-09-22T12:10:19.360+0800 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-09-22T12:10:19.361+0800 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 932566a1-bd11-4fc1-9df9-57d6ffe5adf5: config.tags ( 90449d01-a92c-4bc8-b6f6-bf9774d459a2 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-09-22T12:10:19.362+0800 I  STORAGE  [repl-writer-worker-13] createCollection: config.version with provided UUID: 040e4fca-70a7-4d42-aac8-66895ee93871 and options: { uuid: UUID("040e4fca-70a7-4d42-aac8-66895ee93871") }
2020-09-22T12:10:19.373+0800 I  INDEX    [repl-writer-worker-13] index build: done building index _id_ on ns config.version
2020-09-22T12:10:19.374+0800 I  SHARDING [repl-writer-worker-11] Marking collection config.lockpings as collection version: <unsharded>
2020-09-22T12:10:19.374+0800 I  SHARDING [repl-writer-worker-11] Marking collection config.version as collection version: <unsharded>
2020-09-22T12:10:19.398+0800 I  STORAGE  [replication-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1600747816, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1600747818, 5)
2020-09-22T12:10:19.398+0800 I  SHARDING [conn20] Marking collection config.shards as collection version: <unsharded>
2020-09-22T12:10:19.399+0800 I  COMMAND  [conn20] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 823ms
2020-09-22T12:10:19.399+0800 I  COMMAND  [conn23] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 808ms
2020-09-22T12:10:19.403+0800 I  STORAGE  [repl-writer-worker-7] createCollection: admin.system.keys with provided UUID: 394a26b5-28ef-428f-a02a-72801fb5a7a6 and options: { uuid: UUID("394a26b5-28ef-428f-a02a-72801fb5a7a6") }
2020-09-22T12:10:19.422+0800 I  INDEX    [repl-writer-worker-7] index build: done building index _id_ on ns admin.system.keys
2020-09-22T12:10:19.424+0800 I  SHARDING [repl-writer-worker-4] Marking collection admin.system.keys as collection version: <unsharded>
2020-09-22T12:10:19.846+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34648 #27 (10 connections now open)
2020-09-22T12:10:19.846+0800 I  NETWORK  [conn27] received client metadata from 120.55.192.104:34648 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:19.848+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34650 #28 (11 connections now open)
2020-09-22T12:10:19.848+0800 I  NETWORK  [conn28] received client metadata from 120.55.192.104:34650 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:20.390+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49066 #29 (12 connections now open)
2020-09-22T12:10:20.391+0800 I  NETWORK  [conn29] received client metadata from 118.31.43.238:49066 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:20.393+0800 I  SHARDING [conn29] Marking collection config.settings as collection version: <unsharded>
2020-09-22T12:10:20.411+0800 I  STORAGE  [repl-writer-worker-6] createCollection: config.mongos with provided UUID: 282775af-a43f-4c57-858a-851b59ec70fc and options: { uuid: UUID("282775af-a43f-4c57-858a-851b59ec70fc") }
2020-09-22T12:10:20.424+0800 I  INDEX    [repl-writer-worker-6] index build: done building index _id_ on ns config.mongos
2020-09-22T12:10:20.425+0800 I  SHARDING [repl-writer-worker-14] Marking collection config.mongos as collection version: <unsharded>
2020-09-22T12:10:21.378+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:60982 #30 (13 connections now open)
2020-09-22T12:10:21.378+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:59320 #31 (14 connections now open)
2020-09-22T12:10:21.378+0800 I  NETWORK  [conn31] received client metadata from 112.124.21.191:59320 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:21.378+0800 I  NETWORK  [conn30] received client metadata from 120.55.194.98:60982 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:21.382+0800 I  SHARDING [conn31] Marking collection config.collections as collection version: <unsharded>
2020-09-22T12:10:23.012+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36118 #32 (15 connections now open)
2020-09-22T12:10:23.012+0800 I  NETWORK  [conn32] received client metadata from 47.96.5.198:36118 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.014+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49070 #33 (16 connections now open)
2020-09-22T12:10:23.014+0800 I  NETWORK  [conn33] received client metadata from 118.31.43.238:49070 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.015+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51658 #34 (17 connections now open)
2020-09-22T12:10:23.015+0800 I  NETWORK  [conn34] received client metadata from 47.96.16.32:51658 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.035+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36128 #35 (18 connections now open)
2020-09-22T12:10:23.035+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36132 #36 (19 connections now open)
2020-09-22T12:10:23.035+0800 I  NETWORK  [conn35] received client metadata from 47.96.5.198:36128 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.035+0800 I  NETWORK  [conn36] received client metadata from 47.96.5.198:36132 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:23.093+0800 I  STORAGE  [repl-writer-worker-0] createCollection: config.changelog with provided UUID: 4eb1c795-cfa4-4b19-801d-0eab6874e47f and options: { uuid: UUID("4eb1c795-cfa4-4b19-801d-0eab6874e47f"), capped: true, size: 209715200 }
2020-09-22T12:10:23.106+0800 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.changelog
2020-09-22T12:10:23.109+0800 I  SHARDING [repl-writer-worker-1] Marking collection config.changelog as collection version: <unsharded>
2020-09-22T12:10:23.229+0800 I  SHARDING [repl-writer-worker-3] Marking collection config.locks as collection version: <unsharded>
2020-09-22T12:10:23.257+0800 I  STORAGE  [repl-writer-worker-9] createCollection: config.databases with provided UUID: 4d7c98cb-17cc-41c8-adb8-aa748e2229f3 and options: { uuid: UUID("4d7c98cb-17cc-41c8-adb8-aa748e2229f3") }
2020-09-22T12:10:23.267+0800 I  INDEX    [repl-writer-worker-9] index build: done building index _id_ on ns config.databases
2020-09-22T12:10:23.268+0800 I  SHARDING [repl-writer-worker-8] Marking collection config.databases as collection version: <unsharded>
2020-09-22T12:10:23.442+0800 I  SHARDING [conn36] Marking collection config.tags as collection version: <unsharded>
2020-09-22T12:10:23.459+0800 I  SHARDING [repl-writer-worker-9] Marking collection config.chunks as collection version: <unsharded>
2020-09-22T12:10:23.482+0800 I  STORAGE  [repl-writer-worker-14] createCollection: config.collections with provided UUID: aff6d799-d8e5-42bb-9d1a-d8dc37c3bc27 and options: { uuid: UUID("aff6d799-d8e5-42bb-9d1a-d8dc37c3bc27") }
2020-09-22T12:10:23.495+0800 I  INDEX    [repl-writer-worker-14] index build: done building index _id_ on ns config.collections
2020-09-22T12:10:26.052+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58560 #37 (20 connections now open)
2020-09-22T12:10:26.053+0800 I  NETWORK  [conn37] received client metadata from 114.212.84.175:58560 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:26.058+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58566 #38 (21 connections now open)
2020-09-22T12:10:26.058+0800 I  NETWORK  [conn38] received client metadata from 114.212.84.175:58566 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:26.212+0800 I  NETWORK  [conn37] end connection 114.212.84.175:58560 (20 connections now open)
2020-09-22T12:10:26.215+0800 I  NETWORK  [conn38] end connection 114.212.84.175:58566 (19 connections now open)
2020-09-22T12:10:30.970+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51698 #39 (20 connections now open)
2020-09-22T12:10:30.971+0800 I  NETWORK  [conn39] received client metadata from 47.96.16.32:51698 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:32.844+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49124 #40 (21 connections now open)
2020-09-22T12:10:32.844+0800 I  NETWORK  [conn40] received client metadata from 118.31.43.238:49124 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:34.169+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58718 #41 (22 connections now open)
2020-09-22T12:10:34.169+0800 I  NETWORK  [conn41] received client metadata from 114.212.84.175:58718 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.174+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58724 #42 (23 connections now open)
2020-09-22T12:10:34.175+0800 I  NETWORK  [conn42] received client metadata from 114.212.84.175:58724 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.313+0800 I  NETWORK  [conn41] end connection 114.212.84.175:58718 (22 connections now open)
2020-09-22T12:10:34.314+0800 I  NETWORK  [conn42] end connection 114.212.84.175:58724 (21 connections now open)
2020-09-22T12:10:34.763+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58732 #43 (22 connections now open)
2020-09-22T12:10:34.764+0800 I  NETWORK  [conn43] received client metadata from 114.212.84.175:58732 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.775+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58736 #44 (23 connections now open)
2020-09-22T12:10:34.776+0800 I  NETWORK  [conn44] received client metadata from 114.212.84.175:58736 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:34.929+0800 I  NETWORK  [conn43] end connection 114.212.84.175:58732 (22 connections now open)
2020-09-22T12:10:34.934+0800 I  NETWORK  [conn44] end connection 114.212.84.175:58736 (21 connections now open)
2020-09-22T12:10:35.651+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58762 #45 (22 connections now open)
2020-09-22T12:10:35.651+0800 I  NETWORK  [conn45] received client metadata from 114.212.84.175:58762 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:35.659+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58766 #46 (23 connections now open)
2020-09-22T12:10:35.660+0800 I  NETWORK  [conn46] received client metadata from 114.212.84.175:58766 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:35.810+0800 I  NETWORK  [conn45] end connection 114.212.84.175:58762 (22 connections now open)
2020-09-22T12:10:35.814+0800 I  NETWORK  [conn46] end connection 114.212.84.175:58766 (21 connections now open)
2020-09-22T12:10:38.669+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58840 #47 (22 connections now open)
2020-09-22T12:10:38.669+0800 I  NETWORK  [conn47] received client metadata from 114.212.84.175:58840 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:38.677+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58838 #48 (23 connections now open)
2020-09-22T12:10:38.678+0800 I  NETWORK  [conn48] received client metadata from 114.212.84.175:58838 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:38.818+0800 I  NETWORK  [conn47] end connection 114.212.84.175:58840 (22 connections now open)
2020-09-22T12:10:38.822+0800 I  NETWORK  [conn48] end connection 114.212.84.175:58838 (21 connections now open)
2020-09-22T12:10:39.700+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:10:39.700+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 1
2020-09-22T12:10:39.700+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 516 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.700+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 517 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.700+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:39.701+0800 I  ELECTION [replexec-1] VoteRequester(term 1 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747831, 5), $clusterTime: { clusterTime: Timestamp(1600747838, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747831, 5) }
2020-09-22T12:10:39.701+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 2
2020-09-22T12:10:39.702+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 518 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.702+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 519 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:39.703+0800 I  ELECTION [replexec-3] VoteRequester(term 2) received a yes vote from 120.55.192.104:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747831, 5), $clusterTime: { clusterTime: Timestamp(1600747838, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747831, 5) }
2020-09-22T12:10:39.703+0800 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 2
2020-09-22T12:10:39.703+0800 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-09-22T12:10:39.703+0800 I  REPL     [replexec-3] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:10:39.704+0800 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-09-22T12:10:39.704+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:10:40.452+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:10:40.452+0800 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747831, 5), t: 1 }. My Last Applied: { ts: Timestamp(1600747831, 5), t: 1 }
2020-09-22T12:10:40.452+0800 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-09-22T12:10:40.452+0800 I  REPL     [replexec-0] Stopping replication producer
2020-09-22T12:10:40.452+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
2020-09-22T12:10:40.452+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
2020-09-22T12:10:40.452+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:10:40.452+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:40.452+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:40.452+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:40.452+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:40.454+0800 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-09-22T12:10:40.454+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:40.454+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:40.455+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:40.455+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:40.455+0800 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:10:40.456+0800 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-09-22T12:10:40.456+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("ab627ffa-6894-4fde-896e-17748d17e74b"), lastMod: 1 } took 0 ms
2020-09-22T12:10:40.457+0800 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5f69792fb532ea868744a14e took 0 ms
2020-09-22T12:10:40.457+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 118.31.43.238:27018
2020-09-22T12:10:40.457+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 47.96.5.198:27018
2020-09-22T12:10:40.457+0800 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to 47.96.16.32:27018
2020-09-22T12:10:40.464+0800 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-09-22T12:10:40.470+0800 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-09-22T12:10:40.539+0800 I  NETWORK  [conn16] end connection 120.55.194.98:60966 (20 connections now open)
2020-09-22T12:10:40.541+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32798 #55 (21 connections now open)
2020-09-22T12:10:40.541+0800 I  NETWORK  [conn55] received client metadata from 120.55.194.98:32798 conn55: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:40.701+0800 I  CONNPOOL [Replication] Ending idle connection to host 120.55.194.98:27019 because the pool meets constraints; 1 connections to that host remain open
2020-09-22T12:10:40.704+0800 I  REPL     [replexec-1] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:10:40.704+0800 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-09-22T12:10:40.704+0800 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-09-22T12:10:40.704+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:40.704+0800 W  COMMAND  [conn30] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:10:40.704+0800 I  COMMAND  [conn30] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747839, 1), signature: { hash: BinData(0, 54F01E578858B0C73595F12DA012AE968B20DD1B), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 110ms
2020-09-22T12:10:40.705+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:40.705+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 2, userOpsRunning: 0 }
2020-09-22T12:10:40.705+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:10:40.705+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:10:40.706+0800 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-09-22T12:10:40.706+0800 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-09-22T12:10:40.706+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:10:40.958+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:10:41.316+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:10:41.319+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34702 #58 (22 connections now open)
2020-09-22T12:10:41.319+0800 I  NETWORK  [conn58] received client metadata from 120.55.192.104:34702 conn58: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.321+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34704 #59 (23 connections now open)
2020-09-22T12:10:41.321+0800 I  NETWORK  [conn59] received client metadata from 120.55.192.104:34704 conn59: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.434+0800 I  ELECTION [conn55] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747831, 5), t: 1 } }
2020-09-22T12:10:41.434+0800 I  ELECTION [conn55] Sending vote response: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747831, 5), t: 1 }, my last applied OpTime: { ts: Timestamp..." }
2020-09-22T12:10:41.688+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32802 #60 (24 connections now open)
2020-09-22T12:10:41.688+0800 I  NETWORK  [conn60] received client metadata from 120.55.194.98:32802 conn60: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.690+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32804 #61 (25 connections now open)
2020-09-22T12:10:41.691+0800 I  NETWORK  [conn61] received client metadata from 120.55.194.98:32804 conn61: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.704+0800 I  REPL     [replexec-4] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:10:41.717+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:10:41.717+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 2
2020-09-22T12:10:41.717+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 535 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.717+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 536 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.717+0800 I  ELECTION [replexec-0] VoteRequester(term 2 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747831, 5), $clusterTime: { clusterTime: Timestamp(1600747841, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747840, 1) }
2020-09-22T12:10:41.717+0800 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 3
2020-09-22T12:10:41.718+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:41.718+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:41.718+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 537 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.718+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 538 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747840, 1), t: 2 } }
2020-09-22T12:10:41.720+0800 I  ELECTION [replexec-3] VoteRequester(term 3) received a yes vote from 120.55.192.104:27019; response message: { term: 3, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747831, 5), $clusterTime: { clusterTime: Timestamp(1600747841, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747840, 1) }
2020-09-22T12:10:41.720+0800 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 3
2020-09-22T12:10:41.720+0800 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-09-22T12:10:41.720+0800 I  REPL     [replexec-3] Resetting sync source to empty, which was :27017
2020-09-22T12:10:41.720+0800 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-09-22T12:10:41.720+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:41.722+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:41.722+0800 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747840, 1), t: 2 }. My Last Applied: { ts: Timestamp(1600747840, 1), t: 2 }
2020-09-22T12:10:41.722+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:10:41.722+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:10:41.722+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 3
2020-09-22T12:10:41.722+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 3
2020-09-22T12:10:41.722+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:41.722+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:41.722+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:41.723+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:10:41.723+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:41.724+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:41.724+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:41.724+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:41.724+0800 I  CONNPOOL [ShardRegistry] Connecting to 118.31.43.238:27018
2020-09-22T12:10:41.738+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:59386 #65 (26 connections now open)
2020-09-22T12:10:41.739+0800 I  NETWORK  [conn65] received client metadata from 112.124.21.191:59386 conn65: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.868+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34706 #66 (27 connections now open)
2020-09-22T12:10:41.868+0800 I  NETWORK  [conn66] received client metadata from 120.55.192.104:34706 conn66: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:41.958+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49146 #67 (28 connections now open)
2020-09-22T12:10:41.959+0800 I  NETWORK  [conn67] received client metadata from 118.31.43.238:49146 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:42.007+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36206 #68 (29 connections now open)
2020-09-22T12:10:42.007+0800 I  NETWORK  [conn68] received client metadata from 47.96.5.198:36206 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:42.095+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32806 #69 (30 connections now open)
2020-09-22T12:10:42.095+0800 I  NETWORK  [conn69] received client metadata from 120.55.194.98:32806 conn69: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:42.226+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51730 #70 (31 connections now open)
2020-09-22T12:10:42.226+0800 I  NETWORK  [conn70] received client metadata from 47.96.16.32:51730 conn70: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:42.330+0800 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-09-22T12:10:42.330+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:10:42.330+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn31] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 10), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 592ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn65] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-01:27017" }, u: { $set: { _id: "Jepsen-Node-01:27017", ping: new Date(1600747841399), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 10), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 590ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 28), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 462ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn66] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Jepsen-Node-02:27017" }, u: { $set: { _id: "Jepsen-Node-02:27017", ping: new Date(1600747841866), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 28), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 461ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn29] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.01:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.01:27017", ping: new Date(1600747840450), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.01" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 32), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 374ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn67] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 32), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 369ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn20] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 16), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 325ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn68] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.02:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.02:27017", ping: new Date(1600747841412), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.02" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 16), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 321ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn30] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 30), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 236ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn69] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "iZbp157vvbma2xfbxku74xZ:27017" }, u: { $set: { _id: "iZbp157vvbma2xfbxku74xZ:27017", ping: new Date(1600747841401), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747841, 30), signature: { hash: BinData(0, 67A761F7BAF4D4EDA0E7F693CA95AE7DAD976BAA), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 235ms
2020-09-22T12:10:42.330+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747842, 1), signature: { hash: BinData(0, 6136FD4D0F52C2BA53436B8599B59E3F05F5AE9C), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 106ms
2020-09-22T12:10:42.332+0800 I  COMMAND  [conn70] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "Disalg.Hangzhou.I.00:27017" }, u: { $set: { _id: "Disalg.Hangzhou.I.00:27017", ping: new Date(1600747841434), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [ "Disalg.Hangzhou.I.00" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747842, 1), signature: { hash: BinData(0, 6136FD4D0F52C2BA53436B8599B59E3F05F5AE9C), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747831, 5), t: 1 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 103ms
2020-09-22T12:10:43.249+0800 I  ELECTION [conn55] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747842, 3), t: 3 } }
2020-09-22T12:10:43.249+0800 I  ELECTION [conn55] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-09-22T12:10:43.251+0800 I  REPL     [conn55] stepping down from primary, because a new term has begun: 4
2020-09-22T12:10:43.251+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:43.251+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:43.251+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:10:43.251+0800 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-09-22T12:10:43.252+0800 I  ELECTION [conn55] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747842, 3), t: 3 } }
2020-09-22T12:10:43.252+0800 I  ELECTION [conn55] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-09-22T12:10:43.252+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:10:43.253+0800 I  NETWORK  [conn55] end connection 120.55.194.98:32798 (30 connections now open)
2020-09-22T12:10:43.254+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32808 #71 (31 connections now open)
2020-09-22T12:10:43.254+0800 I  NETWORK  [conn71] received client metadata from 120.55.194.98:32808 conn71: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:43.699+0800 I  NETWORK  [conn61] end connection 120.55.194.98:32804 (30 connections now open)
2020-09-22T12:10:43.722+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:44.252+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:10:44.254+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:10:44.255+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:10:47.043+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58972 #73 (31 connections now open)
2020-09-22T12:10:47.045+0800 I  NETWORK  [conn73] received client metadata from 114.212.84.175:58972 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:47.054+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:58964 #74 (32 connections now open)
2020-09-22T12:10:47.055+0800 I  NETWORK  [conn74] received client metadata from 114.212.84.175:58964 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:47.188+0800 I  NETWORK  [conn73] end connection 114.212.84.175:58972 (31 connections now open)
2020-09-22T12:10:47.194+0800 I  NETWORK  [conn74] end connection 114.212.84.175:58964 (30 connections now open)
2020-09-22T12:10:47.881+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:10:47.881+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 4
2020-09-22T12:10:47.881+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 572 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.881+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 573 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.881+0800 I  ELECTION [replexec-4] VoteRequester(term 4 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747844, 1), $clusterTime: { clusterTime: Timestamp(1600747847, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747844, 1) }
2020-09-22T12:10:47.881+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 5
2020-09-22T12:10:47.882+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:47.882+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:47.882+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 574 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.882+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 575 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747844, 1), t: 4 } }
2020-09-22T12:10:47.884+0800 I  ELECTION [replexec-1] VoteRequester(term 5) received a yes vote from 120.55.192.104:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1600747844, 1), $clusterTime: { clusterTime: Timestamp(1600747847, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747844, 1) }
2020-09-22T12:10:47.884+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 5
2020-09-22T12:10:47.884+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:10:47.884+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:10:47.884+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:10:48.081+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747844, 1), t: 4 }; sync source index: -1; primary index: 0) is no longer valid
2020-09-22T12:10:48.197+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59018 #75 (31 connections now open)
2020-09-22T12:10:48.198+0800 I  NETWORK  [conn75] received client metadata from 114.212.84.175:59018 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:48.200+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59026 #76 (32 connections now open)
2020-09-22T12:10:48.200+0800 I  NETWORK  [conn76] received client metadata from 114.212.84.175:59026 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:48.337+0800 I  NETWORK  [conn75] end connection 114.212.84.175:59018 (31 connections now open)
2020-09-22T12:10:48.338+0800 I  NETWORK  [conn76] end connection 114.212.84.175:59026 (30 connections now open)
2020-09-22T12:10:48.580+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:10:48.881+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:10:48.881+0800 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747844, 1), t: 4 }. My Last Applied: { ts: Timestamp(1600747844, 1), t: 4 }
2020-09-22T12:10:48.881+0800 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-09-22T12:10:48.881+0800 I  REPL     [replexec-3] Stopping replication producer
2020-09-22T12:10:48.881+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-09-22T12:10:48.881+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-09-22T12:10:48.881+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:48.881+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:48.881+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:48.882+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:10:48.882+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:48.883+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:48.883+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:48.883+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:48.995+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59036 #79 (31 connections now open)
2020-09-22T12:10:48.995+0800 I  NETWORK  [conn79] received client metadata from 114.212.84.175:59036 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.014+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59042 #80 (32 connections now open)
2020-09-22T12:10:49.015+0800 I  NETWORK  [conn80] received client metadata from 114.212.84.175:59042 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.155+0800 I  NETWORK  [conn79] end connection 114.212.84.175:59036 (31 connections now open)
2020-09-22T12:10:49.160+0800 I  NETWORK  [conn80] end connection 114.212.84.175:59042 (30 connections now open)
2020-09-22T12:10:49.443+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32814 #81 (31 connections now open)
2020-09-22T12:10:49.444+0800 I  NETWORK  [conn81] received client metadata from 120.55.194.98:32814 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:49.444+0800 I  NETWORK  [listener] connection accepted from 112.124.21.191:59398 #82 (32 connections now open)
2020-09-22T12:10:49.444+0800 I  NETWORK  [conn82] received client metadata from 112.124.21.191:59398 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:49.447+0800 I  NETWORK  [listener] connection accepted from 47.96.16.32:51736 #83 (33 connections now open)
2020-09-22T12:10:49.447+0800 I  NETWORK  [conn83] received client metadata from 47.96.16.32:51736 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:49.593+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59056 #84 (34 connections now open)
2020-09-22T12:10:49.594+0800 I  NETWORK  [conn84] received client metadata from 114.212.84.175:59056 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.596+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59062 #85 (35 connections now open)
2020-09-22T12:10:49.597+0800 I  NETWORK  [conn85] received client metadata from 114.212.84.175:59062 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:49.662+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:10:49.662+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:10:49.662+0800 I  COMMAND  [conn69] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 3), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 551ms
2020-09-22T12:10:49.662+0800 I  COMMAND  [conn65] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 3), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 408ms
2020-09-22T12:10:49.662+0800 I  COMMAND  [conn30] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "iZbp157vvbma2xfbxku74xZ:27017:1600747818:7332321692021962316" }, update: { $set: { ping: new Date(1600747849381) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 3), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:648 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 281ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn31] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Jepsen-Node-01:27017:1600747818:8589022375712416522" }, update: { $set: { ping: new Date(1600747849381) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 3), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 280ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn29] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.01:27017:1600747818:3466407884530610701" }, update: { $set: { ping: new Date(1600747849382) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 4), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:645 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 277ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn70] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.00:27017:1600747818:2541039578456057690" }, update: { $set: { ping: new Date(1600747849382) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 4), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:645 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 277ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn68] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.02:27017:1600747818:7156575011715358840" }, update: { $set: { ping: new Date(1600747849381) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 4), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:645 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 273ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 4), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 226ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn20] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 4), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 179ms
2020-09-22T12:10:49.663+0800 I  COMMAND  [conn66] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747848, 3), signature: { hash: BinData(0, D61468C42A4B3DE03BD8A2AA4ABEE77CD44E9619), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747844, 1), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 158ms
2020-09-22T12:10:49.735+0800 I  NETWORK  [conn84] end connection 114.212.84.175:59056 (34 connections now open)
2020-09-22T12:10:49.736+0800 I  NETWORK  [conn85] end connection 114.212.84.175:59062 (33 connections now open)
2020-09-22T12:10:50.044+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32818 #86 (34 connections now open)
2020-09-22T12:10:50.045+0800 I  NETWORK  [conn86] received client metadata from 120.55.194.98:32818 conn86: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:50.417+0800 I  ELECTION [conn11] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.417+0800 I  ELECTION [conn11] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-09-22T12:10:50.419+0800 I  REPL     [conn11] stepping down from primary, because a new term has begun: 6
2020-09-22T12:10:50.419+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:50.419+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:50.419+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:10:50.419+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:10:50.420+0800 I  ELECTION [conn11] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:50.420+0800 I  ELECTION [conn11] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-09-22T12:10:50.420+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:10:50.421+0800 I  NETWORK  [conn11] end connection 120.55.192.104:34634 (33 connections now open)
2020-09-22T12:10:50.422+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34716 #87 (34 connections now open)
2020-09-22T12:10:50.422+0800 I  NETWORK  [conn87] received client metadata from 120.55.192.104:34716 conn87: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:50.568+0800 I  NETWORK  [conn58] end connection 120.55.192.104:34702 (33 connections now open)
2020-09-22T12:10:50.616+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59090 #88 (34 connections now open)
2020-09-22T12:10:50.616+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59094 #89 (35 connections now open)
2020-09-22T12:10:50.617+0800 I  NETWORK  [conn88] received client metadata from 114.212.84.175:59090 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:50.617+0800 I  NETWORK  [conn89] received client metadata from 114.212.84.175:59094 conn89: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:50.757+0800 I  NETWORK  [conn89] end connection 114.212.84.175:59094 (34 connections now open)
2020-09-22T12:10:50.757+0800 I  NETWORK  [conn88] end connection 114.212.84.175:59090 (33 connections now open)
2020-09-22T12:10:51.535+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:10:51.535+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 6
2020-09-22T12:10:51.535+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 586 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.535+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 587 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.535+0800 I  ELECTION [replexec-0] VoteRequester(term 6 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp(1600747850, 8), t: 6 }"; response message: { term: 6, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000006') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747851, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 8) }
2020-09-22T12:10:51.536+0800 I  ELECTION [replexec-4] VoteRequester(term 6 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000004') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747851, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 1) }
2020-09-22T12:10:51.537+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 7
2020-09-22T12:10:51.538+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 588 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.538+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 589 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747850, 1), t: 5 } }
2020-09-22T12:10:51.539+0800 I  ELECTION [replexec-6] VoteRequester(term 7) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp(1600747850, 8), t: 6 }"; response message: { term: 7, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747850, 1), t: 5 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000006') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747851, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 8) }
2020-09-22T12:10:51.542+0800 I  ELECTION [replexec-5] VoteRequester(term 7) received a yes vote from 120.55.194.98:27019; response message: { term: 7, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000004') }, lastCommittedOpTime: Timestamp(1600747850, 1), $clusterTime: { clusterTime: Timestamp(1600747851, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747850, 1) }
2020-09-22T12:10:51.542+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 7
2020-09-22T12:10:51.542+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:10:51.542+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-09-22T12:10:51.542+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:10:51.543+0800 I  REPL     [replexec-1] Heartbeats updated catchup target optime to { ts: Timestamp(1600747850, 8), t: 6 }
2020-09-22T12:10:51.543+0800 I  REPL     [replexec-1] Latest known optime per replica set member:
2020-09-22T12:10:51.543+0800 I  REPL     [replexec-1] Member ID: MemberId(0), latest known optime: { ts: Timestamp(1600747850, 1), t: 5 }
2020-09-22T12:10:51.543+0800 I  REPL     [replexec-1] Member ID: MemberId(1), latest known optime: { ts: Timestamp(1600747850, 8), t: 6 }
2020-09-22T12:10:51.543+0800 I  REPL     [replexec-1] Member ID: MemberId(2), latest known optime: unknown
2020-09-22T12:10:51.750+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59116 #90 (34 connections now open)
2020-09-22T12:10:51.750+0800 I  NETWORK  [conn90] received client metadata from 114.212.84.175:59116 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:51.754+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59118 #91 (35 connections now open)
2020-09-22T12:10:51.754+0800 I  NETWORK  [conn91] received client metadata from 114.212.84.175:59118 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:51.909+0800 I  NETWORK  [conn90] end connection 114.212.84.175:59116 (34 connections now open)
2020-09-22T12:10:51.910+0800 I  NETWORK  [conn91] end connection 114.212.84.175:59118 (33 connections now open)
2020-09-22T12:10:52.421+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:10:52.421+0800 I  CONNPOOL [RS] Connecting to 120.55.192.104:27019
2020-09-22T12:10:52.542+0800 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-09-22T12:10:52.542+0800 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-09-22T12:10:52.542+0800 I  REPL     [replexec-3] Stopping replication producer
2020-09-22T12:10:52.542+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 7
2020-09-22T12:10:52.542+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 7
2020-09-22T12:10:52.542+0800 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: 120.55.192.104:27019
2020-09-22T12:10:52.542+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:52.542+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:52.542+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:52.543+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:10:52.543+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:10:52.543+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:10:52.544+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:10:52.544+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:10:52.544+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:10:52.575+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:10:52.575+0800 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-09-22T12:10:52.575+0800 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-09-22T12:10:52.575+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:10:52.575+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:10:52.575+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:10:52.575+0800 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-09-22T12:10:52.575+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:10:52.575+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:10:53.542+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:10:53.543+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:10:53.618+0800 I  ELECTION [replexec-4] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-09-22T12:10:53.948+0800 I  REPL     [replexec-2] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:10:53.948+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:10:54.052+0800 I  NETWORK  [conn87] end connection 120.55.192.104:34716 (32 connections now open)
2020-09-22T12:10:54.139+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59160 #92 (33 connections now open)
2020-09-22T12:10:54.140+0800 I  NETWORK  [conn92] received client metadata from 114.212.84.175:59160 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:54.145+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59156 #93 (34 connections now open)
2020-09-22T12:10:54.146+0800 I  NETWORK  [conn93] received client metadata from 114.212.84.175:59156 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:54.289+0800 I  NETWORK  [conn92] end connection 114.212.84.175:59160 (33 connections now open)
2020-09-22T12:10:54.292+0800 I  NETWORK  [conn93] end connection 114.212.84.175:59156 (32 connections now open)
2020-09-22T12:10:54.420+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34726 #94 (33 connections now open)
2020-09-22T12:10:54.420+0800 I  NETWORK  [conn94] received client metadata from 120.55.192.104:34726 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:54.543+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:10:54.543+0800 I  CONNPOOL [RS] Connecting to 120.55.192.104:27019
2020-09-22T12:10:54.545+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1600747852, 14), t: 7 }. source's GTE: { ts: Timestamp(1600747853, 2), t: 8 }
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1600747850, 1), t: 5 }
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: 120.55.192.104:27019)
2020-09-22T12:10:54.546+0800 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 2, userOpsRunning: 32 }
2020-09-22T12:10:54.546+0800 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 94
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 71
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-09-22T12:10:54.546+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-09-22T12:10:54.546+0800 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-09-22T12:10:54.546+0800 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-09-22T12:10:54.546+0800 I  ROLLBACK [rsBackgroundSync] finding common point
2020-09-22T12:10:54.547+0800 I  COMMAND  [conn31] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747853, 9), t: 8 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747853, 9), signature: { hash: BinData(0, 771597ACB8ED1BEC1583BFA9E51968455D8740A5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747853, 9), t: 8 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1600747853, 9), t: 8 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:755 locks:{} protocol:op_msg 578ms
2020-09-22T12:10:54.547+0800 I  COMMAND  [conn20] command config.$cmd command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747853, 7), t: 8 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747853, 8), signature: { hash: BinData(0, 771597ACB8ED1BEC1583BFA9E51968455D8740A5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747853, 7), t: 8 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1600747853, 7), t: 8 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:755 locks:{} protocol:op_msg 993ms
2020-09-22T12:10:54.550+0800 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1600747850, 1), t: 5 }
2020-09-22T12:10:54.551+0800 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-09-22T12:10:54.551+0800 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-09-22T12:10:54.551+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-09-22T12:10:54.551+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-09-22T12:10:54.551+0800 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-09-22T12:10:54.551+0800 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-09-22T12:10:54.594+0800 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1600747850, 1) Initial Data Timestamp: Timestamp(1600747816, 1)
2020-09-22T12:10:54.594+0800 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-09-22T12:10:54.599+0800 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-09-22T12:10:54.599+0800 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 151 records totaling to 34559 bytes
2020-09-22T12:10:54.599+0800 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:10:54.599+0800 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-09-22T12:10:54.601+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-09-22T12:10:54.602+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-09-22T12:10:54.610+0800 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-09-22T12:10:54.610+0800 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-09-22T12:10:54.610+0800 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1600747850, 1)
2020-09-22T12:10:54.610+0800 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 0 update operations and 0 delete operations.
2020-09-22T12:10:54.610+0800 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1600747852, 14), t: 7 }
2020-09-22T12:10:54.611+0800 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1600747852, 14) }
2020-09-22T12:10:54.611+0800 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1600747850, 1) (top of oplog: { ts: Timestamp(1600747850, 1), t: 5 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1600747850, 1)
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-09-22T12:10:54.546+0800
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-09-22T12:10:54.612+0800
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	sync source: 120.55.192.104:27019
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: none; no files written
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1600747852, 14), t: 7 }
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1600747850, 1), t: 5 }
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-09-22T12:10:52.543+0800
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-09-22T12:10:50.064+0800
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 2 second(s)
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1600747852, 14)
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1600747850, 1)
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: none
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 		update: 0
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 1
2020-09-22T12:10:54.612+0800 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was 120.55.192.104:27019
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Rollback successful.
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-09-22T12:10:54.612+0800 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-09-22T12:10:54.613+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:10:54.614+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:10:54.975+0800 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.975+0800 I  ELECTION [conn94] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-09-22T12:10:54.977+0800 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747853, 9), t: 8 } }
2020-09-22T12:10:54.977+0800 I  ELECTION [conn94] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-09-22T12:10:55.448+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:10:55.448+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:10:55.448+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 600 timed out, deadline was 2020-09-22T12:10:55.448+0800, op was RemoteCommand 600 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:10:55.448+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 8 }
2020-09-22T12:10:56.948+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:10:58.522+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59250 #99 (34 connections now open)
2020-09-22T12:10:58.523+0800 I  NETWORK  [conn99] received client metadata from 114.212.84.175:59250 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:58.527+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59258 #100 (35 connections now open)
2020-09-22T12:10:58.528+0800 I  NETWORK  [conn100] received client metadata from 114.212.84.175:59258 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:10:58.617+0800 I  NETWORK  [conn71] end connection 120.55.194.98:32808 (34 connections now open)
2020-09-22T12:10:58.675+0800 I  NETWORK  [conn99] end connection 114.212.84.175:59250 (33 connections now open)
2020-09-22T12:10:58.675+0800 I  NETWORK  [conn100] end connection 114.212.84.175:59258 (32 connections now open)
2020-09-22T12:10:58.973+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32830 #101 (33 connections now open)
2020-09-22T12:10:58.974+0800 I  NETWORK  [conn101] received client metadata from 120.55.194.98:32830 conn101: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:59.626+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32826 #102 (34 connections now open)
2020-09-22T12:10:59.626+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32824 #103 (35 connections now open)
2020-09-22T12:10:59.626+0800 I  NETWORK  [conn103] received client metadata from 120.55.194.98:32824 conn103: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:10:59.626+0800 I  NETWORK  [conn102] received client metadata from 120.55.194.98:32826 conn102: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:00.244+0800 I  ELECTION [conn103] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:00.244+0800 I  ELECTION [conn103] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-09-22T12:11:00.246+0800 I  ELECTION [conn103] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:00.246+0800 I  ELECTION [conn103] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-09-22T12:11:00.247+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.192.104:27019, my last fetched oplog optime: { ts: Timestamp(1600747859, 5), t: 9 }, latest oplog optime of sync source: { ts: Timestamp(1600747859, 5), t: 9 } (sync source does not know the primary)
2020-09-22T12:11:00.247+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.192.104:27019, OpTime { ts: Timestamp(1600747859, 5), t: 9 }, its sync source index:-1
2020-09-22T12:11:00.247+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.192.104:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747859, 5), t: 9 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:00.247+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.192.104:27019 to choose a new one.
2020-09-22T12:11:00.247+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:00.248+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:00.248+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:00.356+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59300 #104 (36 connections now open)
2020-09-22T12:11:00.357+0800 I  NETWORK  [conn104] received client metadata from 114.212.84.175:59300 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:00.362+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59306 #105 (37 connections now open)
2020-09-22T12:11:00.363+0800 I  NETWORK  [conn105] received client metadata from 114.212.84.175:59306 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:00.522+0800 I  NETWORK  [conn104] end connection 114.212.84.175:59300 (36 connections now open)
2020-09-22T12:11:00.523+0800 I  NETWORK  [conn105] end connection 114.212.84.175:59306 (35 connections now open)
2020-09-22T12:11:00.746+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.192.104:27019
2020-09-22T12:11:00.952+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:01.172+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59328 #106 (36 connections now open)
2020-09-22T12:11:01.173+0800 I  NETWORK  [conn106] received client metadata from 114.212.84.175:59328 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:01.177+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59322 #107 (37 connections now open)
2020-09-22T12:11:01.178+0800 I  NETWORK  [conn107] received client metadata from 114.212.84.175:59322 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:01.248+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:01.249+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:01.321+0800 I  NETWORK  [conn106] end connection 114.212.84.175:59328 (36 connections now open)
2020-09-22T12:11:01.326+0800 I  NETWORK  [conn107] end connection 114.212.84.175:59322 (35 connections now open)
2020-09-22T12:11:01.335+0800 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747859, 5), t: 9 } }
2020-09-22T12:11:01.335+0800 I  ELECTION [conn94] Sending vote response: { term: 10, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747859, 5), t: 9 }, my last applied OpTime: { ts: Timestamp..." }
2020-09-22T12:11:02.028+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59334 #108 (36 connections now open)
2020-09-22T12:11:02.028+0800 I  NETWORK  [conn108] received client metadata from 114.212.84.175:59334 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.028+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59338 #109 (37 connections now open)
2020-09-22T12:11:02.029+0800 I  NETWORK  [conn109] received client metadata from 114.212.84.175:59338 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.169+0800 I  NETWORK  [conn108] end connection 114.212.84.175:59334 (36 connections now open)
2020-09-22T12:11:02.169+0800 I  NETWORK  [conn109] end connection 114.212.84.175:59338 (35 connections now open)
2020-09-22T12:11:02.250+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34736 #110 (36 connections now open)
2020-09-22T12:11:02.251+0800 I  NETWORK  [conn110] received client metadata from 120.55.192.104:34736 conn110: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:02.606+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59358 #111 (37 connections now open)
2020-09-22T12:11:02.607+0800 I  NETWORK  [conn111] received client metadata from 114.212.84.175:59358 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.617+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59364 #112 (38 connections now open)
2020-09-22T12:11:02.617+0800 I  NETWORK  [conn112] received client metadata from 114.212.84.175:59364 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:02.759+0800 I  NETWORK  [conn111] end connection 114.212.84.175:59358 (37 connections now open)
2020-09-22T12:11:02.764+0800 I  NETWORK  [conn112] end connection 114.212.84.175:59364 (36 connections now open)
2020-09-22T12:11:03.555+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:03.555+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 10
2020-09-22T12:11:03.555+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 672 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.555+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 673 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.555+0800 I  ELECTION [replexec-1] VoteRequester(term 10 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 10, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1600747860, 2), $clusterTime: { clusterTime: Timestamp(1600747860, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747860, 2) }
2020-09-22T12:11:03.556+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 11
2020-09-22T12:11:03.556+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:03.556+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:03.557+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 674 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.557+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 675 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747860, 2), t: 10 } }
2020-09-22T12:11:03.559+0800 I  ELECTION [replexec-2] VoteRequester(term 11) received a yes vote from 120.55.192.104:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1600747860, 2), $clusterTime: { clusterTime: Timestamp(1600747860, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747860, 2) }
2020-09-22T12:11:03.559+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 11
2020-09-22T12:11:03.559+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:11:03.559+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:11:03.559+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:11:04.559+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:04.559+0800 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-09-22T12:11:04.559+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:11:04.559+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:11:04.559+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:04.559+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:04.559+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 11
2020-09-22T12:11:04.559+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 11
2020-09-22T12:11:04.559+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:04.559+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:04.559+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:11:04.560+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:04.560+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:04.562+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:04.562+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:04.562+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:04.562+0800 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:04.563+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:04.563+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:04.564+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:04.564+0800 I  CONNPOOL [ShardRegistry] Connecting to 47.96.16.32:27018
2020-09-22T12:11:05.384+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:06.119+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59452 #114 (37 connections now open)
2020-09-22T12:11:06.120+0800 I  NETWORK  [conn114] received client metadata from 114.212.84.175:59452 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:06.125+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59448 #115 (38 connections now open)
2020-09-22T12:11:06.125+0800 I  NETWORK  [conn115] received client metadata from 114.212.84.175:59448 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:06.265+0800 I  NETWORK  [conn114] end connection 114.212.84.175:59452 (37 connections now open)
2020-09-22T12:11:06.268+0800 I  NETWORK  [conn115] end connection 114.212.84.175:59448 (36 connections now open)
2020-09-22T12:11:06.498+0800 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.498+0800 I  ELECTION [conn94] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-09-22T12:11:06.500+0800 I  REPL     [conn94] stepping down from primary, because a new term has begun: 12
2020-09-22T12:11:06.500+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:06.500+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:06.500+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:11:06.500+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:11:06.501+0800 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747865, 1), t: 11 } }
2020-09-22T12:11:06.501+0800 I  ELECTION [conn94] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-09-22T12:11:06.501+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:06.502+0800 I  NETWORK  [conn94] end connection 120.55.192.104:34726 (35 connections now open)
2020-09-22T12:11:06.502+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34738 #116 (36 connections now open)
2020-09-22T12:11:06.503+0800 I  NETWORK  [conn116] received client metadata from 120.55.192.104:34738 conn116: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:06.561+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:06.563+0800 I  NETWORK  [conn59] end connection 120.55.192.104:34704 (35 connections now open)
2020-09-22T12:11:07.501+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:07.503+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:07.503+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:11:07.560+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:11:08.953+0800 I  ELECTION [conn103] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:08.953+0800 I  ELECTION [conn103] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-09-22T12:11:08.955+0800 I  ELECTION [conn103] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:08.955+0800 I  ELECTION [conn103] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-09-22T12:11:09.560+0800 I  REPL     [replexec-3] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:09.561+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:09.968+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59520 #120 (36 connections now open)
2020-09-22T12:11:09.968+0800 I  NETWORK  [conn120] received client metadata from 114.212.84.175:59520 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:09.969+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59524 #121 (37 connections now open)
2020-09-22T12:11:09.970+0800 I  NETWORK  [conn121] received client metadata from 114.212.84.175:59524 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:10.087+0800 I  ELECTION [conn116] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747866, 7), t: 12 } }
2020-09-22T12:11:10.087+0800 I  ELECTION [conn116] Sending vote response: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747866, 7), t: 12 }, my last applied OpTime: { ts: Timestam..." }
2020-09-22T12:11:10.110+0800 I  NETWORK  [conn120] end connection 114.212.84.175:59520 (36 connections now open)
2020-09-22T12:11:10.110+0800 I  NETWORK  [conn121] end connection 114.212.84.175:59524 (35 connections now open)
2020-09-22T12:11:10.959+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34742 #122 (36 connections now open)
2020-09-22T12:11:10.960+0800 I  NETWORK  [conn122] received client metadata from 120.55.192.104:34742 conn122: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:11.746+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59560 #123 (37 connections now open)
2020-09-22T12:11:11.747+0800 I  NETWORK  [conn123] received client metadata from 114.212.84.175:59560 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:11.747+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59564 #124 (38 connections now open)
2020-09-22T12:11:11.748+0800 I  NETWORK  [conn124] received client metadata from 114.212.84.175:59564 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:11.885+0800 I  NETWORK  [conn123] end connection 114.212.84.175:59560 (37 connections now open)
2020-09-22T12:11:11.885+0800 I  NETWORK  [conn124] end connection 114.212.84.175:59564 (36 connections now open)
2020-09-22T12:11:13.672+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59600 #125 (37 connections now open)
2020-09-22T12:11:13.673+0800 I  NETWORK  [conn125] received client metadata from 114.212.84.175:59600 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:13.676+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59604 #126 (38 connections now open)
2020-09-22T12:11:13.677+0800 I  NETWORK  [conn126] received client metadata from 114.212.84.175:59604 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:13.830+0800 I  NETWORK  [conn125] end connection 114.212.84.175:59600 (37 connections now open)
2020-09-22T12:11:13.831+0800 I  NETWORK  [conn126] end connection 114.212.84.175:59604 (36 connections now open)
2020-09-22T12:11:14.267+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59626 #127 (37 connections now open)
2020-09-22T12:11:14.268+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59636 #128 (38 connections now open)
2020-09-22T12:11:14.268+0800 I  NETWORK  [conn127] received client metadata from 114.212.84.175:59626 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.268+0800 I  NETWORK  [conn128] received client metadata from 114.212.84.175:59636 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.407+0800 I  NETWORK  [conn127] end connection 114.212.84.175:59626 (37 connections now open)
2020-09-22T12:11:14.408+0800 I  NETWORK  [conn128] end connection 114.212.84.175:59636 (36 connections now open)
2020-09-22T12:11:14.849+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59654 #129 (37 connections now open)
2020-09-22T12:11:14.850+0800 I  NETWORK  [conn129] received client metadata from 114.212.84.175:59654 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:14.859+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59650 #130 (38 connections now open)
2020-09-22T12:11:14.861+0800 I  NETWORK  [conn130] received client metadata from 114.212.84.175:59650 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:15.003+0800 I  NETWORK  [conn129] end connection 114.212.84.175:59654 (37 connections now open)
2020-09-22T12:11:15.008+0800 I  NETWORK  [conn130] end connection 114.212.84.175:59650 (36 connections now open)
2020-09-22T12:11:16.728+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59692 #131 (37 connections now open)
2020-09-22T12:11:16.728+0800 I  NETWORK  [conn131] received client metadata from 114.212.84.175:59692 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:16.732+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59696 #132 (38 connections now open)
2020-09-22T12:11:16.733+0800 I  NETWORK  [conn132] received client metadata from 114.212.84.175:59696 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:16.875+0800 I  NETWORK  [conn131] end connection 114.212.84.175:59692 (37 connections now open)
2020-09-22T12:11:16.878+0800 I  NETWORK  [conn132] end connection 114.212.84.175:59696 (36 connections now open)
2020-09-22T12:11:17.779+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:17.779+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 13
2020-09-22T12:11:17.779+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 776 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.779+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 777 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.779+0800 I  ELECTION [replexec-1] VoteRequester(term 13 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1600747875, 27), $clusterTime: { clusterTime: Timestamp(1600747875, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747875, 27) }
2020-09-22T12:11:17.779+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 14
2020-09-22T12:11:17.780+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:17.780+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 778 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.780+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 779 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747875, 27), t: 13 } }
2020-09-22T12:11:17.781+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:17.782+0800 I  ELECTION [replexec-4] VoteRequester(term 14) received a yes vote from 120.55.192.104:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1600747875, 27), $clusterTime: { clusterTime: Timestamp(1600747875, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747875, 27) }
2020-09-22T12:11:17.782+0800 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 14
2020-09-22T12:11:17.782+0800 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-09-22T12:11:17.782+0800 I  REPL     [replexec-4] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:11:17.782+0800 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-09-22T12:11:17.782+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:11:18.585+0800 I  NETWORK  [conn103] end connection 120.55.194.98:32824 (35 connections now open)
2020-09-22T12:11:18.764+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:11:18.764+0800 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747875, 27), t: 13 }. My Last Applied: { ts: Timestamp(1600747875, 27), t: 13 }
2020-09-22T12:11:18.764+0800 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-09-22T12:11:18.764+0800 I  REPL     [replexec-5] Stopping replication producer
2020-09-22T12:11:18.764+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-09-22T12:11:18.764+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-09-22T12:11:18.764+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:18.764+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:18.764+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:18.764+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:18.764+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:11:18.765+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:18.765+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:18.766+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:18.766+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:18.766+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:18.771+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:18.771+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:18.904+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:11:19.049+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59738 #135 (36 connections now open)
2020-09-22T12:11:19.050+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59740 #136 (37 connections now open)
2020-09-22T12:11:19.050+0800 I  NETWORK  [conn136] received client metadata from 114.212.84.175:59740 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.050+0800 I  NETWORK  [conn135] received client metadata from 114.212.84.175:59738 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.187+0800 I  NETWORK  [conn135] end connection 114.212.84.175:59738 (36 connections now open)
2020-09-22T12:11:19.187+0800 I  NETWORK  [conn136] end connection 114.212.84.175:59740 (35 connections now open)
2020-09-22T12:11:19.630+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59754 #137 (36 connections now open)
2020-09-22T12:11:19.630+0800 I  NETWORK  [conn137] received client metadata from 114.212.84.175:59754 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.632+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59758 #138 (37 connections now open)
2020-09-22T12:11:19.632+0800 I  NETWORK  [conn138] received client metadata from 114.212.84.175:59758 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:19.786+0800 I  NETWORK  [conn137] end connection 114.212.84.175:59754 (36 connections now open)
2020-09-22T12:11:19.787+0800 I  NETWORK  [conn138] end connection 114.212.84.175:59758 (35 connections now open)
2020-09-22T12:11:20.391+0800 I  COMMAND  [conn66] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747880, 26), signature: { hash: BinData(0, 8175931DBD180922885E720A03098F2F3F275DE4), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747879, 5), t: 14 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 118ms
2020-09-22T12:11:20.392+0800 I  COMMAND  [conn28] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Jepsen-Node-02:27017:1600747819:-4663412768929081412" }, update: { $set: { ping: new Date(1600747880067) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747880, 26), signature: { hash: BinData(0, 8175931DBD180922885E720A03098F2F3F275DE4), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747879, 5), t: 14 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:640 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 119ms
2020-09-22T12:11:20.764+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:20.968+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59790 #139 (36 connections now open)
2020-09-22T12:11:20.969+0800 I  NETWORK  [conn139] received client metadata from 114.212.84.175:59790 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:20.981+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59794 #140 (37 connections now open)
2020-09-22T12:11:20.981+0800 I  NETWORK  [conn140] received client metadata from 114.212.84.175:59794 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:21.074+0800 I  ELECTION [conn116] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.074+0800 I  ELECTION [conn116] Sending vote response: { term: 14, voteGranted: true, reason: "" }
2020-09-22T12:11:21.076+0800 I  REPL     [conn116] stepping down from primary, because a new term has begun: 15
2020-09-22T12:11:21.076+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:21.076+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:21.076+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-09-22T12:11:21.076+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:11:21.077+0800 I  ELECTION [conn116] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747880, 82), t: 14 } }
2020-09-22T12:11:21.077+0800 I  ELECTION [conn116] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-09-22T12:11:21.077+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:21.079+0800 I  NETWORK  [conn116] end connection 120.55.192.104:34738 (36 connections now open)
2020-09-22T12:11:21.079+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34750 #141 (37 connections now open)
2020-09-22T12:11:21.079+0800 I  NETWORK  [conn141] received client metadata from 120.55.192.104:34750 conn141: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:21.136+0800 I  NETWORK  [conn139] end connection 114.212.84.175:59790 (36 connections now open)
2020-09-22T12:11:21.142+0800 I  NETWORK  [conn140] end connection 114.212.84.175:59794 (35 connections now open)
2020-09-22T12:11:21.471+0800 I  NETWORK  [conn110] end connection 120.55.192.104:34736 (34 connections now open)
2020-09-22T12:11:21.788+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:11:22.078+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:11:22.079+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:11:22.083+0800 I  COMMAND  [conn31] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747881, 3), t: 15 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747881, 3), signature: { hash: BinData(0, D133F6AD683563A8859E16759CF220FD59E61A3B), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 980ms
2020-09-22T12:11:22.984+0800 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:22.984+0800 I  ELECTION [conn102] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-09-22T12:11:22.986+0800 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:22.986+0800 I  ELECTION [conn102] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-09-22T12:11:23.038+0800 I  NETWORK  [conn35] end connection 47.96.5.198:36128 (33 connections now open)
2020-09-22T12:11:23.083+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.192.104:27019, my last fetched oplog optime: { ts: Timestamp(1600747881, 3), t: 15 }, latest oplog optime of sync source: { ts: Timestamp(1600747881, 3), t: 15 } (120.55.194.98:27019 is)
2020-09-22T12:11:23.083+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.192.104:27019, OpTime { ts: Timestamp(1600747881, 3), t: 15 }, its sync source index:-1
2020-09-22T12:11:23.083+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.192.104:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747881, 3), t: 15 }; sync source index: -1; primary index: 0) is no longer valid
2020-09-22T12:11:23.083+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.192.104:27019 to choose a new one.
2020-09-22T12:11:23.083+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:23.084+0800 I  REPL     [replexec-0] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:23.084+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:23.195+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59840 #142 (34 connections now open)
2020-09-22T12:11:23.196+0800 I  NETWORK  [conn142] received client metadata from 114.212.84.175:59840 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:23.207+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59844 #143 (35 connections now open)
2020-09-22T12:11:23.207+0800 I  NETWORK  [conn143] received client metadata from 114.212.84.175:59844 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:23.350+0800 I  NETWORK  [conn142] end connection 114.212.84.175:59840 (34 connections now open)
2020-09-22T12:11:23.355+0800 I  NETWORK  [conn143] end connection 114.212.84.175:59844 (33 connections now open)
2020-09-22T12:11:23.582+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.192.104:27019
2020-09-22T12:11:24.083+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:24.205+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:24.205+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 16
2020-09-22T12:11:24.205+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 808 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.205+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 809 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.206+0800 I  ELECTION [replexec-1] VoteRequester(term 16 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 16, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000f') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747883, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747881, 3) }
2020-09-22T12:11:24.206+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 17
2020-09-22T12:11:24.206+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:24.207+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 810 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.207+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 811 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:24.207+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:24.208+0800 I  ELECTION [replexec-6] VoteRequester(term 17) received a yes vote from 120.55.192.104:27019; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000f') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747883, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747881, 3) }
2020-09-22T12:11:24.208+0800 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 17
2020-09-22T12:11:24.208+0800 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-09-22T12:11:24.208+0800 I  REPL     [replexec-6] Resetting sync source to empty, which was :27017
2020-09-22T12:11:24.208+0800 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-09-22T12:11:24.209+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:11:24.584+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-09-22T12:11:24.584+0800 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747881, 3), t: 15 }. My Last Applied: { ts: Timestamp(1600747881, 3), t: 15 }
2020-09-22T12:11:24.584+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:11:24.584+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:11:24.584+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:11:24.584+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 17
2020-09-22T12:11:24.584+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 17
2020-09-22T12:11:24.584+0800 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: 120.55.194.98:27019
2020-09-22T12:11:24.584+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:24.584+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:24.584+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:24.585+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:24.585+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:24.586+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:24.586+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:24.586+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:25.209+0800 I  REPL     [replexec-0] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:25.209+0800 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:25.209+0800 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-09-22T12:11:25.209+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:25.209+0800 W  COMMAND  [conn39] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.209+0800 I  COMMAND  [conn39] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.00:27018:1600747823:-5900587996018832451" }, update: { $set: { ping: new Date(1600747883548) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 3), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 615ms
2020-09-22T12:11:25.210+0800 W  COMMAND  [conn36] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.210+0800 I  COMMAND  [conn36] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.02:27018:1600747823:-4430192164990820571" }, update: { $set: { ping: new Date(1600747883554) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 9), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 614ms
2020-09-22T12:11:25.210+0800 W  COMMAND  [conn23] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.210+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 3), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 161ms
2020-09-22T12:11:25.211+0800 W  COMMAND  [conn29] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.211+0800 I  COMMAND  [conn29] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 11), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 162ms
2020-09-22T12:11:25.212+0800 W  COMMAND  [conn28] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.212+0800 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 3), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 165ms
2020-09-22T12:11:25.212+0800 W  COMMAND  [conn31] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.212+0800 I  COMMAND  [conn31] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 3), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 166ms
2020-09-22T12:11:25.213+0800 W  COMMAND  [conn20] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.213+0800 I  COMMAND  [conn20] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 3), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 160ms
2020-09-22T12:11:25.214+0800 W  COMMAND  [conn40] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:25.214+0800 I  COMMAND  [conn40] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.01:27018:1600747823:-5358775017967458485" }, update: { $set: { ping: new Date(1600747883548) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747884, 1), signature: { hash: BinData(0, F390B2A5B15D90A1510A5A26D385FE8497BCE7B5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747881, 3), t: 15 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:764 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 619ms
2020-09-22T12:11:25.215+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:25.215+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 8, userOpsRunning: 0 }
2020-09-22T12:11:25.215+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:11:25.215+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:11:25.216+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:25.336+0800 I  ELECTION [conn141] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747881, 3), t: 15 } }
2020-09-22T12:11:25.336+0800 I  ELECTION [conn141] Sending vote response: { term: 17, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747881, 3), t: 15 }, my last applied OpTime: { ts: Timestam..." }
2020-09-22T12:11:25.693+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59890 #145 (34 connections now open)
2020-09-22T12:11:25.694+0800 I  NETWORK  [conn145] received client metadata from 114.212.84.175:59890 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:25.695+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59892 #146 (35 connections now open)
2020-09-22T12:11:25.696+0800 I  NETWORK  [conn146] received client metadata from 114.212.84.175:59892 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:25.833+0800 I  NETWORK  [conn145] end connection 114.212.84.175:59890 (34 connections now open)
2020-09-22T12:11:25.835+0800 I  NETWORK  [conn146] end connection 114.212.84.175:59892 (33 connections now open)
2020-09-22T12:11:26.091+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32854 #147 (34 connections now open)
2020-09-22T12:11:26.091+0800 I  NETWORK  [conn147] received client metadata from 120.55.194.98:32854 conn147: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.123+0800 I  NETWORK  [conn147] end connection 120.55.194.98:32854 (33 connections now open)
2020-09-22T12:11:26.131+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32858 #148 (34 connections now open)
2020-09-22T12:11:26.131+0800 I  NETWORK  [conn148] received client metadata from 120.55.194.98:32858 conn148: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.140+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59904 #149 (35 connections now open)
2020-09-22T12:11:26.141+0800 I  NETWORK  [conn149] received client metadata from 114.212.84.175:59904 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.148+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59900 #150 (36 connections now open)
2020-09-22T12:11:26.149+0800 I  NETWORK  [conn150] received client metadata from 114.212.84.175:59900 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.175+0800 I  NETWORK  [conn149] end connection 114.212.84.175:59904 (35 connections now open)
2020-09-22T12:11:26.187+0800 I  NETWORK  [conn150] end connection 114.212.84.175:59900 (34 connections now open)
2020-09-22T12:11:26.209+0800 I  REPL     [replexec-0] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:26.225+0800 I  NETWORK  [conn148] end connection 120.55.194.98:32858 (33 connections now open)
2020-09-22T12:11:26.232+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32860 #151 (34 connections now open)
2020-09-22T12:11:26.232+0800 I  NETWORK  [conn151] received client metadata from 120.55.194.98:32860 conn151: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.334+0800 I  NETWORK  [conn151] end connection 120.55.194.98:32860 (33 connections now open)
2020-09-22T12:11:26.341+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32862 #152 (34 connections now open)
2020-09-22T12:11:26.342+0800 I  NETWORK  [conn152] received client metadata from 120.55.194.98:32862 conn152: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.351+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:26.351+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 17
2020-09-22T12:11:26.351+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 818 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.351+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 819 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.354+0800 I  ELECTION [replexec-4] VoteRequester(term 17 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000f') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747885, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747883, 3) }
2020-09-22T12:11:26.354+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 18
2020-09-22T12:11:26.355+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 820 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.355+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 821 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747884, 10), t: 17 } }
2020-09-22T12:11:26.356+0800 I  ELECTION [replexec-1] VoteRequester(term 18) received a yes vote from 120.55.192.104:27019; response message: { term: 18, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000f') }, lastCommittedOpTime: Timestamp(1600747881, 3), $clusterTime: { clusterTime: Timestamp(1600747885, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747883, 3) }
2020-09-22T12:11:26.356+0800 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 18
2020-09-22T12:11:26.356+0800 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-09-22T12:11:26.356+0800 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-09-22T12:11:26.356+0800 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-09-22T12:11:26.433+0800 I  NETWORK  [conn152] end connection 120.55.194.98:32862 (33 connections now open)
2020-09-22T12:11:26.441+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32864 #153 (34 connections now open)
2020-09-22T12:11:26.441+0800 I  NETWORK  [conn153] received client metadata from 120.55.194.98:32864 conn153: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.487+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59918 #154 (35 connections now open)
2020-09-22T12:11:26.487+0800 I  NETWORK  [conn154] received client metadata from 114.212.84.175:59918 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.495+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59914 #155 (36 connections now open)
2020-09-22T12:11:26.496+0800 I  NETWORK  [conn155] received client metadata from 114.212.84.175:59914 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:26.539+0800 I  NETWORK  [conn153] end connection 120.55.194.98:32864 (35 connections now open)
2020-09-22T12:11:26.547+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32866 #156 (36 connections now open)
2020-09-22T12:11:26.548+0800 I  NETWORK  [conn156] received client metadata from 120.55.194.98:32866 conn156: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.626+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34760 #157 (37 connections now open)
2020-09-22T12:11:26.626+0800 I  NETWORK  [conn157] received client metadata from 120.55.192.104:34760 conn157: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.627+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34762 #158 (38 connections now open)
2020-09-22T12:11:26.627+0800 I  NETWORK  [conn158] received client metadata from 120.55.192.104:34762 conn158: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:26.635+0800 I  NETWORK  [conn154] end connection 114.212.84.175:59918 (37 connections now open)
2020-09-22T12:11:26.639+0800 I  NETWORK  [conn155] end connection 114.212.84.175:59914 (36 connections now open)
2020-09-22T12:11:26.658+0800 I  NETWORK  [conn156] end connection 120.55.194.98:32866 (35 connections now open)
2020-09-22T12:11:27.356+0800 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-09-22T12:11:27.356+0800 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-09-22T12:11:27.356+0800 I  REPL     [replexec-4] Stopping replication producer
2020-09-22T12:11:27.356+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 18
2020-09-22T12:11:27.356+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:27.356+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:27.356+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:27.357+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:27.357+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:27.358+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:27.358+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:27.358+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:27.527+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:27.527+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:28.137+0800 I  NETWORK  [conn158] end connection 120.55.192.104:34762 (34 connections now open)
2020-09-22T12:11:29.399+0800 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 18, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:29.399+0800 I  ELECTION [conn102] Sending vote response: { term: 18, voteGranted: true, reason: "" }
2020-09-22T12:11:29.401+0800 I  REPL     [conn102] stepping down from primary, because a new term has begun: 19
2020-09-22T12:11:29.402+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:29.402+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:29.402+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:11:29.402+0800 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-09-22T12:11:29.402+0800 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 19, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:29.402+0800 I  ELECTION [conn102] Sending vote response: { term: 19, voteGranted: true, reason: "" }
2020-09-22T12:11:29.403+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:29.403+0800 I  NETWORK  [conn102] end connection 120.55.194.98:32826 (33 connections now open)
2020-09-22T12:11:29.404+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32868 #159 (34 connections now open)
2020-09-22T12:11:29.404+0800 I  NETWORK  [conn159] received client metadata from 120.55.194.98:32868 conn159: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:29.559+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59968 #160 (35 connections now open)
2020-09-22T12:11:29.559+0800 I  NETWORK  [conn160] received client metadata from 114.212.84.175:59968 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:29.561+0800 I  NETWORK  [conn60] end connection 120.55.194.98:32802 (34 connections now open)
2020-09-22T12:11:29.571+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:59972 #161 (35 connections now open)
2020-09-22T12:11:29.572+0800 I  NETWORK  [conn161] received client metadata from 114.212.84.175:59972 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:29.718+0800 I  NETWORK  [conn160] end connection 114.212.84.175:59968 (34 connections now open)
2020-09-22T12:11:29.721+0800 I  NETWORK  [conn161] end connection 114.212.84.175:59972 (33 connections now open)
2020-09-22T12:11:30.428+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:30.428+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 19
2020-09-22T12:11:30.428+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 830 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:30.428+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 831 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747887, 5), t: 18 } }
2020-09-22T12:11:30.428+0800 I  CONNPOOL [Replication] Connecting to 120.55.192.104:27019
2020-09-22T12:11:30.662+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34768 #162 (34 connections now open)
2020-09-22T12:11:30.662+0800 I  NETWORK  [conn162] received client metadata from 120.55.192.104:34768 conn162: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:30.664+0800 I  ELECTION [conn162] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747889, 2), t: 19 } }
2020-09-22T12:11:30.664+0800 I  ELECTION [conn162] Sending vote response: { term: 20, voteGranted: true, reason: "" }
2020-09-22T12:11:30.764+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:11:30.764+0800 I  ELECTION [replexec-4] VoteRequester(term 19 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's term (19) is lower than mine (20)"; response message: { term: 20, voteGranted: false, reason: "candidate's term (19) is lower than mine (20)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1600747887, 5), $clusterTime: { clusterTime: Timestamp(1600747890, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747890, 4) }
2020-09-22T12:11:30.764+0800 I  ELECTION [replexec-4] not running for primary, we have been superseded already during dry run. original term: 19, current term: 20
2020-09-22T12:11:30.764+0800 I  ELECTION [replexec-4] Lost dry run election due to internal error
2020-09-22T12:11:30.956+0800 I  NETWORK  [conn141] end connection 120.55.192.104:34750 (33 connections now open)
2020-09-22T12:11:31.217+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:31.403+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:11:31.404+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:11:31.648+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34766 #166 (34 connections now open)
2020-09-22T12:11:31.648+0800 I  NETWORK  [conn166] received client metadata from 120.55.192.104:34766 conn166: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:31.800+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60050 #167 (35 connections now open)
2020-09-22T12:11:31.801+0800 I  NETWORK  [conn167] received client metadata from 114.212.84.175:60050 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:31.801+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60058 #168 (36 connections now open)
2020-09-22T12:11:31.802+0800 I  NETWORK  [conn168] received client metadata from 114.212.84.175:60058 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:31.941+0800 I  NETWORK  [conn167] end connection 114.212.84.175:60050 (35 connections now open)
2020-09-22T12:11:31.941+0800 I  NETWORK  [conn168] end connection 114.212.84.175:60058 (34 connections now open)
2020-09-22T12:11:32.648+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32874 #169 (35 connections now open)
2020-09-22T12:11:32.649+0800 I  NETWORK  [conn169] received client metadata from 120.55.194.98:32874 conn169: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:33.709+0800 I  ELECTION [conn159] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 20, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747892, 1), t: 20 } }
2020-09-22T12:11:33.709+0800 I  ELECTION [conn159] Sending vote response: { term: 20, voteGranted: true, reason: "" }
2020-09-22T12:11:33.711+0800 I  ELECTION [conn159] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 21, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747892, 1), t: 20 } }
2020-09-22T12:11:33.711+0800 I  ELECTION [conn159] Sending vote response: { term: 21, voteGranted: true, reason: "" }
2020-09-22T12:11:33.764+0800 I  REPL     [replexec-4] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:33.920+0800 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.192.104:27019, my last fetched oplog optime: { ts: Timestamp(1600747892, 1), t: 20 }, latest oplog optime of sync source: { ts: Timestamp(1600747892, 1), t: 20 } (sync source does not know the primary)
2020-09-22T12:11:33.920+0800 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.192.104:27019, OpTime { ts: Timestamp(1600747892, 1), t: 20 }, its sync source index:-1
2020-09-22T12:11:33.920+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.192.104:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747892, 1), t: 20 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:11:33.920+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.192.104:27019 to choose a new one.
2020-09-22T12:11:33.920+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:11:33.921+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:33.922+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.192.104:27019
2020-09-22T12:11:33.922+0800 I  NETWORK  [conn169] end connection 120.55.194.98:32874 (34 connections now open)
2020-09-22T12:11:34.104+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60098 #170 (35 connections now open)
2020-09-22T12:11:34.105+0800 I  NETWORK  [conn170] received client metadata from 114.212.84.175:60098 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:34.114+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60094 #171 (36 connections now open)
2020-09-22T12:11:34.114+0800 I  NETWORK  [conn171] received client metadata from 114.212.84.175:60094 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:34.257+0800 I  NETWORK  [conn170] end connection 114.212.84.175:60098 (35 connections now open)
2020-09-22T12:11:34.262+0800 I  NETWORK  [conn171] end connection 114.212.84.175:60094 (34 connections now open)
2020-09-22T12:11:34.920+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:34.922+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:34.922+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:11:35.064+0800 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-09-22T12:11:35.947+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60126 #173 (35 connections now open)
2020-09-22T12:11:35.948+0800 I  NETWORK  [conn173] received client metadata from 114.212.84.175:60126 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:35.956+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60122 #174 (36 connections now open)
2020-09-22T12:11:35.956+0800 I  NETWORK  [conn174] received client metadata from 114.212.84.175:60122 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:36.095+0800 I  NETWORK  [conn173] end connection 114.212.84.175:60126 (35 connections now open)
2020-09-22T12:11:36.099+0800 I  NETWORK  [conn174] end connection 114.212.84.175:60122 (34 connections now open)
2020-09-22T12:11:39.875+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60206 #175 (35 connections now open)
2020-09-22T12:11:39.876+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60202 #176 (36 connections now open)
2020-09-22T12:11:39.876+0800 I  NETWORK  [conn176] received client metadata from 114.212.84.175:60202 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:39.877+0800 I  NETWORK  [conn175] received client metadata from 114.212.84.175:60206 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:40.032+0800 I  NETWORK  [conn175] end connection 114.212.84.175:60206 (35 connections now open)
2020-09-22T12:11:40.032+0800 I  NETWORK  [conn176] end connection 114.212.84.175:60202 (34 connections now open)
2020-09-22T12:11:40.612+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:40.612+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 21
2020-09-22T12:11:40.612+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 914 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.612+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 915 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.612+0800 I  ELECTION [replexec-1] VoteRequester(term 21 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 21, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747897, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747897, 14) }
2020-09-22T12:11:40.613+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 22
2020-09-22T12:11:40.613+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:40.614+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 916 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.614+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 917 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:40.615+0800 I  ELECTION [replexec-6] VoteRequester(term 22) received a yes vote from 120.55.192.104:27019; response message: { term: 22, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747897, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747897, 14) }
2020-09-22T12:11:40.615+0800 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 22
2020-09-22T12:11:40.615+0800 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-09-22T12:11:40.615+0800 I  REPL     [replexec-6] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:11:40.615+0800 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-09-22T12:11:40.616+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:40.616+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:41.615+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:41.615+0800 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-09-22T12:11:41.615+0800 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-09-22T12:11:41.615+0800 I  REPL     [replexec-2] Stopping replication producer
2020-09-22T12:11:41.615+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:41.615+0800 I  CONNPOOL [RS] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:41.615+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 22
2020-09-22T12:11:41.615+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 22
2020-09-22T12:11:41.615+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:41.615+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:41.615+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:41.616+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:41.616+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:41.617+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:41.617+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:41.617+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:41.620+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:11:42.165+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:42.165+0800 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:42.165+0800 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-09-22T12:11:42.165+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:42.165+0800 W  COMMAND  [conn67] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:42.165+0800 I  COMMAND  [conn67] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747901, 25), signature: { hash: BinData(0, E6426EC8817EFFA62F02F2DCE2C75721144F55F5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 309ms
2020-09-22T12:11:42.166+0800 W  COMMAND  [conn70] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:42.166+0800 I  COMMAND  [conn70] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747901, 31), signature: { hash: BinData(0, E6426EC8817EFFA62F02F2DCE2C75721144F55F5), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 313ms
2020-09-22T12:11:42.166+0800 W  COMMAND  [conn68] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:42.166+0800 I  COMMAND  [conn68] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747900, 2), signature: { hash: BinData(0, BB816515D3AC6C5DA061832FC329AA32C9109092), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747897, 14), t: 21 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 514ms
2020-09-22T12:11:42.167+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:42.167+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 3, userOpsRunning: 0 }
2020-09-22T12:11:42.167+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:11:42.167+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:11:42.168+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:42.284+0800 I  ELECTION [conn166] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:42.284+0800 I  ELECTION [conn166] Sending vote response: { term: 22, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:11:42.616+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:43.239+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:43.239+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 22
2020-09-22T12:11:43.239+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 931 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.239+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 932 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.239+0800 I  ELECTION [replexec-4] VoteRequester(term 22 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 22, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747901, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747897, 14) }
2020-09-22T12:11:43.239+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 23
2020-09-22T12:11:43.241+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 933 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.241+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 934 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747901, 1), t: 22 } }
2020-09-22T12:11:43.241+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:11:43.242+0800 I  ELECTION [replexec-0] VoteRequester(term 23) received a yes vote from 120.55.192.104:27019; response message: { term: 23, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747901, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747897, 14) }
2020-09-22T12:11:43.242+0800 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 23
2020-09-22T12:11:43.242+0800 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-09-22T12:11:43.242+0800 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-09-22T12:11:43.242+0800 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-09-22T12:11:44.242+0800 I  REPL     [replexec-6] Catchup timed out after becoming primary.
2020-09-22T12:11:44.242+0800 I  REPL     [replexec-6] Exited primary catch-up mode.
2020-09-22T12:11:44.242+0800 I  REPL     [replexec-6] Stopping replication producer
2020-09-22T12:11:44.242+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 23
2020-09-22T12:11:44.242+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 23
2020-09-22T12:11:44.242+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:44.242+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:44.242+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:44.243+0800 I  REPL     [replexec-2] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:44.243+0800 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:44.243+0800 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-09-22T12:11:44.243+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:44.243+0800 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-09-22T12:11:44.244+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:44.244+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:44.244+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:44.244+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:44.244+0800 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-09-22T12:11:44.245+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-09-22T12:11:44.245+0800 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: operation was interrupted
2020-09-22T12:11:44.245+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:44.245+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:44.245+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:44.361+0800 I  ELECTION [conn166] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747897, 14), t: 21 } }
2020-09-22T12:11:44.361+0800 I  ELECTION [conn166] Sending vote response: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747897, 14), t: 21 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:11:44.965+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60290 #177 (35 connections now open)
2020-09-22T12:11:44.965+0800 I  NETWORK  [conn177] received client metadata from 114.212.84.175:60290 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:44.976+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60286 #178 (36 connections now open)
2020-09-22T12:11:44.976+0800 I  NETWORK  [conn178] received client metadata from 114.212.84.175:60286 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:44.989+0800 I  NETWORK  [conn159] end connection 120.55.194.98:32868 (35 connections now open)
2020-09-22T12:11:45.107+0800 I  NETWORK  [conn177] end connection 114.212.84.175:60290 (34 connections now open)
2020-09-22T12:11:45.113+0800 I  NETWORK  [conn178] end connection 114.212.84.175:60286 (33 connections now open)
2020-09-22T12:11:45.171+0800 I  ELECTION [conn166] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 24, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747904, 1), t: 23 } }
2020-09-22T12:11:45.171+0800 I  ELECTION [conn166] Sending vote response: { term: 24, voteGranted: true, reason: "" }
2020-09-22T12:11:45.243+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:11:45.726+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32878 #179 (34 connections now open)
2020-09-22T12:11:45.726+0800 I  NETWORK  [conn179] received client metadata from 120.55.194.98:32878 conn179: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:45.791+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60310 #180 (35 connections now open)
2020-09-22T12:11:45.792+0800 I  NETWORK  [conn180] received client metadata from 114.212.84.175:60310 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:45.801+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60314 #181 (36 connections now open)
2020-09-22T12:11:45.802+0800 I  NETWORK  [conn181] received client metadata from 114.212.84.175:60314 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:45.949+0800 I  NETWORK  [conn180] end connection 114.212.84.175:60310 (35 connections now open)
2020-09-22T12:11:45.955+0800 I  NETWORK  [conn181] end connection 114.212.84.175:60314 (34 connections now open)
2020-09-22T12:11:46.168+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:11:46.169+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:11:46.245+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:46.394+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60324 #183 (35 connections now open)
2020-09-22T12:11:46.394+0800 I  NETWORK  [conn183] received client metadata from 114.212.84.175:60324 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:46.403+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60320 #184 (36 connections now open)
2020-09-22T12:11:46.403+0800 I  NETWORK  [conn184] received client metadata from 114.212.84.175:60320 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:46.547+0800 I  NETWORK  [conn183] end connection 114.212.84.175:60324 (35 connections now open)
2020-09-22T12:11:46.552+0800 I  NETWORK  [conn184] end connection 114.212.84.175:60320 (34 connections now open)
2020-09-22T12:11:46.608+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source changed from 120.55.194.98:27019 to 120.55.192.104:27019
2020-09-22T12:11:46.728+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32880 #185 (35 connections now open)
2020-09-22T12:11:46.729+0800 I  NETWORK  [conn185] received client metadata from 120.55.194.98:32880 conn185: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:47.290+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:47.290+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 24
2020-09-22T12:11:47.290+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 946 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 24, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:11:47.290+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 947 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 24, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:11:47.291+0800 I  ELECTION [replexec-4] VoteRequester(term 24 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 24, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747905, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747905, 30) }
2020-09-22T12:11:47.291+0800 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 25
2020-09-22T12:11:47.291+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.192.104:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:47.292+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 948 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 25, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:11:47.292+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 949 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 25, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747905, 30), t: 24 } }
2020-09-22T12:11:47.294+0800 I  ELECTION [replexec-3] VoteRequester(term 25) received a yes vote from 120.55.194.98:27019; response message: { term: 25, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747897, 14), $clusterTime: { clusterTime: Timestamp(1600747905, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747905, 30) }
2020-09-22T12:11:47.294+0800 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 25
2020-09-22T12:11:47.294+0800 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-09-22T12:11:47.294+0800 I  REPL     [replexec-3] Resetting sync source to empty, which was 120.55.192.104:27019
2020-09-22T12:11:47.294+0800 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-09-22T12:11:47.294+0800 I  CONNPOOL [Replication] Connecting to 120.55.192.104:27019
2020-09-22T12:11:47.294+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.192.104:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:48.239+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.192.104:27019
2020-09-22T12:11:48.292+0800 I  REPL     [replexec-1] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:11:48.292+0800 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747905, 30), t: 24 }. My Last Applied: { ts: Timestamp(1600747905, 30), t: 24 }
2020-09-22T12:11:48.292+0800 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-09-22T12:11:48.292+0800 I  REPL     [replexec-1] Stopping replication producer
2020-09-22T12:11:48.292+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:11:48.293+0800 I  CONNPOOL [RS] Ending connection to host 120.55.192.104:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:48.293+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 25
2020-09-22T12:11:48.293+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 25
2020-09-22T12:11:48.293+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:48.293+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:48.293+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-09-22T12:11:48.295+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:48.295+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:48.296+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:48.299+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:11:48.299+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:11:48.299+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:48.299+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:48.458+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60362 #188 (36 connections now open)
2020-09-22T12:11:48.459+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60358 #189 (37 connections now open)
2020-09-22T12:11:48.459+0800 I  NETWORK  [conn188] received client metadata from 114.212.84.175:60362 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:48.459+0800 I  NETWORK  [conn189] received client metadata from 114.212.84.175:60358 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:48.582+0800 I  NETWORK  [listener] connection accepted from 118.31.43.238:49196 #190 (38 connections now open)
2020-09-22T12:11:48.582+0800 I  NETWORK  [conn190] received client metadata from 118.31.43.238:49196 conn190: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:48.588+0800 I  NETWORK  [listener] connection accepted from 47.96.5.198:36270 #191 (39 connections now open)
2020-09-22T12:11:48.588+0800 I  NETWORK  [conn191] received client metadata from 47.96.5.198:36270 conn191: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:48.598+0800 I  NETWORK  [conn188] end connection 114.212.84.175:60362 (38 connections now open)
2020-09-22T12:11:48.598+0800 I  NETWORK  [conn189] end connection 114.212.84.175:60358 (37 connections now open)
2020-09-22T12:11:49.445+0800 I  NETWORK  [conn82] end connection 112.124.21.191:59398 (36 connections now open)
2020-09-22T12:11:49.590+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:49.590+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:49.590+0800 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:49.590+0800 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-09-22T12:11:49.590+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:49.590+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:49.590+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:49.590+0800 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-09-22T12:11:49.591+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:49.700+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:49.817+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60396 #192 (37 connections now open)
2020-09-22T12:11:49.817+0800 I  NETWORK  [conn192] received client metadata from 114.212.84.175:60396 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:49.824+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60400 #193 (38 connections now open)
2020-09-22T12:11:49.824+0800 I  NETWORK  [conn193] received client metadata from 114.212.84.175:60400 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:49.970+0800 I  NETWORK  [conn193] end connection 114.212.84.175:60400 (37 connections now open)
2020-09-22T12:11:49.971+0800 I  NETWORK  [conn192] end connection 114.212.84.175:60396 (36 connections now open)
2020-09-22T12:11:50.728+0800 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:50.728+0800 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 26
2020-09-22T12:11:50.728+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 959 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:50.728+0800 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 960 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:50.728+0800 I  CONNPOOL [Replication] Connecting to 120.55.192.104:27019
2020-09-22T12:11:50.728+0800 I  ELECTION [replexec-3] VoteRequester(term 26 dry run) received a yes vote from 120.55.194.98:27019; response message: { term: 26, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747910, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747908, 56) }
2020-09-22T12:11:50.729+0800 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 27
2020-09-22T12:11:50.730+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 961 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:50.730+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 962 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:50.735+0800 I  ELECTION [replexec-5] VoteRequester(term 27) received a yes vote from 120.55.194.98:27019; response message: { term: 27, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747910, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747908, 56) }
2020-09-22T12:11:50.735+0800 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 27
2020-09-22T12:11:50.735+0800 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-09-22T12:11:50.735+0800 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-09-22T12:11:50.735+0800 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-09-22T12:11:50.735+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.192.104:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:11:51.292+0800 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1600747908, 56), t: 25 }. My Last Applied: { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:51.292+0800 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-09-22T12:11:51.292+0800 I  REPL     [replexec-0] Stopping replication producer
2020-09-22T12:11:51.292+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 27
2020-09-22T12:11:51.292+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 27
2020-09-22T12:11:51.292+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:51.292+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:51.292+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:11:51.293+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:11:51.293+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:11:51.294+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:11:51.294+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:11:51.294+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:11:52.630+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state RS_DOWN - no response within election timeout period
2020-09-22T12:11:52.630+0800 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-09-22T12:11:52.630+0800 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-09-22T12:11:52.630+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:11:52.630+0800 W  COMMAND  [conn190] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.630+0800 I  COMMAND  [conn190] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747910, 2), signature: { hash: BinData(0, 004BF278760F14F13938C75EA3AFA222D719AAF3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1076ms
2020-09-22T12:11:52.631+0800 W  COMMAND  [conn23] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.631+0800 I  COMMAND  [conn23] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747911, 2), signature: { hash: BinData(0, C86B951CB0F2DB91C8F7CDA9A3CAE9C2B7159595), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1079ms
2020-09-22T12:11:52.631+0800 W  COMMAND  [conn29] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.631+0800 I  COMMAND  [conn29] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.01:27017:1600747818:3466407884530610701" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747910, 2), signature: { hash: BinData(0, 004BF278760F14F13938C75EA3AFA222D719AAF3), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1077ms
2020-09-22T12:11:52.632+0800 W  COMMAND  [conn191] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.632+0800 I  COMMAND  [conn191] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747911, 2), signature: { hash: BinData(0, C86B951CB0F2DB91C8F7CDA9A3CAE9C2B7159595), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 895ms
2020-09-22T12:11:52.632+0800 W  COMMAND  [conn68] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.632+0800 I  COMMAND  [conn68] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.02:27017:1600747818:7156575011715358840" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747911, 2), signature: { hash: BinData(0, C86B951CB0F2DB91C8F7CDA9A3CAE9C2B7159595), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 896ms
2020-09-22T12:11:52.633+0800 W  COMMAND  [conn83] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-09-22T12:11:52.633+0800 I  COMMAND  [conn83] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "Disalg.Hangzhou.I.00:27017:1600747818:2541039578456057690" }, update: { $set: { ping: new Date(1600747909677) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747911, 2), signature: { hash: BinData(0, C86B951CB0F2DB91C8F7CDA9A3CAE9C2B7159595), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747908, 56), t: 25 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:763 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1081ms
2020-09-22T12:11:52.634+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:11:52.634+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 6, userOpsRunning: 0 }
2020-09-22T12:11:52.634+0800 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-09-22T12:11:52.634+0800 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-09-22T12:11:52.634+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:11:52.670+0800 I  ELECTION [conn179] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747908, 56), t: 25 } }
2020-09-22T12:11:52.670+0800 I  ELECTION [conn179] Sending vote response: { term: 27, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747908, 56), t: 25 }, my last applied OpTime: { ts: Timesta..." }
2020-09-22T12:11:52.735+0800 I  REPL     [replexec-5] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:52.941+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60438 #194 (37 connections now open)
2020-09-22T12:11:52.941+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60442 #195 (38 connections now open)
2020-09-22T12:11:52.941+0800 I  NETWORK  [conn195] received client metadata from 114.212.84.175:60442 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:52.942+0800 I  NETWORK  [conn194] received client metadata from 114.212.84.175:60438 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:53.078+0800 I  NETWORK  [conn194] end connection 114.212.84.175:60438 (37 connections now open)
2020-09-22T12:11:53.078+0800 I  NETWORK  [conn195] end connection 114.212.84.175:60442 (36 connections now open)
2020-09-22T12:11:53.723+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:53.723+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 27
2020-09-22T12:11:53.723+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 972 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747911, 15), t: 27 } }
2020-09-22T12:11:53.723+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 973 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747911, 15), t: 27 } }
2020-09-22T12:11:54.235+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:11:54.235+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 970 timed out, deadline was 2020-09-22T12:11:54.235+0800, op was RemoteCommand 970 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:11:54.235+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 27 }
2020-09-22T12:11:54.457+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60506 #196 (37 connections now open)
2020-09-22T12:11:54.458+0800 I  NETWORK  [conn196] received client metadata from 114.212.84.175:60506 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:54.466+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60508 #197 (38 connections now open)
2020-09-22T12:11:54.467+0800 I  NETWORK  [conn197] received client metadata from 114.212.84.175:60508 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:54.536+0800 I  ELECTION [replexec-3] VoteRequester(term 27 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's term (27) is lower than mine (28)"; response message: { term: 28, voteGranted: false, reason: "candidate's term (27) is lower than mine (28)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747908, 56), $clusterTime: { clusterTime: Timestamp(1600747913, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747910, 2) }
2020-09-22T12:11:54.536+0800 I  ELECTION [replexec-3] not running for primary, we have been superseded already
2020-09-22T12:11:54.536+0800 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-09-22T12:11:54.610+0800 I  NETWORK  [conn196] end connection 114.212.84.175:60506 (37 connections now open)
2020-09-22T12:11:54.616+0800 I  NETWORK  [conn197] end connection 114.212.84.175:60508 (36 connections now open)
2020-09-22T12:11:54.762+0800 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-09-22T12:11:55.139+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:11:55.208+0800 I  NETWORK  [conn162] end connection 120.55.192.104:34768 (35 connections now open)
2020-09-22T12:11:55.252+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34792 #198 (36 connections now open)
2020-09-22T12:11:55.252+0800 I  NETWORK  [conn198] received client metadata from 120.55.192.104:34792 conn198: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.287+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60524 #199 (37 connections now open)
2020-09-22T12:11:55.288+0800 I  NETWORK  [conn199] received client metadata from 114.212.84.175:60524 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:55.288+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60520 #200 (38 connections now open)
2020-09-22T12:11:55.289+0800 I  NETWORK  [conn200] received client metadata from 114.212.84.175:60520 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:55.415+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32896 #201 (39 connections now open)
2020-09-22T12:11:55.416+0800 I  NETWORK  [conn201] received client metadata from 120.55.194.98:32896 conn201: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:55.428+0800 I  NETWORK  [conn199] end connection 114.212.84.175:60524 (38 connections now open)
2020-09-22T12:11:55.429+0800 I  NETWORK  [conn200] end connection 114.212.84.175:60520 (37 connections now open)
2020-09-22T12:11:55.488+0800 I  NETWORK  [conn201] end connection 120.55.194.98:32896 (36 connections now open)
2020-09-22T12:11:56.219+0800 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:11:56.219+0800 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 28
2020-09-22T12:11:56.219+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 978 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 28, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747911, 15), t: 27 } }
2020-09-22T12:11:56.219+0800 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 979 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 28, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747911, 15), t: 27 } }
2020-09-22T12:11:56.220+0800 I  ELECTION [replexec-6] VoteRequester(term 28 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747911, 15), t: 27 }, my last applied OpTime: { ts: Timestamp(1600747914, 1), t: 28 }"; response message: { term: 28, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747911, 15), t: 27 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1600747914, 1), $clusterTime: { clusterTime: Timestamp(1600747915, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747914, 1) }
2020-09-22T12:11:56.320+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34784 #202 (37 connections now open)
2020-09-22T12:11:56.320+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34782 #203 (38 connections now open)
2020-09-22T12:11:56.320+0800 I  NETWORK  [conn203] received client metadata from 120.55.192.104:34782 conn203: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:56.321+0800 I  NETWORK  [conn202] received client metadata from 120.55.192.104:34784 conn202: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:11:56.566+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60550 #204 (39 connections now open)
2020-09-22T12:11:56.566+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60546 #205 (40 connections now open)
2020-09-22T12:11:56.566+0800 I  NETWORK  [conn205] received client metadata from 114.212.84.175:60546 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:56.567+0800 I  NETWORK  [conn204] received client metadata from 114.212.84.175:60550 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:11:56.635+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:56.637+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:56.637+0800 I  CONNPOOL [RS] Connecting to 120.55.194.98:27019
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1600747911, 15), t: 27 }. source's GTE: { ts: Timestamp(1600747914, 1), t: 28 }
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: 120.55.194.98:27019)
2020-09-22T12:11:56.638+0800 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 41 }
2020-09-22T12:11:56.638+0800 I  ROLLBACK [rsBackgroundSync] ElectionInProgress: Cannot transition from SECONDARY to ROLLBACK :: caused by :: Cannot set follower mode to ROLLBACK because we are in the middle of running an election
2020-09-22T12:11:56.638+0800 W  REPL     [rsBackgroundSync] Rollback failed with retryable error: ElectionInProgress: Cannot transition from SECONDARY to ROLLBACK :: caused by :: Cannot set follower mode to ROLLBACK because we are in the middle of running an election
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-09-22T12:11:56.638+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:56.638+0800 I  ELECTION [replexec-1] not running for primary, we received insufficient votes
2020-09-22T12:11:56.638+0800 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-09-22T12:11:56.639+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1600747911, 15), t: 27 }. source's GTE: { ts: Timestamp(1600747914, 1), t: 28 }
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: 120.55.194.98:27019)
2020-09-22T12:11:56.640+0800 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 41 }
2020-09-22T12:11:56.640+0800 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 203
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 202
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 198
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 191
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 190
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 185
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 179
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 166
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 157
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 122
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 101
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-09-22T12:11:56.641+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-09-22T12:11:56.641+0800 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-09-22T12:11:56.641+0800 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-09-22T12:11:56.641+0800 I  ROLLBACK [rsBackgroundSync] finding common point
2020-09-22T12:11:56.641+0800 I  NETWORK  [conn205] end connection 114.212.84.175:60546 (39 connections now open)
2020-09-22T12:11:56.641+0800 I  NETWORK  [conn204] end connection 114.212.84.175:60550 (38 connections now open)
2020-09-22T12:11:56.644+0800 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:56.645+0800 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-09-22T12:11:56.645+0800 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-09-22T12:11:56.645+0800 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 990ea228-4f92-4ac6-83ef-83a3dd549ffd to /var/lib/mongodb/rollback/config.lockpings/removed.2020-09-22T04-11-56.0.bson
2020-09-22T12:11:56.645+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-09-22T12:11:56.646+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-09-22T12:11:56.646+0800 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-09-22T12:11:56.646+0800 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-09-22T12:11:56.669+0800 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1600747908, 56) Initial Data Timestamp: Timestamp(1600747816, 1)
2020-09-22T12:11:56.669+0800 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-09-22T12:11:56.675+0800 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-09-22T12:11:56.675+0800 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 218 records totaling to 47298 bytes
2020-09-22T12:11:56.675+0800 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:11:56.675+0800 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-09-22T12:11:56.677+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-09-22T12:11:56.677+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-09-22T12:11:56.687+0800 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-09-22T12:11:56.687+0800 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-09-22T12:11:56.687+0800 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1600747908, 56)
2020-09-22T12:11:56.687+0800 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 3 update operations and 0 delete operations.
2020-09-22T12:11:56.687+0800 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1600747911, 1), t: 27 }
2020-09-22T12:11:56.687+0800 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1600747911, 1) }
2020-09-22T12:11:56.687+0800 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1600747908, 56) (top of oplog: { ts: Timestamp(1600747908, 56), t: 25 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1600747908, 56)
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-09-22T12:11:56.640+0800
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-09-22T12:11:56.688+0800
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	sync source: 120.55.194.98:27019
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1600747911, 15), t: 27 }
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1600747908, 56), t: 25 }
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-09-22T12:11:51.736+0800
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-09-22T12:11:48.585+0800
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 3 second(s)
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1600747911, 1)
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1600747908, 56)
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 		update: 3
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 4
2020-09-22T12:11:56.688+0800 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Rollback successful.
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-09-22T12:11:56.688+0800 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-09-22T12:11:56.689+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:11:56.690+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:11:57.242+0800 I  ELECTION [conn179] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 28, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747914, 1), t: 28 } }
2020-09-22T12:11:57.242+0800 I  ELECTION [conn179] Sending vote response: { term: 28, voteGranted: true, reason: "" }
2020-09-22T12:11:57.244+0800 I  ELECTION [conn179] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 29, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747914, 1), t: 28 } }
2020-09-22T12:11:57.245+0800 I  ELECTION [conn179] Sending vote response: { term: 29, voteGranted: true, reason: "" }
2020-09-22T12:11:58.640+0800 I  REPL     [replexec-3] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:11:58.975+0800 I  NETWORK  [conn101] end connection 120.55.194.98:32830 (37 connections now open)
2020-09-22T12:11:59.242+0800 I  NETWORK  [conn30] end connection 120.55.194.98:60982 (36 connections now open)
2020-09-22T12:11:59.882+0800 I  NETWORK  [conn81] end connection 120.55.194.98:32814 (35 connections now open)
2020-09-22T12:12:00.248+0800 I  NETWORK  [conn166] end connection 120.55.192.104:34766 (34 connections now open)
2020-09-22T12:12:00.298+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60610 #209 (35 connections now open)
2020-09-22T12:12:00.299+0800 I  NETWORK  [conn209] received client metadata from 114.212.84.175:60610 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.309+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60614 #210 (36 connections now open)
2020-09-22T12:12:00.309+0800 I  NETWORK  [conn210] received client metadata from 114.212.84.175:60614 conn210: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.328+0800 I  NETWORK  [conn27] end connection 120.55.192.104:34648 (35 connections now open)
2020-09-22T12:12:00.451+0800 I  NETWORK  [conn209] end connection 114.212.84.175:60610 (34 connections now open)
2020-09-22T12:12:00.456+0800 I  NETWORK  [conn210] end connection 114.212.84.175:60614 (33 connections now open)
2020-09-22T12:12:00.889+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60622 #211 (34 connections now open)
2020-09-22T12:12:00.890+0800 I  NETWORK  [conn211] received client metadata from 114.212.84.175:60622 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:00.892+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60626 #212 (35 connections now open)
2020-09-22T12:12:00.892+0800 I  NETWORK  [conn212] received client metadata from 114.212.84.175:60626 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:01.024+0800 I  NETWORK  [conn211] end connection 114.212.84.175:60622 (34 connections now open)
2020-09-22T12:12:01.025+0800 I  NETWORK  [conn212] end connection 114.212.84.175:60626 (33 connections now open)
2020-09-22T12:12:01.703+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60640 #213 (34 connections now open)
2020-09-22T12:12:01.704+0800 I  NETWORK  [conn213] received client metadata from 114.212.84.175:60640 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:01.706+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60636 #214 (35 connections now open)
2020-09-22T12:12:01.706+0800 I  NETWORK  [conn214] received client metadata from 114.212.84.175:60636 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:01.865+0800 I  NETWORK  [conn213] end connection 114.212.84.175:60640 (34 connections now open)
2020-09-22T12:12:01.866+0800 I  NETWORK  [conn214] end connection 114.212.84.175:60636 (33 connections now open)
2020-09-22T12:12:04.131+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60700 #215 (34 connections now open)
2020-09-22T12:12:04.132+0800 I  NETWORK  [conn215] received client metadata from 114.212.84.175:60700 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.132+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60696 #216 (35 connections now open)
2020-09-22T12:12:04.132+0800 I  NETWORK  [conn216] received client metadata from 114.212.84.175:60696 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.268+0800 I  NETWORK  [conn215] end connection 114.212.84.175:60700 (34 connections now open)
2020-09-22T12:12:04.269+0800 I  NETWORK  [conn216] end connection 114.212.84.175:60696 (33 connections now open)
2020-09-22T12:12:04.943+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60720 #217 (34 connections now open)
2020-09-22T12:12:04.943+0800 I  NETWORK  [conn217] received client metadata from 114.212.84.175:60720 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:04.945+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60716 #218 (35 connections now open)
2020-09-22T12:12:04.946+0800 I  NETWORK  [conn218] received client metadata from 114.212.84.175:60716 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:05.078+0800 I  NETWORK  [conn217] end connection 114.212.84.175:60720 (34 connections now open)
2020-09-22T12:12:05.079+0800 I  NETWORK  [conn218] end connection 114.212.84.175:60716 (33 connections now open)
2020-09-22T12:12:05.761+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:12:06.154+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.154+0800 I  ELECTION [conn203] Sending vote response: { term: 29, voteGranted: true, reason: "" }
2020-09-22T12:12:06.156+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:06.156+0800 I  ELECTION [conn203] Sending vote response: { term: 30, voteGranted: true, reason: "" }
2020-09-22T12:12:07.286+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:07.286+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 30
2020-09-22T12:12:07.286+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1070 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:07.286+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1071 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747924, 3), t: 29 } }
2020-09-22T12:12:07.286+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:07.286+0800 I  ELECTION [replexec-4] VoteRequester(term 30 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747924, 3), t: 29 }, my last applied OpTime: { ts: Timestamp(1600747926, 2), t: 30 }"; response message: { term: 30, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747924, 3), t: 29 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001e') }, lastCommittedOpTime: Timestamp(1600747924, 3), $clusterTime: { clusterTime: Timestamp(1600747927, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747926, 2) }
2020-09-22T12:12:07.641+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:07.641+0800 I  REPL     [replexec-1] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 1069 timed out, deadline was 2020-09-22T12:12:07.641+0800, op was RemoteCommand 1069 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:12:07.641+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 30 }
2020-09-22T12:12:08.286+0800 I  ELECTION [replexec-0] VoteRequester(term 30 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:08.286+0800 I  ELECTION [replexec-0] not running for primary, we received insufficient votes
2020-09-22T12:12:08.286+0800 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-09-22T12:12:08.305+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.305+0800 I  ELECTION [conn203] Sending vote response: { term: 30, voteGranted: true, reason: "" }
2020-09-22T12:12:08.307+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747926, 2), t: 30 } }
2020-09-22T12:12:08.307+0800 I  ELECTION [conn203] Sending vote response: { term: 31, voteGranted: true, reason: "" }
2020-09-22T12:12:08.513+0800 I  NETWORK  [conn179] end connection 120.55.194.98:32878 (32 connections now open)
2020-09-22T12:12:08.602+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60782 #221 (33 connections now open)
2020-09-22T12:12:08.603+0800 I  NETWORK  [conn221] received client metadata from 114.212.84.175:60782 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:08.611+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60776 #222 (34 connections now open)
2020-09-22T12:12:08.611+0800 I  NETWORK  [conn222] received client metadata from 114.212.84.175:60776 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:08.748+0800 I  NETWORK  [conn221] end connection 114.212.84.175:60782 (33 connections now open)
2020-09-22T12:12:08.752+0800 I  NETWORK  [conn222] end connection 114.212.84.175:60776 (32 connections now open)
2020-09-22T12:12:09.250+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32906 #223 (33 connections now open)
2020-09-22T12:12:09.251+0800 I  NETWORK  [conn223] received client metadata from 120.55.194.98:32906 conn223: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:09.588+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 31, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747929, 1), t: 31 } }
2020-09-22T12:12:09.588+0800 I  ELECTION [conn223] Sending vote response: { term: 31, voteGranted: true, reason: "" }
2020-09-22T12:12:09.592+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747929, 1), t: 31 } }
2020-09-22T12:12:09.592+0800 I  ELECTION [conn223] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-09-22T12:12:10.107+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60792 #224 (34 connections now open)
2020-09-22T12:12:10.108+0800 I  NETWORK  [conn224] received client metadata from 114.212.84.175:60792 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:10.117+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60796 #225 (35 connections now open)
2020-09-22T12:12:10.118+0800 I  NETWORK  [conn225] received client metadata from 114.212.84.175:60796 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:10.263+0800 I  NETWORK  [conn224] end connection 114.212.84.175:60792 (34 connections now open)
2020-09-22T12:12:10.268+0800 I  NETWORK  [conn225] end connection 114.212.84.175:60796 (33 connections now open)
2020-09-22T12:12:10.666+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.666+0800 I  ELECTION [conn203] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-09-22T12:12:10.668+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 33, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 33), t: 32 } }
2020-09-22T12:12:10.668+0800 I  ELECTION [conn203] Sending vote response: { term: 33, voteGranted: true, reason: "" }
2020-09-22T12:12:11.056+0800 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747930, 33), t: 32 }, latest oplog optime of sync source: { ts: Timestamp(1600747930, 33), t: 32 } (sync source does not know the primary)
2020-09-22T12:12:11.056+0800 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747930, 33), t: 32 }, its sync source index:-1
2020-09-22T12:12:11.056+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747930, 33), t: 32 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:12:11.056+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:12:11.056+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:12:11.057+0800 I  REPL     [replexec-3] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:12:11.099+0800 I  NETWORK  [conn122] end connection 120.55.192.104:34742 (32 connections now open)
2020-09-22T12:12:11.555+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:12:11.644+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60824 #226 (33 connections now open)
2020-09-22T12:12:11.645+0800 I  NETWORK  [conn226] received client metadata from 114.212.84.175:60824 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:11.651+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60830 #227 (34 connections now open)
2020-09-22T12:12:11.652+0800 I  NETWORK  [conn227] received client metadata from 114.212.84.175:60830 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:11.796+0800 I  NETWORK  [conn226] end connection 114.212.84.175:60824 (33 connections now open)
2020-09-22T12:12:11.799+0800 I  NETWORK  [conn227] end connection 114.212.84.175:60830 (32 connections now open)
2020-09-22T12:12:12.056+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:12:12.628+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:12.628+0800 I  ELECTION [conn223] Sending vote response: { term: 33, voteGranted: true, reason: "" }
2020-09-22T12:12:12.630+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:12.630+0800 I  ELECTION [conn223] Sending vote response: { term: 34, voteGranted: true, reason: "" }
2020-09-22T12:12:12.872+0800 I  REPL     [replexec-2] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:12:12.872+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:12:12.872+0800 I  CONNPOOL [RS] Connecting to 120.55.192.104:27019
2020-09-22T12:12:12.875+0800 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.192.104:27019, my last fetched oplog optime: { ts: Timestamp(1600747930, 56), t: 33 }, latest oplog optime of sync source: { ts: Timestamp(1600747930, 56), t: 33 } (120.55.194.98:27019 is)
2020-09-22T12:12:12.876+0800 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.192.104:27019, OpTime { ts: Timestamp(1600747930, 56), t: 33 }, its sync source index:-1
2020-09-22T12:12:12.876+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.192.104:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747930, 56), t: 33 }; sync source index: -1; primary index: 0) is no longer valid
2020-09-22T12:12:12.876+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.192.104:27019 to choose a new one.
2020-09-22T12:12:12.876+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:12:12.876+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:12.876+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.192.104:27019
2020-09-22T12:12:12.876+0800 I  COMMAND  [conn40] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1616299817, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1600747930, 56), t: 33 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1600747932, 1), signature: { hash: BinData(0, 7CFC87D9ECABDEB05E64130BA36E42E33F28DFED), keyId: 6875159523158392863 } }, $configServerState: { opTime: { ts: Timestamp(1600747930, 56), t: 33 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 hasSortStage:1 cursorExhausted:1 numYields:0 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:573 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 688ms
2020-09-22T12:12:12.878+0800 I  REPL     [replexec-4] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:13.279+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60870 #230 (33 connections now open)
2020-09-22T12:12:13.280+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60874 #231 (34 connections now open)
2020-09-22T12:12:13.280+0800 I  NETWORK  [conn230] received client metadata from 114.212.84.175:60870 conn230: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:13.281+0800 I  NETWORK  [conn231] received client metadata from 114.212.84.175:60874 conn231: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:13.419+0800 I  NETWORK  [conn230] end connection 114.212.84.175:60870 (33 connections now open)
2020-09-22T12:12:13.419+0800 I  NETWORK  [conn231] end connection 114.212.84.175:60874 (32 connections now open)
2020-09-22T12:12:13.876+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:14.193+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.193+0800 I  ELECTION [conn203] Sending vote response: { term: 34, voteGranted: true, reason: "" }
2020-09-22T12:12:14.195+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:14.195+0800 I  ELECTION [conn203] Sending vote response: { term: 35, voteGranted: true, reason: "" }
2020-09-22T12:12:14.388+0800 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:12:14.390+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:12:14.878+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:14.878+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 1121 timed out, deadline was 2020-09-22T12:12:14.878+0800, op was RemoteCommand 1121 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:12:14.878+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 34 }
2020-09-22T12:12:15.323+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:15.323+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 35
2020-09-22T12:12:15.323+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1125 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:15.323+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1126 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747930, 56), t: 33 } }
2020-09-22T12:12:15.323+0800 I  ELECTION [replexec-0] VoteRequester(term 35 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747930, 56), t: 33 }, my last applied OpTime: { ts: Timestamp(1600747934, 2), t: 35 }"; response message: { term: 35, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747930, 56), t: 33 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000023') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747934, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747934, 2) }
2020-09-22T12:12:15.572+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:12:15.575+0800 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: 120.55.194.98:27019, my last fetched oplog optime: { ts: Timestamp(1600747934, 2), t: 34 }, latest oplog optime of sync source: { ts: Timestamp(1600747934, 2), t: 34 } (sync source does not know the primary)
2020-09-22T12:12:15.575+0800 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: 120.55.194.98:27019, OpTime { ts: Timestamp(1600747934, 2), t: 34 }, its sync source index:-1
2020-09-22T12:12:15.575+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747934, 2), t: 34 }; sync source index: -1; primary index: -1) is no longer valid
2020-09-22T12:12:15.575+0800 I  REPL     [rsBackgroundSync] Clearing sync source 120.55.194.98:27019 to choose a new one.
2020-09-22T12:12:15.575+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:12:15.575+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:15.577+0800 I  ELECTION [replexec-1] VoteRequester(term 35 dry run) received a no vote from 120.55.194.98:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747930, 56), t: 33 }, my last applied OpTime: { ts: Timestamp(1600747934, 2), t: 34 }"; response message: { term: 35, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747930, 56), t: 33 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000022') }, lastCommittedOpTime: Timestamp(1600747930, 56), $clusterTime: { clusterTime: Timestamp(1600747934, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747934, 2) }
2020-09-22T12:12:15.577+0800 I  ELECTION [replexec-1] not running for primary, we received insufficient votes
2020-09-22T12:12:15.577+0800 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-09-22T12:12:15.577+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:12:15.639+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60936 #233 (33 connections now open)
2020-09-22T12:12:15.640+0800 I  NETWORK  [conn233] received client metadata from 114.212.84.175:60936 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:15.640+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60940 #234 (34 connections now open)
2020-09-22T12:12:15.640+0800 I  NETWORK  [conn234] received client metadata from 114.212.84.175:60940 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:15.776+0800 I  NETWORK  [conn233] end connection 114.212.84.175:60936 (33 connections now open)
2020-09-22T12:12:15.776+0800 I  NETWORK  [conn234] end connection 114.212.84.175:60940 (32 connections now open)
2020-09-22T12:12:16.076+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:12:16.334+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 35, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.334+0800 I  ELECTION [conn203] Sending vote response: { term: 35, voteGranted: true, reason: "" }
2020-09-22T12:12:16.336+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 36, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747934, 2), t: 35 } }
2020-09-22T12:12:16.336+0800 I  ELECTION [conn203] Sending vote response: { term: 36, voteGranted: true, reason: "" }
2020-09-22T12:12:16.575+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.192.104:27019
2020-09-22T12:12:16.576+0800 I  REPL     [replexec-0] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.192.104:27019
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1600747934, 2), t: 34 }. source's GTE: { ts: Timestamp(1600747934, 2), t: 35 }
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1600747930, 56), t: 33 }
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: 120.55.192.104:27019)
2020-09-22T12:12:16.577+0800 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 33 }
2020-09-22T12:12:16.577+0800 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 223
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 203
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 202
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 198
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 191
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 190
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 185
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 157
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-09-22T12:12:16.577+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-09-22T12:12:16.578+0800 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-09-22T12:12:16.578+0800 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-09-22T12:12:16.578+0800 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-09-22T12:12:16.578+0800 I  ROLLBACK [rsBackgroundSync] finding common point
2020-09-22T12:12:16.581+0800 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1600747930, 56), t: 33 }
2020-09-22T12:12:16.582+0800 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 4
2020-09-22T12:12:16.582+0800 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-09-22T12:12:16.582+0800 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 990ea228-4f92-4ac6-83ef-83a3dd549ffd to /var/lib/mongodb/rollback/config.lockpings/removed.2020-09-22T04-12-16.1.bson
2020-09-22T12:12:16.582+0800 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid 282775af-a43f-4c57-858a-851b59ec70fc to /var/lib/mongodb/rollback/config.mongos/removed.2020-09-22T04-12-16.2.bson
2020-09-22T12:12:16.583+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-09-22T12:12:16.583+0800 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-09-22T12:12:16.583+0800 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-09-22T12:12:16.583+0800 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-09-22T12:12:16.595+0800 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1600747930, 56) Initial Data Timestamp: Timestamp(1600747816, 1)
2020-09-22T12:12:16.595+0800 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-09-22T12:12:16.601+0800 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-09-22T12:12:16.601+0800 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 242 records totaling to 51807 bytes
2020-09-22T12:12:16.601+0800 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-09-22T12:12:16.601+0800 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-09-22T12:12:16.603+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-09-22T12:12:16.603+0800 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-09-22T12:12:16.613+0800 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-09-22T12:12:16.613+0800 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-09-22T12:12:16.613+0800 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1600747930, 56)
2020-09-22T12:12:16.613+0800 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 2 update operations and 0 delete operations.
2020-09-22T12:12:16.613+0800 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1600747932, 5), t: 34 }
2020-09-22T12:12:16.613+0800 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1600747932, 5) }
2020-09-22T12:12:16.613+0800 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-09-22T12:12:16.614+0800 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1600747930, 56) (top of oplog: { ts: Timestamp(1600747930, 56), t: 33 }, appliedThrough: { ts: Timestamp(1600747930, 56), t: 33 }, TruncateAfter: Timestamp(0, 0))
2020-09-22T12:12:16.614+0800 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1600747930, 56)
2020-09-22T12:12:16.614+0800 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-09-22T12:12:16.614+0800 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-09-22T12:12:16.577+0800
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-09-22T12:12:16.615+0800
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	sync source: 120.55.192.104:27019
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	rollback id: 4
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1600747934, 2), t: 34 }
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1600747930, 56), t: 33 }
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-09-22T12:12:14.265+0800
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-09-22T12:12:12.635+0800
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 1 second(s)
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1600747932, 5)
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1600747930, 56)
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 		update: 2
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 3
2020-09-22T12:12:16.615+0800 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was 120.55.192.104:27019
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] Rollback successful.
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-09-22T12:12:16.615+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:16.616+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:12:16.616+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.192.104:27019: InvalidSyncSource: Sync source changed from 120.55.192.104:27019 to 120.55.194.98:27019
2020-09-22T12:12:17.504+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 36, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:17.504+0800 I  ELECTION [conn223] Sending vote response: { term: 36, voteGranted: true, reason: "" }
2020-09-22T12:12:17.506+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 37, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:17.506+0800 I  ELECTION [conn223] Sending vote response: { term: 37, voteGranted: true, reason: "" }
2020-09-22T12:12:17.820+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60984 #236 (33 connections now open)
2020-09-22T12:12:17.821+0800 I  NETWORK  [conn236] received client metadata from 114.212.84.175:60984 conn236: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:17.827+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60988 #237 (34 connections now open)
2020-09-22T12:12:17.828+0800 I  NETWORK  [conn237] received client metadata from 114.212.84.175:60988 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:17.976+0800 I  NETWORK  [conn236] end connection 114.212.84.175:60984 (33 connections now open)
2020-09-22T12:12:17.980+0800 I  NETWORK  [conn237] end connection 114.212.84.175:60988 (32 connections now open)
2020-09-22T12:12:18.411+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32768 #238 (33 connections now open)
2020-09-22T12:12:18.411+0800 I  NETWORK  [conn238] received client metadata from 114.212.84.175:32768 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:18.418+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:60996 #239 (34 connections now open)
2020-09-22T12:12:18.419+0800 I  NETWORK  [conn239] received client metadata from 114.212.84.175:60996 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:18.555+0800 I  NETWORK  [conn238] end connection 114.212.84.175:32768 (33 connections now open)
2020-09-22T12:12:18.559+0800 I  NETWORK  [conn239] end connection 114.212.84.175:60996 (32 connections now open)
2020-09-22T12:12:18.578+0800 I  REPL     [replexec-6] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:19.576+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.192.104:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-09-22T12:12:19.576+0800 I  REPL     [replexec-1] Member 120.55.192.104:27019 is now in state RS_DOWN - Request 1172 timed out, deadline was 2020-09-22T12:12:19.576+0800, op was RemoteCommand 1172 -- target:[120.55.192.104:27019] db:admin expDate:2020-09-22T12:12:19.576+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 37 }
2020-09-22T12:12:20.306+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34820 #240 (33 connections now open)
2020-09-22T12:12:20.306+0800 I  NETWORK  [conn240] received client metadata from 120.55.192.104:34820 conn240: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:20.392+0800 I  NETWORK  [conn66] end connection 120.55.192.104:34706 (32 connections now open)
2020-09-22T12:12:20.468+0800 I  NETWORK  [conn202] end connection 120.55.192.104:34784 (31 connections now open)
2020-09-22T12:12:20.527+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32820 #241 (32 connections now open)
2020-09-22T12:12:20.527+0800 I  NETWORK  [conn241] received client metadata from 114.212.84.175:32820 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:20.537+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32816 #242 (33 connections now open)
2020-09-22T12:12:20.537+0800 I  NETWORK  [conn242] received client metadata from 114.212.84.175:32816 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:20.673+0800 I  NETWORK  [conn241] end connection 114.212.84.175:32820 (32 connections now open)
2020-09-22T12:12:20.678+0800 I  NETWORK  [conn242] end connection 114.212.84.175:32816 (31 connections now open)
2020-09-22T12:12:20.836+0800 I  NETWORK  [listener] connection accepted from 120.55.192.104:34818 #243 (32 connections now open)
2020-09-22T12:12:20.836+0800 I  NETWORK  [conn243] received client metadata from 120.55.192.104:34818 conn243: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:21.112+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32842 #244 (33 connections now open)
2020-09-22T12:12:21.112+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32838 #245 (34 connections now open)
2020-09-22T12:12:21.112+0800 I  NETWORK  [conn245] received client metadata from 114.212.84.175:32838 conn245: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.113+0800 I  NETWORK  [conn244] received client metadata from 114.212.84.175:32842 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.261+0800 I  NETWORK  [conn244] end connection 114.212.84.175:32842 (33 connections now open)
2020-09-22T12:12:21.261+0800 I  NETWORK  [conn245] end connection 114.212.84.175:32838 (32 connections now open)
2020-09-22T12:12:21.576+0800 I  REPL     [replexec-6] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:12:21.816+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32870 #246 (33 connections now open)
2020-09-22T12:12:21.816+0800 I  NETWORK  [conn246] received client metadata from 114.212.84.175:32870 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.819+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32866 #247 (34 connections now open)
2020-09-22T12:12:21.820+0800 I  NETWORK  [conn247] received client metadata from 114.212.84.175:32866 conn247: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:21.884+0800 I  ELECTION [conn203] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747937, 2), t: 36 } }
2020-09-22T12:12:21.884+0800 I  ELECTION [conn203] Sending vote response: { term: 37, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747937, 2), t: 36 }, my last applied OpTime: { ts: Timestam..." }
2020-09-22T12:12:21.884+0800 I  NETWORK  [conn203] end connection 120.55.192.104:34782 (33 connections now open)
2020-09-22T12:12:21.973+0800 I  NETWORK  [conn246] end connection 114.212.84.175:32870 (32 connections now open)
2020-09-22T12:12:21.974+0800 I  NETWORK  [conn247] end connection 114.212.84.175:32866 (31 connections now open)
2020-09-22T12:12:22.729+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:22.729+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 37
2020-09-22T12:12:22.729+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1213 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.729+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1214 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 37, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.729+0800 I  ELECTION [replexec-1] VoteRequester(term 37 dry run) received a yes vote from 120.55.192.104:27019; response message: { term: 37, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000024') }, lastCommittedOpTime: Timestamp(1600747940, 12), $clusterTime: { clusterTime: Timestamp(1600747941, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747940, 12) }
2020-09-22T12:12:22.729+0800 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 38
2020-09-22T12:12:22.731+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1215 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 38, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.731+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1216 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 38, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747940, 12), t: 37 } }
2020-09-22T12:12:22.731+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:22.732+0800 I  ELECTION [replexec-2] VoteRequester(term 38) received a yes vote from 120.55.192.104:27019; response message: { term: 38, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000024') }, lastCommittedOpTime: Timestamp(1600747940, 12), $clusterTime: { clusterTime: Timestamp(1600747941, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747940, 12) }
2020-09-22T12:12:22.732+0800 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 38
2020-09-22T12:12:22.732+0800 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-09-22T12:12:22.732+0800 I  REPL     [replexec-2] Resetting sync source to empty, which was 120.55.194.98:27019
2020-09-22T12:12:22.732+0800 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-09-22T12:12:22.733+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:12:22.734+0800 I  REPL     [replexec-0] Heartbeats updated catchup target optime to { ts: Timestamp(1600747942, 16), t: 37 }
2020-09-22T12:12:22.734+0800 I  REPL     [replexec-0] Latest known optime per replica set member:
2020-09-22T12:12:22.734+0800 I  REPL     [replexec-0] Member ID: MemberId(0), latest known optime: { ts: Timestamp(1600747942, 16), t: 37 }
2020-09-22T12:12:22.734+0800 I  REPL     [replexec-0] Member ID: MemberId(1), latest known optime: { ts: Timestamp(1600747940, 12), t: 37 }
2020-09-22T12:12:22.734+0800 I  REPL     [replexec-0] Member ID: MemberId(2), latest known optime: unknown
2020-09-22T12:12:22.944+0800 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to 120.55.194.98:27019: InvalidSyncSource: Sync source was cleared. Was 120.55.194.98:27019
2020-09-22T12:12:22.945+0800 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source 120.55.194.98:27019 (config version: 1; last applied optime: { ts: Timestamp(1600747940, 12), t: 37 }; sync source index: -1; primary index: 0) is no longer valid
2020-09-22T12:12:22.945+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:22.946+0800 I  REPL     [rsBackgroundSync] Changed sync source from empty to 120.55.194.98:27019
2020-09-22T12:12:22.950+0800 I  REPL     [replication-0] Restarting oplog query due to error: StaleTerm: error in fetcher batch callback :: caused by :: Replication term of this node was stale; retry query. Last fetched optime: { ts: Timestamp(1600747940, 12), t: 37 }. Restarts remaining: 1
2020-09-22T12:12:22.950+0800 I  REPL     [replication-0] Scheduled new oplog query Fetcher source: 120.55.194.98:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1600747940, 12) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 38, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 1223 -- target:120.55.194.98:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1600747940, 12) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 38, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-09-22T12:12:22.952+0800 I  REPL     [rsSync-0] Caught up to the latest known optime successfully after becoming primary. Target optime: { ts: Timestamp(1600747942, 16), t: 37 }. My Last Applied: { ts: Timestamp(1600747942, 16), t: 37 }
2020-09-22T12:12:22.952+0800 I  REPL     [rsSync-0] Exited primary catch-up mode.
2020-09-22T12:12:22.952+0800 I  REPL     [rsSync-0] Stopping replication producer
2020-09-22T12:12:22.952+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 38
2020-09-22T12:12:22.952+0800 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 38
2020-09-22T12:12:22.952+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:22.952+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:22.952+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-09-22T12:12:22.953+0800 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-09-22T12:12:22.953+0800 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-09-22T12:12:22.954+0800 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-09-22T12:12:22.953+0800 I  SHARDING [Balancer] CSRS balancer is starting
2020-09-22T12:12:22.955+0800 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-09-22T12:12:22.955+0800 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-09-22T12:12:22.955+0800 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:12:22.958+0800 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-09-22T12:12:22.958+0800 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-09-22T12:12:22.958+0800 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/118.31.43.238:27018,47.96.16.32:27018,47.96.5.198:27018
2020-09-22T12:12:22.958+0800 I  CONNPOOL [ShardRegistry] Connecting to 47.96.5.198:27018
2020-09-22T12:12:23.800+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32922 #251 (32 connections now open)
2020-09-22T12:12:23.801+0800 I  NETWORK  [conn251] received client metadata from 114.212.84.175:32922 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:23.809+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32926 #252 (33 connections now open)
2020-09-22T12:12:23.810+0800 I  NETWORK  [conn252] received client metadata from 114.212.84.175:32926 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:23.964+0800 I  NETWORK  [conn251] end connection 114.212.84.175:32922 (32 connections now open)
2020-09-22T12:12:23.969+0800 I  NETWORK  [conn252] end connection 114.212.84.175:32926 (31 connections now open)
2020-09-22T12:12:24.734+0800 I  REPL     [replexec-2] Member 120.55.194.98:27019 is now in state SECONDARY
2020-09-22T12:12:24.756+0800 I  ELECTION [conn223] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 38, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:24.756+0800 I  ELECTION [conn223] Sending vote response: { term: 38, voteGranted: true, reason: "" }
2020-09-22T12:12:24.757+0800 I  NETWORK  [conn223] end connection 120.55.194.98:32906 (30 connections now open)
2020-09-22T12:12:24.758+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32926 #253 (31 connections now open)
2020-09-22T12:12:24.758+0800 I  NETWORK  [conn253] received client metadata from 120.55.194.98:32926 conn253: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:24.758+0800 I  REPL     [conn253] stepping down from primary, because a new term has begun: 39
2020-09-22T12:12:24.759+0800 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-09-22T12:12:24.759+0800 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-09-22T12:12:24.759+0800 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-09-22T12:12:24.759+0800 I  REPL     [replexec-7] transition to SECONDARY from PRIMARY
2020-09-22T12:12:24.759+0800 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-09-22T12:12:24.760+0800 I  REPL     [replexec-0] Member 120.55.194.98:27019 is now in state PRIMARY
2020-09-22T12:12:24.760+0800 I  ELECTION [conn253] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 39, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:24.760+0800 I  ELECTION [conn253] Sending vote response: { term: 39, voteGranted: true, reason: "" }
2020-09-22T12:12:24.760+0800 I  NETWORK  [listener] connection accepted from 120.55.194.98:32928 #254 (32 connections now open)
2020-09-22T12:12:24.761+0800 I  NETWORK  [conn254] received client metadata from 120.55.194.98:32928 conn254: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-09-22T12:12:24.761+0800 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-09-22T12:12:24.762+0800 I  NETWORK  [conn253] end connection 120.55.194.98:32926 (31 connections now open)
2020-09-22T12:12:24.815+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32956 #255 (32 connections now open)
2020-09-22T12:12:24.815+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32960 #256 (33 connections now open)
2020-09-22T12:12:24.815+0800 I  NETWORK  [conn256] received client metadata from 114.212.84.175:32960 conn256: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:24.816+0800 I  NETWORK  [conn255] received client metadata from 114.212.84.175:32956 conn255: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:24.956+0800 I  NETWORK  [conn86] end connection 120.55.194.98:32818 (32 connections now open)
2020-09-22T12:12:24.969+0800 I  NETWORK  [conn255] end connection 114.212.84.175:32956 (31 connections now open)
2020-09-22T12:12:24.970+0800 I  NETWORK  [conn256] end connection 114.212.84.175:32960 (30 connections now open)
2020-09-22T12:12:25.404+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32970 #257 (31 connections now open)
2020-09-22T12:12:25.404+0800 I  NETWORK  [conn257] received client metadata from 114.212.84.175:32970 conn257: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:25.417+0800 I  NETWORK  [listener] connection accepted from 114.212.84.175:32974 #258 (32 connections now open)
2020-09-22T12:12:25.417+0800 I  NETWORK  [conn258] received client metadata from 114.212.84.175:32974 conn258: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.4.0-47-generic" }, platform: "Java/Ubuntu/11.0.8+10-post-Ubuntu-0ubuntu120.04" }
2020-09-22T12:12:25.571+0800 I  NETWORK  [conn257] end connection 114.212.84.175:32970 (31 connections now open)
2020-09-22T12:12:25.578+0800 I  NETWORK  [conn258] end connection 114.212.84.175:32974 (30 connections now open)
2020-09-22T12:12:25.760+0800 I  REPL     [rsBackgroundSync] sync source candidate: 120.55.194.98:27019
2020-09-22T12:12:26.250+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 39, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.250+0800 I  ELECTION [conn243] Sending vote response: { term: 39, voteGranted: true, reason: "" }
2020-09-22T12:12:26.252+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:26.252+0800 I  ELECTION [conn243] Sending vote response: { term: 40, voteGranted: true, reason: "" }
2020-09-22T12:12:26.760+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-09-22T12:12:26.760+0800 I  REPL     [replexec-7] Member 120.55.194.98:27019 is now in state RS_DOWN - Request 1242 timed out, deadline was 2020-09-22T12:12:26.760+0800, op was RemoteCommand 1242 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:12:26.760+0800 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "112.124.21.191:27019", fromId: 2, term: 39 }
2020-09-22T12:12:27.388+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:27.388+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 40
2020-09-22T12:12:27.388+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1243 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:27.388+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1244 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:27.388+0800 I  ELECTION [replexec-1] VoteRequester(term 40 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747946, 2), t: 40 }"; response message: { term: 40, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000028') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747946, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747946, 2) }
2020-09-22T12:12:28.327+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.329+0800 I  ELECTION [conn243] Sending vote response: { term: 40, voteGranted: true, reason: "" }
2020-09-22T12:12:28.331+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747946, 2), t: 40 } }
2020-09-22T12:12:28.331+0800 I  ELECTION [conn243] Sending vote response: { term: 41, voteGranted: true, reason: "" }
2020-09-22T12:12:28.388+0800 I  CONNPOOL [Replication] Ending connection to host 120.55.194.98:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-09-22T12:12:28.388+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:28.388+0800 I  ELECTION [replexec-7] VoteRequester(term 40 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Request 1243 timed out, deadline was 2020-09-22T12:12:28.388+0800, op was RemoteCommand 1243 -- target:[120.55.194.98:27019] db:admin expDate:2020-09-22T12:12:28.388+0800 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 40, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:28.388+0800 I  ELECTION [replexec-7] not running for primary, we have been superseded already during dry run. original term: 40, current term: 41
2020-09-22T12:12:28.388+0800 I  ELECTION [replexec-7] Lost dry run election due to internal error
2020-09-22T12:12:29.357+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:29.357+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 41
2020-09-22T12:12:29.357+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1247 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:29.357+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1248 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:29.357+0800 I  ELECTION [replexec-2] VoteRequester(term 41 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747949, 1), t: 41 }"; response message: { term: 41, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000029') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747949, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747949, 1) }
2020-09-22T12:12:30.341+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 41, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.341+0800 I  ELECTION [conn243] Sending vote response: { term: 41, voteGranted: true, reason: "" }
2020-09-22T12:12:30.343+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:30.343+0800 I  ELECTION [conn243] Sending vote response: { term: 42, voteGranted: true, reason: "" }
2020-09-22T12:12:30.357+0800 I  ELECTION [replexec-6] VoteRequester(term 41 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:30.357+0800 I  ELECTION [replexec-6] not running for primary, we have been superseded already during dry run. original term: 41, current term: 42
2020-09-22T12:12:30.357+0800 I  ELECTION [replexec-6] Lost dry run election due to internal error
2020-09-22T12:12:31.437+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:31.437+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 42
2020-09-22T12:12:31.437+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1250 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:31.437+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1251 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:31.437+0800 I  ELECTION [replexec-0] VoteRequester(term 42 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747949, 1), t: 41 }"; response message: { term: 42, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002a') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747950, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747949, 1) }
2020-09-22T12:12:32.353+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 42, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.353+0800 I  ELECTION [conn243] Sending vote response: { term: 42, voteGranted: true, reason: "" }
2020-09-22T12:12:32.355+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:32.355+0800 I  ELECTION [conn243] Sending vote response: { term: 43, voteGranted: true, reason: "" }
2020-09-22T12:12:32.437+0800 I  ELECTION [replexec-1] VoteRequester(term 42 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:32.437+0800 I  ELECTION [replexec-1] not running for primary, we have been superseded already during dry run. original term: 42, current term: 43
2020-09-22T12:12:32.437+0800 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-09-22T12:12:33.502+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:33.502+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 43
2020-09-22T12:12:33.502+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1254 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:33.502+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1255 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:33.502+0800 I  ELECTION [replexec-7] VoteRequester(term 43 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747949, 1), t: 41 }"; response message: { term: 43, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002b') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747952, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747949, 1) }
2020-09-22T12:12:34.473+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 43, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.473+0800 I  ELECTION [conn243] Sending vote response: { term: 43, voteGranted: true, reason: "" }
2020-09-22T12:12:34.475+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747949, 1), t: 41 } }
2020-09-22T12:12:34.475+0800 I  ELECTION [conn243] Sending vote response: { term: 44, voteGranted: true, reason: "" }
2020-09-22T12:12:34.502+0800 I  ELECTION [replexec-2] VoteRequester(term 43 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:34.502+0800 I  ELECTION [replexec-2] not running for primary, we have been superseded already during dry run. original term: 43, current term: 44
2020-09-22T12:12:34.502+0800 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-09-22T12:12:35.539+0800 I  ELECTION [replexec-7] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:35.539+0800 I  ELECTION [replexec-7] conducting a dry run election to see if we could be elected. current term: 44
2020-09-22T12:12:35.539+0800 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 1258 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:35.539+0800 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 1259 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:35.539+0800 I  ELECTION [replexec-5] VoteRequester(term 44 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747955, 1), t: 44 }"; response message: { term: 44, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002c') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747955, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747955, 1) }
2020-09-22T12:12:36.488+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 44, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.488+0800 I  ELECTION [conn243] Sending vote response: { term: 44, voteGranted: true, reason: "" }
2020-09-22T12:12:36.490+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:36.490+0800 I  ELECTION [conn243] Sending vote response: { term: 45, voteGranted: true, reason: "" }
2020-09-22T12:12:36.539+0800 I  ELECTION [replexec-3] VoteRequester(term 44 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:36.539+0800 I  ELECTION [replexec-3] not running for primary, we have been superseded already during dry run. original term: 44, current term: 45
2020-09-22T12:12:36.539+0800 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-09-22T12:12:37.502+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:37.502+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 45
2020-09-22T12:12:37.502+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1261 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:37.502+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1262 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:37.502+0800 I  ELECTION [replexec-6] VoteRequester(term 45 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747955, 1), t: 44 }"; response message: { term: 45, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002d') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747956, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747955, 1) }
2020-09-22T12:12:38.502+0800 I  ELECTION [replexec-3] VoteRequester(term 45 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:38.503+0800 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-09-22T12:12:38.503+0800 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-09-22T12:12:38.573+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.573+0800 I  ELECTION [conn243] Sending vote response: { term: 45, voteGranted: true, reason: "" }
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 45
2020-09-22T12:12:38.574+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1265 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:38.574+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1266 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 45, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-6] VoteRequester(term 45 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's term (45) is lower than mine (46)"; response message: { term: 46, voteGranted: false, reason: "candidate's term (45) is lower than mine (46)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002d') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747956, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747955, 1) }
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-6] not running for primary, we have been superseded already
2020-09-22T12:12:38.574+0800 I  ELECTION [replexec-6] Lost dry run election due to internal error
2020-09-22T12:12:38.575+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747955, 1), t: 44 } }
2020-09-22T12:12:38.575+0800 I  ELECTION [conn243] Sending vote response: { term: 46, voteGranted: true, reason: "" }
2020-09-22T12:12:39.603+0800 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:39.603+0800 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 46
2020-09-22T12:12:39.603+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1267 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:39.603+0800 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1268 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:39.603+0800 I  ELECTION [replexec-5] VoteRequester(term 46 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747959, 1), t: 46 }"; response message: { term: 46, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002e') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747959, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747959, 1) }
2020-09-22T12:12:40.603+0800 I  ELECTION [replexec-2] VoteRequester(term 46 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:40.603+0800 I  ELECTION [replexec-2] not running for primary, we received insufficient votes
2020-09-22T12:12:40.603+0800 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-09-22T12:12:40.639+0800 I  ELECTION [replexec-7] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:40.639+0800 I  ELECTION [replexec-7] conducting a dry run election to see if we could be elected. current term: 46
2020-09-22T12:12:40.639+0800 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 1273 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:40.639+0800 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 1274 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:40.639+0800 I  ELECTION [replexec-3] VoteRequester(term 46 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747959, 1), t: 46 }"; response message: { term: 46, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002e') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747959, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747959, 1) }
2020-09-22T12:12:40.712+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 46, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.712+0800 I  ELECTION [conn243] Sending vote response: { term: 46, voteGranted: true, reason: "" }
2020-09-22T12:12:40.714+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747959, 1), t: 46 } }
2020-09-22T12:12:40.714+0800 I  ELECTION [conn243] Sending vote response: { term: 47, voteGranted: true, reason: "" }
2020-09-22T12:12:41.639+0800 I  ELECTION [replexec-1] VoteRequester(term 46 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:41.639+0800 I  ELECTION [replexec-1] not running for primary, we have been superseded already during dry run. original term: 46, current term: 47
2020-09-22T12:12:41.639+0800 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-09-22T12:12:41.783+0800 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:41.783+0800 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 47
2020-09-22T12:12:41.783+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1277 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:41.783+0800 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1278 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:41.783+0800 I  ELECTION [replexec-6] VoteRequester(term 47 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747961, 1), t: 47 }"; response message: { term: 47, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000002f') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747961, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747961, 1) }
2020-09-22T12:12:42.763+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 47, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.763+0800 I  ELECTION [conn243] Sending vote response: { term: 47, voteGranted: true, reason: "" }
2020-09-22T12:12:42.765+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747961, 1), t: 47 } }
2020-09-22T12:12:42.765+0800 I  ELECTION [conn243] Sending vote response: { term: 48, voteGranted: true, reason: "" }
2020-09-22T12:12:42.783+0800 I  ELECTION [replexec-2] VoteRequester(term 47 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:42.783+0800 I  ELECTION [replexec-2] not running for primary, we have been superseded already during dry run. original term: 47, current term: 48
2020-09-22T12:12:42.783+0800 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-09-22T12:12:43.762+0800 I  REPL     [replexec-5] Member 120.55.192.104:27019 is now in state PRIMARY
2020-09-22T12:12:44.817+0800 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:44.817+0800 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 48
2020-09-22T12:12:44.817+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1281 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:44.817+0800 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1282 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:44.817+0800 I  ELECTION [replexec-0] VoteRequester(term 48 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747964, 5), t: 48 }"; response message: { term: 48, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000030') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747964, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747964, 5) }
2020-09-22T12:12:45.762+0800 I  REPL     [replexec-3] Member 120.55.192.104:27019 is now in state SECONDARY
2020-09-22T12:12:45.817+0800 I  ELECTION [replexec-5] VoteRequester(term 48 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:45.817+0800 I  ELECTION [replexec-5] not running for primary, we received insufficient votes
2020-09-22T12:12:45.817+0800 I  ELECTION [replexec-5] Lost dry run election due to internal error
2020-09-22T12:12:45.826+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:45.826+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 48
2020-09-22T12:12:45.826+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1284 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:45.826+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1285 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:45.826+0800 I  ELECTION [replexec-2] VoteRequester(term 48 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747964, 5), t: 48 }"; response message: { term: 48, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000030') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747964, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747964, 5) }
2020-09-22T12:12:45.828+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 48, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.828+0800 I  ELECTION [conn243] Sending vote response: { term: 48, voteGranted: true, reason: "" }
2020-09-22T12:12:45.831+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747964, 5), t: 48 } }
2020-09-22T12:12:45.831+0800 I  ELECTION [conn243] Sending vote response: { term: 49, voteGranted: true, reason: "" }
2020-09-22T12:12:46.826+0800 I  ELECTION [replexec-3] VoteRequester(term 48 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:46.826+0800 I  ELECTION [replexec-3] not running for primary, we have been superseded already during dry run. original term: 48, current term: 49
2020-09-22T12:12:46.826+0800 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-09-22T12:12:46.876+0800 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:46.876+0800 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 49
2020-09-22T12:12:46.876+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1287 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:46.876+0800 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1288 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:46.876+0800 I  ELECTION [replexec-1] VoteRequester(term 49 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747966, 1), t: 49 }"; response message: { term: 49, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000031') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747966, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747966, 1) }
2020-09-22T12:12:47.876+0800 I  ELECTION [replexec-3] VoteRequester(term 49 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:47.876+0800 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-09-22T12:12:47.876+0800 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-09-22T12:12:47.956+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 49, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.956+0800 I  ELECTION [conn243] Sending vote response: { term: 49, voteGranted: true, reason: "" }
2020-09-22T12:12:47.958+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747966, 1), t: 49 } }
2020-09-22T12:12:47.958+0800 I  ELECTION [conn243] Sending vote response: { term: 50, voteGranted: true, reason: "" }
2020-09-22T12:12:48.300+0800 I  NETWORK  [conn65] end connection 112.124.21.191:59386 (29 connections now open)
2020-09-22T12:12:48.588+0800 I  NETWORK  [conn70] end connection 47.96.16.32:51730 (28 connections now open)
2020-09-22T12:12:48.589+0800 I  NETWORK  [conn67] end connection 118.31.43.238:49146 (27 connections now open)
2020-09-22T12:12:48.591+0800 I  NETWORK  [conn20] end connection 47.96.5.198:36110 (26 connections now open)
2020-09-22T12:12:49.090+0800 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-09-22T12:12:49.091+0800 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 50
2020-09-22T12:12:49.091+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1290 -- target:120.55.194.98:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:49.091+0800 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 1291 -- target:120.55.192.104:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747942, 17), t: 38 } }
2020-09-22T12:12:49.092+0800 I  ELECTION [replexec-2] VoteRequester(term 50 dry run) received a no vote from 120.55.192.104:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timestamp(1600747968, 1), t: 50 }"; response message: { term: 50, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1600747942, 17), t: 38 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000032') }, lastCommittedOpTime: Timestamp(1600747942, 17), $clusterTime: { clusterTime: Timestamp(1600747968, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1600747968, 1) }
2020-09-22T12:12:49.357+0800 I  CONNPOOL [Replication] Connecting to 120.55.194.98:27019
2020-09-22T12:12:50.019+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 50, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.019+0800 I  ELECTION [conn243] Sending vote response: { term: 50, voteGranted: true, reason: "" }
2020-09-22T12:12:50.022+0800 I  ELECTION [conn243] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 51, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1600747968, 1), t: 50 } }
2020-09-22T12:12:50.022+0800 I  ELECTION [conn243] Sending vote response: { term: 51, voteGranted: true, reason: "" }
2020-09-22T12:12:50.091+0800 I  ELECTION [replexec-6] VoteRequester(term 50 dry run) failed to receive response from 120.55.194.98:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-09-22T12:12:50.091+0800 I  ELECTION [replexec-6] not running for primary, we have been superseded already during dry run. original term: 50, current term: 51
2020-09-22T12:12:50.091+0800 I  ELECTION [replexec-6] Lost dry run election due to internal error
